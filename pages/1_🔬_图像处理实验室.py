import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io
from datetime import datetime
import sqlite3
import os
import zipfile
import tempfile
import shutil
import base64
import time
import pandas as pd
import random
from scipy import ndimage
from scipy.signal import convolve2d
import matplotlib
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
# ========== è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼ ==========
plt.rcParams['font.sans-serif'] = ['SimHei']  # é»‘ä½“
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜


# ========== è¾…åŠ©å‡½æ•° ==========
st.set_page_config(
    page_title="å›¾åƒå¤„ç†å®éªŒå®¤ - èæ€æ”¿å¹³å°",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ç°ä»£åŒ–å®éªŒå®¤CSSï¼ˆå¢å¼ºç‰ˆï¼‰
st.markdown("""
<style>
:root {
    --primary-red: #dc2626;
    --dark-red: #b91c1c;
    --light-red: #fef2f2;
    --accent-red: #ef4444;
    --gold: #f59e0b;
    --beige-light: #fefaf0;
    --beige-medium: #fdf6e3;
    --beige-dark: #faf0d9;
}

/* æ•´ä½“é¡µé¢èƒŒæ™¯ - ç±³è‰²æ¸å˜ */
.stApp {
    background: linear-gradient(135deg, #fefaf0 0%, #fdf6e3 50%, #faf0d9 100%);
}

.lab-header {
    background: linear-gradient(135deg, #dc2626 0%, #b91c1c 100%);
    color: white;
    padding: 40px 30px;
    border-radius: 20px;
    text-align: center;
    margin-bottom: 30px;
    box-shadow: 0 8px 32px rgba(220, 38, 38, 0.3);
    border: 3px solid #f59e0b;
}

.lab-title {
    font-size: 2.8rem;
    margin-bottom: 10px;
    font-weight: bold;
}

.ideology-card {
    background: linear-gradient(135deg, #fef2f2, #fff);
    padding: 25px;
    border-radius: 15px;
    border: 2px solid #dc2626;
    margin: 20px 0;
    box-shadow: 0 6px 12px rgba(220, 38, 38, 0.15);
}

.info-card {
    background: linear-gradient(135deg, #fef2f2, #ffecec);
    padding: 20px;
    border-radius: 12px;
    border-left: 4px solid #dc2626;
    margin: 15px 0;
    box-shadow: 0 4px 6px rgba(220, 38, 38, 0.1);
}

.image-container {
    border: 3px solid #dc2626;
    border-radius: 12px;
    padding: 15px;
    background: white;
    box-shadow: 0 6px 12px rgba(0,0,0,0.1);
    transition: all 0.3s ease;
}

.image-container:hover {
    transform: translateY(-2px);
    box-shadow: 0 10px 20px rgba(220, 38, 38, 0.2);
}

/* ç°ä»£åŒ–æŒ‰é’® */
.stButton button {
    background: linear-gradient(135deg, #ffffff, #fef2f2);
    color: #dc2626;
    border: 2px solid #dc2626;
    padding: 14px 28px;
    border-radius: 50px;
    font-weight: 600;
    box-shadow: 0 4px 15px rgba(220, 38, 38, 0.2);
    transition: all 0.3s ease;
    font-size: 1rem;
    letter-spacing: 0.5px;
    position: relative;
    overflow: hidden;
}
    
.stButton button::before {
    content: '';
    position: absolute;
    top: 0;
    left: -100%;
    width: 100%;
    height: 100%;
    background: linear-gradient(90deg, transparent, rgba(220, 38, 38, 0.1), transparent);
    transition: left 0.6s;
}
.stButton button::before {
    content: '';
    position: absolute;
    top: 0;
    left: -100%;
    width: 100%;
    height: 100%;
    background: linear-gradient(90deg, transparent, rgba(220, 38, 38, 0.1), transparent);
    transition: left 0.6s;
}
   
.stButton button:hover {
    background: linear-gradient(135deg, #dc2626, #b91c1c);
    color: white;
    transform: translateY(-3px);
    box-shadow: 0 8px 25px rgba(220, 38, 38, 0.4);
    border-color: #dc2626;
}
    

/* ç‰¹æ®ŠæŒ‰é’®æ ·å¼ - é‡‘è‰²è¾¹æ¡† */
.stButton button.gold-btn {
    border: 2px solid #d4af37;
    color: #d4af37;
    background: linear-gradient(135deg, #fffdf6, #fefaf0);
}
    
.stButton button.gold-btn:hover {
    background: linear-gradient(135deg, #d4af37, #b8941f);
    color: white;
    border-color: #d4af37;
} border-color: #d4af37;
}
/* æ•´ä½“é¡µé¢å†…å®¹åŒºåŸŸ */
.main .block-container {
    padding-top: 2rem;
    padding-bottom: 2rem;
    background: linear-gradient(135deg, #fefaf0 0%, #fdf6e3 50%, #faf0d9 100%);
}

/* ä¾§è¾¹æ æ ·å¼ - ç±³è‰²æ¸å˜ */
section[data-testid="stSidebar"] {
    background: linear-gradient(135deg, #fdf6e3 0%, #faf0d9 50%, #f5e6c8 100%) !important;
}

.file-item {
    background: #f8f9fa;
    border: 1px solid #dee2e6;
    border-radius: 8px;
    padding: 10px;
    margin: 5px 0;
    display: flex;
    justify-content: space-between;
    align-items: center;
}
.file-item:hover {
    background: #e9ecef;
}

/* æ ‡ç­¾é¡µæ ·å¼ */
.stTabs [data-baseweb="tab-list"] {
    gap: 8px;
    background: linear-gradient(135deg, #fdf6e3, #faf0d9);
    padding: 10px;
    border-radius: 15px;
    margin-bottom: 20px;
}

.stTabs [data-baseweb="tab"] {
    border-radius: 10px;
    padding: 10px 20px;
    font-weight: 600;
    transition: all 0.3s ease;
    background: white;
    border: 2px solid #e5e7eb;
}

.stTabs [data-baseweb="tab"]:hover {
    background: #fef2f2;
    border-color: #dc2626;
    color: #dc2626;
}

.stTabs [aria-selected="true"] {
    background: linear-gradient(135deg, #dc2626, #b91c1c) !important;
    color: white !important;
    border-color: #dc2626 !important;
    box-shadow: 0 4px 12px rgba(220, 38, 38, 0.3);
}

/* æ»‘åŠ¨æ¡æ ·å¼ */
.stSlider [data-baseweb="slider"] [aria-valuetext] {
    color: #dc2626 !important;
}

/* æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ */
.stFileUploader {
    border: 2px dashed #dc2626 !important;
    border-radius: 12px !important;
    background: #fef2f2 !important;
}

/* ç‰¹æ•ˆæ ·å¼ */
.effect-preview {
    position: relative;
    overflow: hidden;
    border-radius: 10px;
    margin: 10px 0;
}

.effect-preview img {
    transition: transform 0.5s ease;
}

.effect-preview:hover img {
    transform: scale(1.05);
}

/* è¿›åº¦æ¡æ ·å¼ */
.stProgress > div > div > div > div {
    background-color: #dc2626 !important;
}

/* è­¦å‘Šæ¡†æ ·å¼ */
.stAlert {
    border-radius: 12px !important;
    border: 2px solid !important;
}

/* å®éªŒå¡ç‰‡ */
.experiment-card {
    background: linear-gradient(135deg, #ffffff, #fef2f2);
    border: 2px solid #e5e7eb;
    border-radius: 15px;
    padding: 25px;
    margin: 20px 0;
    transition: all 0.3s ease;
    position: relative;
    overflow: hidden;
}

.experiment-card::before {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    width: 5px;
    height: 100%;
    background: linear-gradient(to bottom, #dc2626, #f59e0b);
}

.experiment-card:hover {
    border-color: #dc2626;
    box-shadow: 0 10px 25px rgba(220, 38, 38, 0.15);
    transform: translateY(-3px);
}

.experiment-number {
    background: linear-gradient(135deg, #dc2626, #b91c1c);
    color: white;
    width: 40px;
    height: 40px;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    font-weight: bold;
    font-size: 1.2rem;
    margin-bottom: 15px;
}

/* å‚æ•°é¢æ¿ */
.param-panel {
    background: linear-gradient(135deg, #f8f9fa, #ffffff);
    border: 2px solid #e9ecef;
    border-radius: 12px;
    padding: 20px;
    margin: 15px 0;
}

.param-panel h4 {
    color: #dc2626;
    border-bottom: 2px solid #f59e0b;
    padding-bottom: 10px;
    margin-bottom: 15px;
}

/* æ¯”è¾ƒè§†å›¾ */
.comparison-view {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 20px;
    margin: 20px 0;
}

.comparison-box {
    text-align: center;
    padding: 15px;
    background: white;
    border-radius: 10px;
    border: 2px solid #e5e7eb;
}

.comparison-box h5 {
    margin-bottom: 10px;
    color: #333;
    font-weight: 600;
}

/* ç»Ÿè®¡å¡ç‰‡å¢å¼º */
.stats-card {
    background: linear-gradient(135deg, #ffffff, #fef2f2);
    padding: 25px;
    border-radius: 15px;
    border: 2px solid #dc2626;
    text-align: center;
    margin: 10px;
    position: relative;
    overflow: hidden;
}

.stats-card::after {
    content: '';
    position: absolute;
    top: -50%;
    left: -50%;
    width: 200%;
    height: 200%;
    background: linear-gradient(45deg, transparent, rgba(220, 38, 38, 0.1), transparent);
    transform: rotate(45deg);
    animation: shimmer 3s infinite;
}

@keyframes shimmer {
    0% { transform: rotate(45deg) translateX(-100%); }
    100% { transform: rotate(45deg) translateX(100%); }
}

.stats-number {
    font-size: 2.5rem;
    font-weight: bold;
    color: #dc2626;
    margin: 15px 0;
    text-shadow: 0 2px 4px rgba(0,0,0,0.1);
}

.stats-label {
    font-size: 0.9rem;
    color: #666;
    text-transform: uppercase;
    letter-spacing: 1px;
}

/* çŠ¶æ€å¾½ç« å¢å¼º */
.status-badge {
    padding: 8px 20px;
    border-radius: 25px;
    font-size: 0.9rem;
    font-weight: bold;
    display: inline-block;
    text-transform: uppercase;
    letter-spacing: 1px;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}

.status-pending {
    background: linear-gradient(135deg, #fef3c7, #fde68a);
    color: #d97706;
    border: 2px solid #f59e0b;
}

.status-graded {
    background: linear-gradient(135deg, #d1fae5, #a7f3d0);
    color: #059669;
    border: 2px solid #10b981;
}

.status-returned {
    background: linear-gradient(135deg, #fee2e2, #fca5a5);
    color: #dc2626;
    border: 2px solid #ef4444;
}

/* æ•™å¸ˆè¯„åˆ†å¡ç‰‡å¢å¼º */
.grading-card {
    background: linear-gradient(135deg, #f0f9ff, #e0f2fe);
    padding: 25px;
    border-radius: 15px;
    border: 2px solid #0ea5e9;
    margin: 15px 0;
    box-shadow: 0 4px 6px rgba(14, 165, 233, 0.2);
    position: relative;
}

.grading-card::before {
    content: 'ğŸ‘¨â€ğŸ«';
    position: absolute;
    top: 10px;
    right: 10px;
    font-size: 1.5rem;
    opacity: 0.3;
}

/* æäº¤æˆåŠŸç‰¹æ•ˆå¢å¼º */
.submission-success {
    text-align: center;
    padding: 50px;
    background: linear-gradient(135deg, #dcfce7, #bbf7d0);
    border-radius: 20px;
    border: 4px solid #22c55e;
    margin: 20px 0;
    animation: celebrate 2s ease-in-out;
    position: relative;
    overflow: hidden;
}

.submission-success::before {
    content: 'ğŸ‰';
    font-size: 4rem;
    position: absolute;
    top: 20px;
    left: 20px;
    opacity: 0.3;
}

.submission-success::after {
    content: 'âœ¨';
    font-size: 3rem;
    position: absolute;
    bottom: 20px;
    right: 20px;
    opacity: 0.3;
}

@keyframes celebrate {
    0% { transform: scale(0.8); opacity: 0; }
    50% { transform: scale(1.05); opacity: 1; }
    100% { transform: scale(1); opacity: 1; }
}

/* é¢œè‰²é€šé“æ ·å¼ */
.channel-display {
    display: grid;
    grid-template-columns: repeat(4, 1fr);
    gap: 15px;
    margin: 20px 0;
}

.channel-box {
    text-align: center;
    padding: 15px;
    border-radius: 10px;
    color: white;
    font-weight: bold;
}

.channel-red { background: linear-gradient(135deg, #ef4444, #dc2626); }
.channel-green { background: linear-gradient(135deg, #10b981, #059669); }
.channel-blue { background: linear-gradient(135deg, #3b82f6, #1d4ed8); }
.channel-gray { background: linear-gradient(135deg, #6b7280, #4b5563); }
/* æäº¤è®°å½•å¡ç‰‡ */
.submission-card {
    background: white;
    border: 2px solid #e5e7eb;
    border-radius: 12px;
    padding: 20px;
    margin: 15px 0;
    box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    transition: all 0.3s ease;
}

.submission-card:hover {
    border-color: #dc2626;
    box-shadow: 0 6px 12px rgba(220, 38, 38, 0.2);
    transform: translateY(-2px);
}

/* ç‰¹æ•ˆé¢„è§ˆç½‘æ ¼ */
.effects-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
    gap: 20px;
    margin: 20px 0;
}

.effect-item {
    background: white;
    border-radius: 10px;
    overflow: hidden;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    transition: all 0.3s ease;
    cursor: pointer;
}

.effect-item:hover {
    transform: translateY(-5px);
    box-shadow: 0 8px 16px rgba(0,0,0,0.2);
}

.effect-thumb {
    height: 150px;
    overflow: hidden;
}

.effect-thumb img {
    width: 100%;
    height: 100%;
    object-fit: cover;
    transition: transform 0.5s ease;
}

.effect-item:hover .effect-thumb img {
    transform: scale(1.1);
}

.effect-info {
    padding: 15px;
    text-align: center;
}

.effect-info h5 {
    margin: 0;
    color: #333;
}

.effect-info p {
    margin: 5px 0 0 0;
    color: #666;
    font-size: 0.9rem;
}
/* çŠ¶æ€å¾½ç«  */
.status-badge {
    padding: 8px 16px;
    border-radius: 20px;
    font-size: 0.9rem;
    font-weight: bold;
    display: inline-block;
}

.status-pending {
    background: #fef3c7;
    color: #d97706;
    border: 1px solid #f59e0b;
}

.status-graded {
    background: #d1fae5;
    color: #059669;
    border: 1px solid #10b981;
}

.status-returned {
    background: #fee2e2;
    color: #dc2626;
    border: 1px solid #ef4444;
}

/* ç»Ÿè®¡å¡ç‰‡ */
.stats-card {
    background: linear-gradient(135deg, #fef2f2, #fff);
    padding: 20px;
    border-radius: 12px;
    border: 2px solid #dc2626;
    text-align: center;
    margin: 10px;
}

.stats-number {
    font-size: 2rem;
    font-weight: bold;
    color: #dc2626;
    margin: 10px 0;
}

.stats-label {
    font-size: 0.9rem;
    color: #666;
}

/* çƒŸèŠ±ç‰¹æ•ˆå®¹å™¨ */
.fireworks-container {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    pointer-events: none;
    z-index: 9999;
}

/* æ•™å¸ˆè¯„åˆ†å¡ç‰‡ */
.grading-card {
    background: linear-gradient(135deg, #f0f9ff, #e0f2fe);
    padding: 20px;
    border-radius: 12px;
    border: 2px solid #0ea5e9;
    margin: 15px 0;
    box-shadow: 0 4px 6px rgba(14, 165, 233, 0.2);
}

/* æäº¤ç‰¹æ•ˆ */
.submission-success {
    text-align: center;
    padding: 40px;
    background: linear-gradient(135deg, #dcfce7, #bbf7d0);
    border-radius: 20px;
    border: 4px solid #22c55e;
    margin: 20px 0;
    animation: celebrate 2s ease-in-out;
}

@keyframes celebrate {
    0% { transform: scale(0.8); opacity: 0; }
    50% { transform: scale(1.05); opacity: 1; }
    100% { transform: scale(1); opacity: 1; }
}

.confetti {
    position: fixed;
    width: 10px;
    height: 10px;
    background: #ff0000;
    opacity: 0.7;
    animation: fall linear forwards;
}

@keyframes fall {
    to {
        transform: translateY(100vh) rotate(360deg);
        opacity: 0;
    }
}

/* ç›´æ–¹å›¾æ ·å¼ */
.histogram-container {
    background: white;
    border-radius: 12px;
    padding: 20px;
    margin: 20px 0;
    box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    border: 2px solid #e5e7eb;
}

.histogram-title {
    text-align: center;
    margin-bottom: 15px;
    color: #dc2626;
    font-weight: bold;
    font-size: 1.2rem;
}

.histogram-comparison {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 20px;
    margin-top: 30px;
}

.histogram-box {
    text-align: center;
    padding: 15px;
    background: #f8f9fa;
    border-radius: 10px;
    border: 2px solid #e9ecef;
}

.histogram-box h5 {
    margin-bottom: 15px;
    color: #333;
    font-weight: 600;
    border-bottom: 2px solid #dc2626;
    padding-bottom: 8px;
}
</style>
""", unsafe_allow_html=True)

# åˆ›å»ºä¸Šä¼ æ–‡ä»¶å­˜å‚¨ç›®å½•
UPLOAD_DIR = "experiment_submissions"
if not os.path.exists(UPLOAD_DIR):
    os.makedirs(UPLOAD_DIR)

def get_beijing_time():
    """è·å–åŒ—äº¬æ—¶é—´"""
    from datetime import datetime, timedelta
    
    # è·å–å½“å‰UTCæ—¶é—´
    utc_now = datetime.utcnow()
    
    # åŒ—äº¬æ˜¯UTC+8æ—¶åŒº
    beijing_time = utc_now + timedelta(hours=8)
    
    return beijing_time.strftime('%Y-%m-%d %H:%M:%S')

# æ•°æ®åº“å‡½æ•° - å®Œæ•´ç‰ˆ
def init_experiment_db():
    """åˆå§‹åŒ–å®éªŒæäº¤æ•°æ®åº“"""
    conn = sqlite3.connect('image_processing_platform.db')
    c = conn.cursor()
    
    # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
    c.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='experiment_submissions'")
    table_exists = c.fetchone()
    
    if table_exists:
        # è¡¨å·²å­˜åœ¨ï¼Œæ£€æŸ¥æ‰€æœ‰å¿…éœ€çš„åˆ—
        c.execute("PRAGMA table_info(experiment_submissions)")
        columns = [column[1] for column in c.fetchall()]
        
        required_columns = {
            'can_view_score': 'BOOLEAN DEFAULT 0',
            'file_names': 'TEXT DEFAULT ""',
            'resubmission_count': 'INTEGER DEFAULT 0'
        }
        
        for col_name, col_type in required_columns.items():
            if col_name not in columns:
                try:
                    c.execute(f'ALTER TABLE experiment_submissions ADD COLUMN {col_name} {col_type}')
                except:
                    pass
    else:
        # åˆ›å»ºæ–°è¡¨
        c.execute('''
            CREATE TABLE experiment_submissions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                student_username TEXT NOT NULL,
                experiment_number INTEGER NOT NULL,
                experiment_title TEXT NOT NULL,
                submission_content TEXT NOT NULL,
                submission_time TEXT NOT NULL,
                status TEXT DEFAULT 'pending',
                teacher_feedback TEXT DEFAULT '',
                score INTEGER DEFAULT 0,
                can_view_score BOOLEAN DEFAULT 0,
                resubmission_count INTEGER DEFAULT 0,
                file_names TEXT DEFAULT ''
            )
        ''')
    
    conn.commit()
    conn.close()

def save_uploaded_files(uploaded_files, submission_id, student_username):
    """ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶"""
    saved_files = []
    if uploaded_files:
        submission_dir = os.path.join(UPLOAD_DIR, f"{student_username}_{submission_id}")
        if not os.path.exists(submission_dir):
            os.makedirs(submission_dir)
        
        for uploaded_file in uploaded_files:
            file_path = os.path.join(submission_dir, uploaded_file.name)
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            saved_files.append(uploaded_file.name)
    
    return saved_files

def get_submission_files(submission_id, student_username):
    """è·å–æäº¤çš„æ–‡ä»¶åˆ—è¡¨"""
    submission_dir = os.path.join(UPLOAD_DIR, f"{student_username}_{submission_id}")
    if os.path.exists(submission_dir):
        return os.listdir(submission_dir)
    return []

def get_file_path(submission_id, student_username, filename):
    """è·å–æ–‡ä»¶è·¯å¾„"""
    return os.path.join(UPLOAD_DIR, f"{student_username}_{submission_id}", filename)

def create_zip_file(submission_id, student_username):
    """åˆ›å»ºåŒ…å«æ‰€æœ‰æäº¤æ–‡ä»¶çš„ZIPåŒ…"""
    submission_dir = os.path.join(UPLOAD_DIR, f"{student_username}_{submission_id}")
    if os.path.exists(submission_dir):
        zip_path = os.path.join(UPLOAD_DIR, f"{student_username}_{submission_id}.zip")
        with zipfile.ZipFile(zip_path, 'w') as zipf:
            for root, dirs, files in os.walk(submission_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    zipf.write(file_path, os.path.relpath(file_path, submission_dir))
        return zip_path
    return None
def get_example_images():
    """è·å–ç´ æåº“ä¸­çš„å›¾åƒæ–‡ä»¶"""
    example_dir = "examples"
    example_files = []
    
    if os.path.exists(example_dir):
        # è·å–æ‰€æœ‰æ”¯æŒçš„å›¾åƒæ–‡ä»¶
        supported_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.webp', '.tiff')
        for file in os.listdir(example_dir):
            if file.lower().endswith(supported_extensions):
                example_files.append(file)
    
    return sorted(example_files)  # æŒ‰åç§°æ’åº

def load_example_image(filename):
    """åŠ è½½ç´ æåº“ä¸­çš„å›¾åƒ"""
    example_path = os.path.join("examples", filename)
    
    # åˆ›å»ºä¸€ä¸ªç±»ä¼¼ä¸Šä¼ æ–‡ä»¶çš„å¯¹è±¡
    class ExampleFile:
        def __init__(self, path):
            self.name = os.path.basename(path)
            self.path = path
        
        def read(self):
            with open(self.path, 'rb') as f:
                return f.read()
    
    return ExampleFile(example_path)
def submit_experiment(student_username, experiment_number, experiment_title, submission_content, uploaded_files):
    """æäº¤å®éªŒ"""
    try:
        conn = sqlite3.connect('image_processing_platform.db')
        c = conn.cursor()
        submission_time = get_beijing_time()  # ä½¿ç”¨åŒ—äº¬æ—¶é—´
        
        # å…ˆæ’å…¥æäº¤è®°å½•
        c.execute('''
            INSERT INTO experiment_submissions 
            (student_username, experiment_number, experiment_title, submission_content, submission_time)
            VALUES (?, ?, ?, ?, ?)
        ''', (student_username, experiment_number, experiment_title, submission_content, submission_time))
        
        submission_id = c.lastrowid
        
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        saved_files = save_uploaded_files(uploaded_files, submission_id, student_username)
        
        # æ›´æ–°æ–‡ä»¶åå­—æ®µ
        c.execute('''
            UPDATE experiment_submissions 
            SET file_names = ? 
            WHERE id = ?
        ''', (','.join(saved_files), submission_id))
        
        conn.commit()
        conn.close()
        return True, "å®éªŒæäº¤æˆåŠŸï¼", submission_id
    except Exception as e:
        return False, f"æäº¤å¤±è´¥ï¼š{str(e)}", None




def get_student_experiments(student_username):
    """è·å–å­¦ç”Ÿçš„å®éªŒæäº¤è®°å½•"""
    try:
        conn = sqlite3.connect('image_processing_platform.db')
        c = conn.cursor()
        c.execute('''
            SELECT * FROM experiment_submissions 
            WHERE student_username = ? 
            ORDER BY submission_time DESC
        ''', (student_username,))
        results = c.fetchall()
        conn.close()
        return results
    except Exception as e:
        st.error(f"è·å–å­¦ç”Ÿå®éªŒè®°å½•å¤±è´¥: {str(e)}")
        return []

def get_all_experiments():
    """è·å–æ‰€æœ‰å­¦ç”Ÿçš„å®éªŒæäº¤ï¼ˆæ•™å¸ˆç«¯ä½¿ç”¨ï¼‰"""
    try:
        conn = sqlite3.connect('image_processing_platform.db')
        c = conn.cursor()
        c.execute('''
            SELECT es.*, u.role 
            FROM experiment_submissions es
            JOIN users u ON es.student_username = u.username
            ORDER BY es.submission_time DESC
        ''')
        results = c.fetchall()
        conn.close()
        return results
    except Exception as e:
        st.error(f"è·å–æ‰€æœ‰å®éªŒè®°å½•å¤±è´¥: {str(e)}")
        return []

def update_experiment_score(submission_id, score, feedback, can_view_score, status):
    """æ›´æ–°å®éªŒè¯„åˆ†å’Œåé¦ˆ"""
    try:
        conn = sqlite3.connect('image_processing_platform.db')
        c = conn.cursor()
        c.execute('''
            UPDATE experiment_submissions 
            SET score = ?, teacher_feedback = ?, can_view_score = ?, status = ?
            WHERE id = ?
        ''', (score, feedback, can_view_score, status, submission_id))
        conn.commit()
        conn.close()
        return True, "è¯„åˆ†æ›´æ–°æˆåŠŸï¼"
    except Exception as e:
        return False, f"æ›´æ–°å¤±è´¥ï¼š{str(e)}"


def withdraw_experiment(submission_id, student_username):
    """æ’¤å›å®éªŒæäº¤"""
    try:
        conn = sqlite3.connect('image_processing_platform.db')
        c = conn.cursor()
        c.execute('''
            DELETE FROM experiment_submissions 
            WHERE id = ? AND student_username = ? AND status = 'pending'
        ''', (submission_id, student_username))
        
        # åˆ é™¤å¯¹åº”çš„æ–‡ä»¶
        submission_dir = os.path.join(UPLOAD_DIR, f"{student_username}_{submission_id}")
        if os.path.exists(submission_dir):
            shutil.rmtree(submission_dir)
        
        conn.commit()
        conn.close()
        return True, "å®éªŒæäº¤å·²æ’¤å›ï¼"
    except Exception as e:
        return False, "æ’¤å›å¤±è´¥ï¼šåªèƒ½æ’¤å›å¾…æ‰¹æ”¹çŠ¶æ€çš„æäº¤"

def get_experiment_title(number):
    titles = {
        1: "å›¾åƒå¢å¼ºæŠ€æœ¯å®è·µ",
        2: "è¾¹ç¼˜æ£€æµ‹ç®—æ³•æ¯”è¾ƒ",
        3: "å›¾åƒæ»¤æ³¢å¤„ç†å®éªŒ",
        4: "å›¾åƒé”åŒ–æŠ€æœ¯åº”ç”¨",
        5: "é‡‡æ ·ä¸é‡åŒ–åˆ†æ",
        6: "å½©è‰²å›¾åƒåˆ†å‰²å®è·µ",
        7: "é¢œè‰²é€šé“åˆ†æä¸å¤„ç†",
        8: "å›¾åƒç‰¹æ•ˆå¤„ç†æŠ€æœ¯",
        9: "å›¾åƒç»˜ç”»é£æ ¼è½¬æ¢",
        10: "é£æ ¼è¿ç§»ä¸è‰ºæœ¯åŒ–",
        11: "è€ç…§ç‰‡ä¸Šè‰²ä¸ä¿®å¤",
        12: "æ•°å­—å½¢æ€å­¦è½¬æ¢",
        13: "ç»¼åˆå›¾åƒå¤„ç†é¡¹ç›®"
    }
    return titles.get(number, f"å®éªŒ{number}")

def get_experiment_description(number):
    descriptions = {
        1: "ä½¿ç”¨ä¸åŒçš„å›¾åƒå¢å¼ºæŠ€æœ¯å¤„ç†å›¾åƒï¼Œåˆ†ææ¯”è¾ƒæ•ˆæœ",
        2: "å®ç°å¹¶æ¯”è¾ƒå¤šç§è¾¹ç¼˜æ£€æµ‹ç®—æ³•çš„æ€§èƒ½",
        3: "åº”ç”¨ä¸­å€¼æ»¤æ³¢ã€å‡å€¼æ»¤æ³¢ç­‰æŠ€æœ¯è¿›è¡Œå›¾åƒå»å™ª",
        4: "ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­ç­‰æ–¹æ³•è¿›è¡Œå›¾åƒé”åŒ–",
        5: "åˆ†æä¸åŒé‡‡æ ·ç‡å’Œé‡åŒ–ç­‰çº§å¯¹å›¾åƒè´¨é‡çš„å½±å“",
        6: "å®ç°åŸºäºRGBå’ŒHSIé¢œè‰²ç©ºé—´çš„å›¾åƒåˆ†å‰²",
        7: "åˆ†æRGBé€šé“å¹¶è¿›è¡Œé€šé“åˆ†ç¦»ä¸é‡ç»„",
        8: "æ·»åŠ é›¨ç‚¹ã€é›ªèŠ±ã€æ¨±èŠ±ç­‰å¤šç§ç‰¹æ•ˆ",
        9: "å®ç°æ²¹ç”»ã€ç´ æã€æ°´å¢¨ç”»ç­‰ç»˜ç”»æ•ˆæœ",
        10: "åº”ç”¨æ¢µé«˜ã€æ˜Ÿç©ºç­‰è‰ºæœ¯é£æ ¼è¿ç§»",
        11: "å°†é»‘ç™½ç…§ç‰‡è½¬æ¢ä¸ºå½©è‰²ç…§ç‰‡",
        12: "åº”ç”¨è…èš€ã€è†¨èƒ€ç­‰å½¢æ€å­¦æ“ä½œ",
        13: "ç»¼åˆè¿ç”¨å¤šç§å›¾åƒå¤„ç†æŠ€æœ¯å®Œæˆå®é™…é¡¹ç›®"
    }
    return descriptions.get(number, "å®ŒæˆæŒ‡å®šçš„å›¾åƒå¤„ç†å®éªŒ")

# åˆå§‹åŒ–æ•°æ®åº“
init_experiment_db()

# ======================= å›¾åƒå¤„ç†å‡½æ•° =======================

# 1. å›¾åƒå¢å¼ºå‡½æ•°
def apply_histogram_equalization(image):
    """ç›´æ–¹å›¾å‡è¡¡åŒ–"""
    if len(image.shape) == 3:
        img_yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)
        img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])
        output = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)
    else:
        output = cv2.equalizeHist(image)
    return output

def apply_contrast_adjustment(image, alpha, beta):
    """å¯¹æ¯”åº¦è°ƒæ•´"""
    output = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)
    return output

def apply_gamma_correction(image, gamma):
    """ä¼½é©¬æ ¡æ­£"""
    if gamma <= 0:
        # å¯ä»¥è¿”å›åŸå›¾æˆ–è®¾ç½®é»˜è®¤å€¼
        gamma = 0.1  # æˆ– return image.copy()
    
    inv_gamma = 1.0 / gamma
    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
    return cv2.LUT(image, table)

def apply_clahe(image, clip_limit=2.0, tile_grid_size=(8,8)):
    """é™åˆ¶å¯¹æ¯”åº¦è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–"""
    if len(image.shape) == 3:
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
        l = clahe.apply(l)
        lab = cv2.merge([l, a, b])
        output = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    else:
        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
        output = clahe.apply(image)
    return output

# 2. è¾¹ç¼˜æ£€æµ‹å‡½æ•°
def apply_canny_edge(image, threshold1=50, threshold2=150):
    """Cannyè¾¹ç¼˜æ£€æµ‹"""
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()
    edges = cv2.Canny(gray, threshold1, threshold2)
    return cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)

def apply_sobel_edge(image, ksize=3):
    """Sobelè¾¹ç¼˜æ£€æµ‹"""
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()
    
    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=ksize)
    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=ksize)
    
    # ä½¿ç”¨cv2.magnitudeè®¡ç®—æ¢¯åº¦å¹…å€¼ï¼ˆæ›´é«˜æ•ˆï¼‰
    magnitude = cv2.magnitude(sobelx, sobely)
    
    # è½¬æ¢ä¸º8ä½æ— ç¬¦å·æ•´æ•°ï¼ˆè‡ªåŠ¨å–ç»å¯¹å€¼ï¼‰
    magnitude = cv2.convertScaleAbs(magnitude)
    
    return cv2.cvtColor(magnitude, cv2.COLOR_GRAY2BGR)

def apply_laplacian_edge(image):
    """Laplacianè¾¹ç¼˜æ£€æµ‹"""
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()
    
    # è®¡ç®—Laplacianï¼ˆå¯èƒ½äº§ç”Ÿè´Ÿå€¼ï¼‰
    laplacian = cv2.Laplacian(gray, cv2.CV_64F)
    
    # å–ç»å¯¹å€¼å¹¶è½¬æ¢ä¸º8ä½
    laplacian_abs = cv2.convertScaleAbs(laplacian)
    
    return cv2.cvtColor(laplacian_abs, cv2.COLOR_GRAY2BGR)

# 3. çº¿æ€§å˜æ¢å‡½æ•°
def apply_affine_transform(image, angle=0, scale=1.0, tx=0, ty=0):
    """ä»¿å°„å˜æ¢"""
    height, width = image.shape[:2]
    center = (width // 2, height // 2)
    matrix = cv2.getRotationMatrix2D(center, angle, scale)
    matrix[0, 2] += tx
    matrix[1, 2] += ty
    return cv2.warpAffine(image, matrix, (width, height))

def apply_perspective_transform(image, perspective_strength=0.1):
    """é€è§†å˜æ¢"""
    height, width = image.shape[:2]
    
    src_points = np.float32([[0, 0], [width, 0], [0, height], [width, height]])
    
    # æ ¹æ®strengthå‚æ•°æ§åˆ¶é€è§†å¼ºåº¦
    offset_x = int(width * perspective_strength)
    offset_y = int(height * perspective_strength)
    
    dst_points = np.float32([
        [offset_x, offset_y],
        [width - offset_x, offset_y],
        [offset_x, height - offset_y],
        [width - offset_x, height - offset_y]
    ])
    
    matrix = cv2.getPerspectiveTransform(src_points, dst_points)
    return cv2.warpPerspective(image, matrix, (width, height))

# 4. å›¾åƒé”åŒ–å‡½æ•°
def apply_sharpen_filter(image, kernel_size=3):
    """
    åº”ç”¨é”åŒ–æ»¤æ³¢å™¨
    kernel_size: æ»¤æ³¢å™¨å¤§å°ï¼Œå¿…é¡»æ˜¯å¥‡æ•°
    """
    # ç¡®ä¿kernel_sizeæ˜¯å¥‡æ•°
    if kernel_size % 2 == 0:
        kernel_size += 1
    
    # åˆ›å»ºé”åŒ–æ ¸
    kernel_sharpen = np.zeros((kernel_size, kernel_size), dtype=np.float32)
    center = kernel_size // 2
    
    # ä¸­å¿ƒä¸ºæ­£å€¼ï¼Œå‘¨å›´ä¸ºè´Ÿå€¼
    for i in range(kernel_size):
        for j in range(kernel_size):
            if i == center and j == center:
                kernel_sharpen[i, j] = kernel_size * kernel_size
            else:
                kernel_sharpen[i, j] = -1
    
    # åº”ç”¨æ»¤æ³¢å™¨
    sharpened = cv2.filter2D(image, -1, kernel_sharpen)
    
    # å¯é€‰ï¼šå½’ä¸€åŒ–ç»“æœ
    sharpened = np.clip(sharpened, 0, 255).astype(np.uint8)
    
    return sharpened

def apply_unsharp_masking(image, sigma=1.0, amount=1.0):
    """
    åº”ç”¨éé”åŒ–æ©è”½
    sigma: é«˜æ–¯æ¨¡ç³Šçš„æ ‡å‡†å·®
    amount: é”åŒ–ç¨‹åº¦
    """
    # é«˜æ–¯æ¨¡ç³Š
    blurred = cv2.GaussianBlur(image, (0, 0), sigma)
    
    # è®¡ç®—åŸå§‹ä¸æ¨¡ç³Šçš„å·®å¼‚
    detail = cv2.subtract(image, blurred)
    
    # å¢å¼ºç»†èŠ‚å¹¶åŠ å›åŸå›¾
    sharpened = cv2.addWeighted(image, 1.0, detail, amount, 0)
    
    # ç¡®ä¿ç»“æœåœ¨0-255èŒƒå›´å†…
    sharpened = np.clip(sharpened, 0, 255).astype(np.uint8)
    
    return sharpened

def apply_laplacian_sharpening(image):
    """
    æ‹‰æ™®æ‹‰æ–¯é”åŒ–
    """
    # è½¬æ¢ä¸ºç°åº¦
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()
    
    # æ‹‰æ™®æ‹‰æ–¯ç®—å­
    laplacian = cv2.Laplacian(gray, cv2.CV_64F)
    
    # è½¬æ¢ä¸º8ä½å¹¶å¢å¼º
    laplacian = cv2.convertScaleAbs(laplacian)
    
    # åŠ å›åŸå›¾
    if len(image.shape) == 3:
        # å½©è‰²å›¾åƒ
        result = image.copy().astype(np.float32)
        for i in range(3):
            result[:, :, i] = np.clip(result[:, :, i] + laplacian, 0, 255)
        result = result.astype(np.uint8)
    else:
        # ç°åº¦å›¾åƒ
        result = cv2.addWeighted(gray, 1.0, laplacian, 0.5, 0)
    
    return result

def apply_high_boost_filter(image, A=1.5):
    """
    é«˜é¢‘æå‡æ»¤æ³¢
    A: å¢å¼ºç³»æ•°ï¼Œé€šå¸¸>1
    """
    # ä½é€šæ»¤æ³¢ï¼ˆæ¨¡ç³Šï¼‰
    low_pass = cv2.GaussianBlur(image, (5, 5), 1.0)
    
    # é«˜é¢‘åˆ†é‡ = åŸå›¾ - ä½é€š
    high_freq = cv2.subtract(image, low_pass)
    
    # é«˜é¢‘æå‡ = åŸå›¾ + (A-1) * é«˜é¢‘åˆ†é‡
    result = cv2.addWeighted(image, 1.0, high_freq, A-1, 0)
    
    # ç¡®ä¿ç»“æœåœ¨æœ‰æ•ˆèŒƒå›´å†…
    result = np.clip(result, 0, 255).astype(np.uint8)
    
    return result

def apply_adaptive_sharpen(image, strength=0.5):
    """
    è‡ªé€‚åº”é”åŒ–ï¼ŒåŸºäºè¾¹ç¼˜æ£€æµ‹
    strength: é”åŒ–å¼ºåº¦ (0-1)
    """
    # è¾¹ç¼˜æ£€æµ‹
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()
    
    edges = cv2.Canny(gray, 50, 150)
    
    # åˆ›å»ºè¾¹ç¼˜é®ç½©
    edges_mask = edges.astype(np.float32) / 255.0
    
    # åº”ç”¨é”åŒ–ï¼ˆä»…åœ¨æœ‰è¾¹ç¼˜çš„åŒºåŸŸï¼‰
    sharpened = apply_unsharp_masking(image, sigma=1.0, amount=strength*3)
    
    # æ··åˆï¼šè¾¹ç¼˜åŒºåŸŸç”¨é”åŒ–ï¼Œå…¶ä»–åŒºåŸŸç”¨åŸå›¾
    if len(image.shape) == 3:
        edges_mask = cv2.cvtColor(edges_mask, cv2.COLOR_GRAY2BGR)
    
    result = image * (1 - edges_mask) + sharpened * edges_mask
    result = np.clip(result, 0, 255).astype(np.uint8)
    
    return result

# 5. é‡‡æ ·ä¸é‡åŒ–å‡½æ•°
def apply_sampling(image, ratio=2):
    """å›¾åƒé‡‡æ ·"""
    height, width = image.shape[:2]
    new_height = max(1, height // ratio)  # é˜²æ­¢é™¤0
    new_width = max(1, width // ratio)
    return cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_LINEAR)

def apply_quantization(image, levels=16):
    """å›¾åƒé‡åŒ–"""
    # ç¡®ä¿levelsåˆç†
    levels = max(2, min(256, levels))
    
    step = 256 / levels  # ä½¿ç”¨æµ®ç‚¹æ•°é™¤æ³•
    
    if len(image.shape) == 3:
        quantized = image.copy().astype(np.float32)
        for i in range(3):
            quantized[:,:,i] = np.round(quantized[:,:,i] / step) * step
    else:
        quantized = np.round(image.astype(np.float32) / step) * step
    
    return np.clip(quantized, 0, 255).astype(np.uint8)

# 6. å½©è‰²å›¾åƒåˆ†å‰²å‡½æ•°
def apply_rgb_segmentation(image, lower_color, upper_color):
    """RGBé¢œè‰²åˆ†å‰²"""
    if len(lower_color) != 3 or len(upper_color) != 3:
        raise ValueError("é¢œè‰²èŒƒå›´å¿…é¡»æ˜¯3ä¸ªå€¼çš„å…ƒç»„/åˆ—è¡¨ (B, G, R)")
    
    mask = cv2.inRange(image, lower_color, upper_color)
    result = cv2.bitwise_and(image, image, mask=mask)
    return result

def apply_hsv_segmentation(image, lower_hsv, upper_hsv):
    """HSVé¢œè‰²åˆ†å‰²"""
    if len(lower_hsv) != 3 or len(upper_hsv) != 3:
        raise ValueError("HSVèŒƒå›´å¿…é¡»æ˜¯3ä¸ªå€¼çš„å…ƒç»„/åˆ—è¡¨ (H, S, V)")
    
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    mask = cv2.inRange(hsv, lower_hsv, upper_hsv)
    result = cv2.bitwise_and(image, image, mask=mask)
    return result

# 7. é¢œè‰²é€šé“åˆ†æä¸å¤„ç†
def split_channels(image):
    """åˆ†ç¦»RGBé€šé“"""
    if len(image.shape) != 3:
        # ç°åº¦å›¾åƒå¤„ç†
        return [image.copy(), image.copy(), image.copy()]
    
    b, g, r = cv2.split(image)
    zeros = np.zeros_like(b)
    
    red_channel = cv2.merge([zeros, zeros, r])
    green_channel = cv2.merge([zeros, g, zeros])
    blue_channel = cv2.merge([b, zeros, zeros])
    
    return [red_channel, green_channel, blue_channel]

def adjust_channel(image, channel_index, value):
    """è°ƒæ•´ç‰¹å®šé€šé“"""
    adjusted = image.copy()
    
    # ç¡®ä¿channel_indexæœ‰æ•ˆ
    if channel_index < 0 or channel_index >= adjusted.shape[2]:
        return adjusted
    
    # ä½¿ç”¨cv2.addç¡®ä¿ä¸æº¢å‡º
    adjusted[:,:,channel_index] = cv2.add(adjusted[:,:,channel_index], value)
    
    # è£å‰ªåˆ°æœ‰æ•ˆèŒƒå›´
    adjusted = np.clip(adjusted, 0, 255).astype(np.uint8)
    
    return adjusted

def create_channel_histogram(image):
    """åˆ›å»ºé€šé“ç›´æ–¹å›¾"""
    if len(image.shape) == 3:
        # å½©è‰²å›¾åƒ
        histograms = []
        for i in range(3):
            hist = cv2.calcHist([image], [i], None, [256], [0, 256])
            # å½’ä¸€åŒ–ä»¥ä¾¿æ¯”è¾ƒ
            hist = cv2.normalize(hist, hist, 0, 1, cv2.NORM_MINMAX)
            histograms.append(hist.flatten())
        return histograms
    else:
        # ç°åº¦å›¾åƒ
        hist = cv2.calcHist([image], [0], None, [256], [0, 256])
        hist = cv2.normalize(hist, hist, 0, 1, cv2.NORM_MINMAX)
        return [hist.flatten()]

# 8. ç‰¹æ•ˆå¤„ç†å‡½æ•°
def add_rain_effect(image, intensity=100, opacity=0.5):
    """æ·»åŠ é›¨æ»´ç‰¹æ•ˆ"""
    rain_layer = np.zeros_like(image, dtype=np.uint8)
    height, width = image.shape[:2]
    
    for _ in range(intensity * 5):  # å¢åŠ æ•°é‡
        x = random.randint(0, width-1)
        y = random.randint(0, height-1)
        length = random.randint(15, 40)
        thickness = random.randint(1, 3)
        color = random.randint(180, 240)
        
        for i in range(length):
            if y+i < height and x+i//3 < width:
                cv2.line(rain_layer, (x+i//3, y+i), (x+i//3+thickness, y+i), 
                        (color, color, color), thickness)
    
    # é«˜æ–¯æ¨¡ç³Š
    rain_layer = cv2.GaussianBlur(rain_layer, (5, 5), 0)
    
    # æ·»åŠ è¿åŠ¨æ¨¡ç³Šï¼ˆå…³é”®æ”¹è¿›ï¼‰
    kernel_size = 7
    kernel = np.zeros((kernel_size, kernel_size))
    kernel[:, kernel_size//2] = 1.0 / kernel_size
    rain_layer = cv2.filter2D(rain_layer, -1, kernel)
    
    result = cv2.addWeighted(image, 1-opacity, rain_layer, opacity, 0)
    return result

def add_snow_effect(image, intensity=200, opacity=0.3):
    """æ·»åŠ é›ªèŠ±ç‰¹æ•ˆ"""
    snow_layer = np.zeros_like(image, dtype=np.uint8)
    height, width = image.shape[:2]
    
    # åˆ›å»ºé›ªèŠ±ï¼ˆå¢åŠ å¤§å°å˜åŒ–ï¼‰
    for _ in range(intensity * 3):  # å¢åŠ é›ªèŠ±æ•°é‡
        x = random.randint(0, width-1)
        y = random.randint(0, height-1)
        radius = random.randint(1, 5)  # å¢åŠ å¤§å°èŒƒå›´
        brightness = random.randint(180, 255)  # å¢åŠ äº®åº¦èŒƒå›´
    
        cv2.circle(snow_layer, (x, y), radius, 
                  (brightness, brightness, brightness), -1)
    
    # åº”ç”¨è½»å¾®æ¨¡ç³Š
    snow_layer = cv2.GaussianBlur(snow_layer, (5, 5), 0)
    
    # æ·»åŠ å‚ç›´è¿åŠ¨æ¨¡ç³Šï¼ˆå…³é”®æ”¹è¿›ï¼ï¼‰
    kernel = np.array([[0, 0, 0],
                       [1, 1, 1],
                       [0, 0, 0]]) / 3.0
    snow_layer = cv2.filter2D(snow_layer, -1, kernel)
    
    # å åŠ é›ªèŠ±å±‚
    result = cv2.addWeighted(image, 1 - opacity, snow_layer, opacity, 0)
    return result

def apply_sakura_effect(image, sakura_intensity):
    """æ·»åŠ æ¨±èŠ±ç‰¹æ•ˆ - æ–°å¢"""
    try:
        if len(image.shape) == 2:
            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
        
        height, width = image.shape[:2]
        sakura_layer = np.zeros((height, width, 4), dtype=np.uint8)  # RGBA
        
        # æ¨±èŠ±æ•°é‡
        num_sakura = int(sakura_intensity * width * height / 800)
        
        for _ in range(num_sakura):
            # éšæœºä½ç½®
            x = np.random.randint(0, width)
            y = np.random.randint(0, height)
            
            # æ¨±èŠ±å¤§å°
            size = np.random.randint(3, 8)
            
            # æ¨±èŠ±é¢œè‰²ï¼ˆç²‰è‰²ç³»ï¼‰
            pink_color = [
                np.random.randint(230, 255),  # R
                np.random.randint(180, 220),  # G
                np.random.randint(200, 240),  # B
                np.random.randint(150, 220)   # A
            ]
            
            # ç»˜åˆ¶æ¨±èŠ±ï¼ˆå¤šä¸ªèŠ±ç“£ï¼‰
            for angle in range(0, 360, 72):
                rad = np.radians(angle)
                px = int(x + size * np.cos(rad))
                py = int(y + size * np.sin(rad))
                cv2.circle(sakura_layer, (px, py), size//2, pink_color, -1)
            
            # èŠ±å¿ƒ
            cv2.circle(sakura_layer, (x, y), size//3, [255, 255, 200, 200], -1)
        
        # æ¨¡ç³Šæ¨±èŠ±å±‚å¢åŠ æŸ”å’Œæ„Ÿ
        sakura_layer = cv2.GaussianBlur(sakura_layer, (3, 3), 0)
        
        # åˆ†ç¦»RGBAé€šé“
        sakura_rgb = sakura_layer[:, :, :3]
        sakura_alpha = sakura_layer[:, :, 3] / 255.0
        
        # ä¸åŸå§‹å›¾åƒæ··åˆ
        result = image.copy().astype(np.float32)
        for c in range(3):
            result[:, :, c] = result[:, :, c] * (1 - sakura_alpha) + sakura_rgb[:, :, c] * sakura_alpha
        
        return result.astype(np.uint8)
    except Exception as e:
        st.error(f"æ¨±èŠ±ç‰¹æ•ˆé”™è¯¯: {str(e)}")
        return image


def add_starry_night_effect(image, stars=100):
    """æ·»åŠ æ˜Ÿç©ºç‰¹æ•ˆ"""
    result = image.copy()
    height, width = image.shape[:2]
    
    # æ·»åŠ ä¸åŒå¤§å°çš„æ˜Ÿæ˜Ÿ
    for _ in range(stars * 3):  # å¢åŠ æ˜Ÿæ˜Ÿæ•°é‡
        x = random.randint(0, width-1)
        y = random.randint(0, height-1)
        
        # éšæœºæ˜Ÿæ˜Ÿå¤§å°ï¼ˆ1-4åƒç´ ï¼‰
        radius = random.randint(1, 4)
        
        # æ˜Ÿæ˜Ÿé¢œè‰²ï¼ˆä¸åŒæ¸©åº¦ï¼‰
        color_choice = random.random()
        if color_choice < 0.6:  # 60% ç™½è‰²æ˜Ÿæ˜Ÿ
            brightness = random.randint(200, 255)
            color = (brightness, brightness, brightness)
        elif color_choice < 0.8:  # 20% é»„è‰²æ˜Ÿæ˜Ÿ
            brightness = random.randint(180, 230)
            color = (brightness, brightness, brightness // 2)
        else:  # 20% è“è‰²æ˜Ÿæ˜Ÿ
            brightness = random.randint(180, 220)
            color = (brightness, brightness - 30, brightness)
        
        # ç»˜åˆ¶æ˜Ÿæ˜Ÿ
        cv2.circle(result, (x, y), radius, color, -1)
        
        # æ·»åŠ æ˜Ÿå…‰æ•ˆæœï¼ˆæ›´è‡ªç„¶çš„å½¢çŠ¶ï¼‰
        if random.random() > 0.5:  # 50%çš„æ˜Ÿæ˜Ÿæœ‰å…‰èŠ’
            # å››å‘å…‰èŠ’
            for dx, dy in [(2,0), (-2,0), (0,2), (0,-2)]:
                px = min(max(x + dx, 0), width-1)
                py = min(max(y + dy, 0), height-1)
                cv2.circle(result, (px, py), max(1, radius-1), color, -1)
            
            # å¯¹è§’å…‰èŠ’
            if random.random() > 0.5:
                for dx, dy in [(2,2), (-2,2), (2,-2), (-2,-2)]:
                    px = min(max(x + dx, 0), width-1)
                    py = min(max(y + dy, 0), height-1)
                    cv2.circle(result, (px, py), 1, color, -1)
    
    # æ·»åŠ é«˜æ–¯æ¨¡ç³Šä½¿æ˜Ÿæ˜Ÿæ›´æŸ”å’Œ
    result = cv2.GaussianBlur(result, (3, 3), 0)
    
    # æ·»åŠ ä¸€äº›ç‰¹åˆ«äº®çš„æ˜Ÿæ˜Ÿ
    for _ in range(stars // 5):
        x = random.randint(0, width-1)
        y = random.randint(0, height-1)
        
        # ç»˜åˆ¶äº®æ˜Ÿ
        cv2.circle(result, (x, y), 2, (255, 255, 255), -1)
        
        # æ·»åŠ å…‰æ™•æ•ˆæœ
        for r in range(3, 6):
            alpha = 0.5 * (1 - (r-3)/3)  # å…‰æ™•æ¸å˜
            color_with_alpha = tuple(int(255 * alpha) for _ in range(3))
            cv2.circle(result, (x, y), r, color_with_alpha, 1)
    
    return result

# 9. å›¾åƒç»˜ç”»å¤„ç†å‡½æ•°

def apply_oil_painting_effect(image, radius=3, intensity=30, enhance_color=True):
    """æ²¹ç”»æ•ˆæœ"""
    # ç¡®ä¿è¾“å…¥æ˜¯uint8
    if image.dtype != np.uint8:
        image = image.astype(np.uint8)
    
    try:
        oil_painting = cv2.xphoto.oilPainting(image, radius, intensity)
    except:
        # å¦‚æœxphotoä¸å¯ç”¨ï¼Œä½¿ç”¨æ›¿ä»£æ–¹æ³•
        oil_painting = cv2.stylization(image, sigma_s=60, sigma_r=0.6)
    
    if enhance_color:
        # å¢å¼ºè‰²å½©é¥±å’Œåº¦
        hsv = cv2.cvtColor(oil_painting, cv2.COLOR_BGR2HSV)
        hsv = hsv.astype(np.float32)
        hsv[:, :, 1] = np.clip(hsv[:, :, 1] * 1.2, 0, 255)
        hsv = np.clip(hsv, 0, 255).astype(np.uint8)
        oil_painting = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    
    return oil_painting.astype(np.uint8)

def apply_pencil_sketch_effect(image, style="elegant", intensity=1.0):
    """ç´ ææ•ˆæœ"""
    # ç¡®ä¿è¾“å…¥æ˜¯uint8
    if image.dtype != np.uint8:
        image = image.astype(np.uint8)
    
    if style == "elegant":
        # ä¼˜é›…é£æ ¼ - ä½¿ç”¨é¢œè‰²å‡æ·¡ç®—æ³•
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        inverted = cv2.bitwise_not(gray)
        blurred = cv2.GaussianBlur(inverted, (21, 21), 3)
        
        # é¿å…é™¤é›¶é”™è¯¯
        denominator = 255 - blurred
        denominator[denominator == 0] = 1
        
        sketch = cv2.divide(gray, denominator, scale=256)
        sketch = cv2.convertScaleAbs(sketch, alpha=1.3 * intensity, beta=0)
        
        # è½¬æ¢ä¸ºå½©è‰²
        sketch_color = cv2.cvtColor(sketch, cv2.COLOR_GRAY2BGR)
        return sketch_color.astype(np.uint8)
    
    elif style == "artistic":
        # è‰ºæœ¯é£æ ¼
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # ä½¿ç”¨Cannyè¾¹ç¼˜æ£€æµ‹å’Œæ¨¡ç³Šæ··åˆ
        edges = cv2.Canny(gray, 50, 150)
        blurred = cv2.GaussianBlur(gray, (5, 5), 2)
        
        # æ··åˆè¾¹ç¼˜å’Œæ¨¡ç³Š
        sketch = cv2.addWeighted(blurred, 0.8, edges, 0.2, 0)
        sketch = 255 - sketch  # åç›¸
        
        # è½¬æ¢ä¸ºå½©è‰²
        sketch_color = cv2.cvtColor(sketch, cv2.COLOR_GRAY2BGR)
        return sketch_color.astype(np.uint8)
    
    else:  # classic
        # ä½¿ç”¨OpenCVå†…ç½®å‡½æ•°
        try:
            _, sketch = cv2.pencilSketch(image, sigma_s=120, sigma_r=0.1)
            sketch = cv2.convertScaleAbs(sketch, alpha=1.4, beta=10)
            sketch_color = cv2.cvtColor(sketch, cv2.COLOR_GRAY2BGR)
            return sketch_color.astype(np.uint8)
        except:
            # å¤‡ç”¨æ–¹æ¡ˆ
            return apply_pencil_sketch_effect(image, style="elegant", intensity=intensity)

def apply_ink_wash_painting_effect(image, ink_strength=0.4, paper_texture=True):
    """æ°´å¢¨ç”»æ•ˆæœ - ç®€åŒ–ç‰ˆï¼Œé¿å…å¤æ‚è¿ç®—"""
    # ç¡®ä¿è¾“å…¥æ˜¯uint8
    if image.dtype != np.uint8:
        image = image.astype(np.uint8)
    
    try:
        # è½¬æ¢ä¸ºç°åº¦
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # å¢å¼ºå¯¹æ¯”åº¦
        gray = cv2.equalizeHist(gray)
        
        # åŒè¾¹æ»¤æ³¢æ¨¡æ‹Ÿæ°´å¢¨æ‰©æ•£
        filtered = cv2.bilateralFilter(gray, 9, 150, 150)
        
        # é«˜æ–¯æ¨¡ç³Šåˆ›å»ºæ™•æŸ“æ•ˆæœ
        blurred = cv2.GaussianBlur(filtered, (15, 15), 5)
        
        # è¾¹ç¼˜æ£€æµ‹
        edges = cv2.adaptiveThreshold(filtered, 255,
                                     cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                     cv2.THRESH_BINARY_INV, 25, 10)
        
        # è½¬æ¢ä¸ºå½©è‰²
        ink_color = cv2.cvtColor(blurred, cv2.COLOR_GRAY2BGR)
        edges_color = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
        
        # é™ä½é¥±å’Œåº¦ï¼ˆåˆ›å»ºæ°´å¢¨æ„Ÿï¼‰
        hsv = cv2.cvtColor(ink_color, cv2.COLOR_BGR2HSV)
        hsv = hsv.astype(np.float32)
        hsv[:, :, 1] = hsv[:, :, 1] * 0.3  # å¤§å¹…é™ä½é¥±å’Œåº¦
        hsv = np.clip(hsv, 0, 255).astype(np.uint8)
        ink_color = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        
        # åˆ›å»ºç®€å•çš„è¾¹ç¼˜mask
        edges_float = edges.astype(np.float32) / 255.0
        
        # ç›´æ¥åº”ç”¨è¾¹ç¼˜ï¼ˆç®€åŒ–ç‰ˆï¼Œé¿å…å¤æ‚çš„maskæ“ä½œï¼‰
        edges_expanded = np.stack([edges_float, edges_float, edges_float], axis=2)
        
        # æ··åˆå¢¨è¿¹å’Œè¾¹ç¼˜
        result = ink_color * (1 - edges_expanded * ink_strength) + edges_color * edges_expanded * ink_strength * 0.3
        
        # æ·»åŠ è½»å¾®æ¨¡ç³Š
        result = cv2.GaussianBlur(result, (5, 5), 2)
        
        return np.clip(result, 0, 255).astype(np.uint8)
    
    except Exception as e:
        # å¦‚æœå‡ºé”™ï¼Œè¿”å›ä¸€ä¸ªç®€å•çš„ç°åº¦ç‰ˆæœ¬
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        result = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
        return result.astype(np.uint8)

def apply_comic_effect(image, edge_threshold=50, color_style="vibrant"):
    """æ¼«ç”»æ•ˆæœ - ç®€åŒ–ç‰ˆ"""
    # ç¡®ä¿è¾“å…¥æ˜¯uint8
    if image.dtype != np.uint8:
        image = image.astype(np.uint8)
    
    try:
        # 1. è½»å¾®æ¨¡ç³Šå‡å°‘å™ªç‚¹
        smoothed = cv2.bilateralFilter(image, 7, 50, 50)
        
        # 2. è¾¹ç¼˜æ£€æµ‹
        gray = cv2.cvtColor(smoothed, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, edge_threshold, edge_threshold * 2)
        
        # 3. æ ¹æ®é£æ ¼å¤„ç†é¢œè‰²
        if color_style == "vibrant":
            # é²œè‰³é£æ ¼ - å¢åŠ å¯¹æ¯”åº¦å’Œé¥±å’Œåº¦
            lab = cv2.cvtColor(smoothed, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            l = clahe.apply(l)
            lab = cv2.merge([l, a, b])
            color_enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
            
            # å¢åŠ é¥±å’Œåº¦
            hsv = cv2.cvtColor(color_enhanced, cv2.COLOR_BGR2HSV)
            hsv = hsv.astype(np.float32)
            hsv[:, :, 1] = np.clip(hsv[:, :, 1] * 1.5, 0, 255)
            hsv = np.clip(hsv, 0, 255).astype(np.uint8)
            color_enhanced = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            
        elif color_style == "soft":
            # æŸ”å’Œé£æ ¼ - ä½¿ç”¨stylization
            color_enhanced = cv2.stylization(smoothed, sigma_s=60, sigma_r=0.3)
            
        else:  # celé£æ ¼
            # ç®€å•é‡åŒ–
            color_enhanced = cv2.stylization(smoothed, sigma_s=100, sigma_r=0.1)
        
        # 4. åˆ›å»ºè¾¹ç¼˜mask
        edges_float = edges.astype(np.float32) / 255.0
        edges_mask = np.stack([edges_float, edges_float, edges_float], axis=2)
        
        # 5. æè¾¹é¢œè‰²
        if color_style == "soft":
            outline_color = np.array([[[60, 60, 60]]], dtype=np.float32)
        else:
            outline_color = np.array([[[10, 10, 10]]], dtype=np.float32)
        
        # 6. åº”ç”¨æè¾¹
        result = color_enhanced.astype(np.float32) * (1 - edges_mask) + outline_color * edges_mask
        
        return np.clip(result, 0, 255).astype(np.uint8)
    
    except Exception as e:
        # å¤‡ç”¨æ–¹æ¡ˆ
        return image.astype(np.uint8)

def apply_watercolor_effect(image, style="classic", texture_strength=0.3):
    """æ°´å½©ç”»æ•ˆæœ - ç®€åŒ–ç‰ˆ"""
    # ç¡®ä¿è¾“å…¥æ˜¯uint8
    if image.dtype != np.uint8:
        image = image.astype(np.uint8)
    
    try:
        if style == "classic":
            # ç»å…¸é£æ ¼ - ä½¿ç”¨stylization
            result = cv2.stylization(image, sigma_s=100, sigma_r=0.4)
            
            # å¢åŠ é¥±å’Œåº¦
            hsv = cv2.cvtColor(result, cv2.COLOR_BGR2HSV)
            hsv = hsv.astype(np.float32)
            hsv[:, :, 1] = np.clip(hsv[:, :, 1] * 1.3, 0, 255)
            hsv = np.clip(hsv, 0, 255).astype(np.uint8)
            result = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            
        else:  # modern
            # ç°ä»£é£æ ¼ - detailEnhance
            result = cv2.detailEnhance(image, sigma_s=10, sigma_r=0.15)
            
            # è¾¹ç¼˜ä¿ç•™æ¨¡ç³Š
            blurred = cv2.bilateralFilter(result, 7, 100, 100)
            result = cv2.addWeighted(result, 0.7, blurred, 0.3, 0)
        
        # è½»å¾®æ¨¡ç³Šä½¿æ•ˆæœæ›´æŸ”å’Œ
        result = cv2.GaussianBlur(result, (3, 3), 0.5)
        
        return result.astype(np.uint8)
    
    except Exception as e:
        # å¤‡ç”¨æ–¹æ¡ˆ
        return cv2.stylization(image, sigma_s=60, sigma_r=0.3).astype(np.uint8)

def apply_pop_art_effect(image, style="warhol", num_colors=8):
    """æ³¢æ™®è‰ºæœ¯æ•ˆæœ - ç®€åŒ–ç‰ˆ"""
    # ç¡®ä¿è¾“å…¥æ˜¯uint8
    if image.dtype != np.uint8:
        image = image.astype(np.uint8)
    
    try:
        # è°ƒæ•´å›¾åƒå¤§å°ä»¥æé«˜å¤„ç†é€Ÿåº¦
        height, width = image.shape[:2]
        if height * width > 800 * 600:
            scale = min(800 / width, 600 / height)
            small = cv2.resize(image, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)
        else:
            small = image
        
        # ä½¿ç”¨K-meansè¿›è¡Œé¢œè‰²é‡åŒ–
        pixels = small.reshape((-1, 3))
        pixels = np.float32(pixels)
        
        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)
        num_colors = min(num_colors, 12)
        
        _, labels, centers = cv2.kmeans(pixels, num_colors, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)
        
        # è½¬æ¢ä¸º8ä½
        centers = np.uint8(centers)
        
        # é‡å¡‘å›¾åƒ
        quantized = centers[labels.flatten()]
        quantized = quantized.reshape(small.shape)
        
        # å¢åŠ å¯¹æ¯”åº¦
        result = cv2.convertScaleAbs(quantized, alpha=1.2, beta=0)
        
        # å¦‚æœéœ€è¦ï¼Œè°ƒæ•´å›åŸå§‹å¤§å°
        if height * width > 800 * 600:
            result = cv2.resize(result, (width, height), interpolation=cv2.INTER_NEAREST)
        
        return result.astype(np.uint8)
    
    except Exception as e:
        # å¤‡ç”¨æ–¹æ¡ˆ - ç®€å•çš„é¢œè‰²é‡åŒ–
        Z = image.reshape((-1,3))
        Z = np.float32(Z)
        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)
        K = 8
        ret,label,center = cv2.kmeans(Z, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)
        center = np.uint8(center)
        res = center[label.flatten()]
        result = res.reshape(image.shape)
        return result.astype(np.uint8)

def apply_impressionist_effect(image, brush_size=3):
    """å°è±¡æ´¾æ•ˆæœ - ç®€åŒ–ç‰ˆ"""
    # ç¡®ä¿è¾“å…¥æ˜¯uint8
    if image.dtype != np.uint8:
        image = image.astype(np.uint8)
    
    try:
        # åˆ›å»ºæ¨¡ç³Šæ•ˆæœ
        blurred1 = cv2.GaussianBlur(image, (brush_size*2+1, brush_size*2+1), 0)
        blurred2 = cv2.bilateralFilter(image, 9, 75, 75)
        
        # æ··åˆæ•ˆæœ
        result = cv2.addWeighted(blurred1, 0.5, blurred2, 0.5, 0)
        
        # å¢å¼ºé¢œè‰²
        hsv = cv2.cvtColor(result, cv2.COLOR_BGR2HSV)
        hsv = hsv.astype(np.float32)
        hsv[:, :, 1] = np.clip(hsv[:, :, 1] * 1.2, 0, 255)
        hsv = np.clip(hsv, 0, 255).astype(np.uint8)
        result = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        
        return result.astype(np.uint8)
    
    except Exception as e:
        # å¤‡ç”¨æ–¹æ¡ˆ
        return cv2.GaussianBlur(image, (11, 11), 0).astype(np.uint8)

def apply_pastel_effect(image, softness=0.7):
    """ç²‰å½©ç”»æ•ˆæœ - ç®€åŒ–ç‰ˆ"""
    # ç¡®ä¿è¾“å…¥æ˜¯uint8
    if image.dtype != np.uint8:
        image = image.astype(np.uint8)
    
    try:
        # æ·±åº¦æ¨¡ç³Š
        blurred = cv2.bilateralFilter(image, 9, 150, 150)
        
        # æé«˜äº®åº¦
        lab = cv2.cvtColor(blurred, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        l = cv2.add(l, 30)
        lab = cv2.merge([l, a, b])
        result = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
        
        # æ·»åŠ å…‰æ™•æ•ˆæœ
        bloom = cv2.GaussianBlur(result, (0, 0), 10)
        result = cv2.addWeighted(result, 0.9, bloom, 0.1, 0)
        
        return result.astype(np.uint8)
    
    except Exception as e:
        # å¤‡ç”¨æ–¹æ¡ˆ
        return cv2.bilateralFilter(image, 9, 150, 150).astype(np.uint8)



# 10. é£æ ¼è¿ç§»æ•ˆæœ
def apply_van_gogh_style(image, twist_strength=0.001):
    """æ¢µé«˜é£æ ¼ï¼ˆç®€åŒ–ç‰ˆï¼‰- å‡å°æ—‹è½¬ç¨‹åº¦"""
    try:
        height, width = image.shape[:2]
        
        # ç¡®ä¿å›¾åƒæ˜¯BGRæ ¼å¼
        if len(image.shape) != 3:
            # å¦‚æœæ˜¯ç°åº¦å›¾ï¼Œè½¬æ¢ä¸ºBGR
            if len(image.shape) == 2:
                image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
            else:
                # åˆ›å»ºé»˜è®¤çš„BGRå›¾åƒ
                image = np.stack([image] * 3, axis=2) if len(image.shape) == 2 else image
        
        # 1. å¢å¼ºè‰²å½©é¥±å’Œåº¦
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        hsv = hsv.astype(np.float32)
        hsv[:,:,1] = np.clip(hsv[:,:,1] * 1.5, 0, 255)
        hsv = hsv.astype(np.uint8)
        vivid = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        
        # 2. æ·»åŠ æ²¹ç”»æ•ˆæœ - ä¿®å¤ xphoto ä¸å¯ç”¨çš„é—®é¢˜
        try:
            # æ£€æŸ¥ xphoto æ¨¡å—æ˜¯å¦å­˜åœ¨
            if hasattr(cv2, 'xphoto') and hasattr(cv2.xphoto, 'oilPainting'):
                oil_painting = cv2.xphoto.oilPainting(vivid, 7, 30)
            else:
                raise AttributeError("xphoto module not available")
        except (AttributeError, Exception):
            # å¦‚æœ xphoto ä¸å¯ç”¨ï¼Œä½¿ç”¨æ›¿ä»£æ–¹æ³•
            oil_painting = cv2.stylization(vivid, sigma_s=60, sigma_r=0.6)
            # å¢åŠ ä¸€äº›çº¹ç†æ•ˆæœ
            oil_painting = cv2.bilateralFilter(oil_painting, 9, 75, 75)
        
        # 3. æ·»åŠ æ—‹è½¬æ‰­æ›²ï¼ˆå‡å°æ—‹è½¬å¼ºåº¦ï¼‰
        result = np.zeros_like(oil_painting, dtype=np.float32)
        center_x, center_y = width // 2, height // 2
        
        # ä½¿ç”¨çŸ¢é‡æ“ä½œåŠ é€Ÿ
        y_coords, x_coords = np.mgrid[0:height, 0:width]
        dx = x_coords - center_x
        dy = y_coords - center_y
        distance = np.sqrt(dx*dx + dy*dy)
        
        # ä½¿ç”¨è¾ƒå°çš„æ‰­æ›²å¼ºåº¦
        twist_angle = distance * twist_strength
        angle = np.arctan2(dy, dx) + twist_angle
        
        src_x = (center_x + distance * np.cos(angle)).astype(np.int32)
        src_y = (center_y + distance * np.sin(angle)).astype(np.int32)
        
        # è¾¹ç•Œæ£€æŸ¥
        src_x = np.clip(src_x, 0, width-1)
        src_y = np.clip(src_y, 0, height-1)
        
        result = oil_painting[src_y, src_x]
        
        return result.astype(np.uint8)
    
    except Exception as e:
        # å¦‚æœå‘ç”Ÿä»»ä½•é”™è¯¯ï¼Œè¿”å›åŸå§‹å›¾åƒ
        print(f"Warning: apply_van_gogh_style failed: {e}")
        return image.copy() if isinstance(image, np.ndarray) else image
def apply_oil_painting_effect(image, radius=3, intensity=30, enhance_color=True):
    """æ²¹ç”»æ•ˆæœ"""
    try:
        # ç¡®ä¿è¾“å…¥æ˜¯uint8
        if image.dtype != np.uint8:
            image = image.astype(np.uint8)
        
        # ç¡®ä¿å›¾åƒæ˜¯BGRæ ¼å¼
        if len(image.shape) != 3:
            # å¦‚æœæ˜¯ç°åº¦å›¾ï¼Œè½¬æ¢ä¸ºBGR
            if len(image.shape) == 2:
                image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
            else:
                # åˆ›å»ºé»˜è®¤çš„BGRå›¾åƒ
                image = np.stack([image] * 3, axis=2) if len(image.shape) == 2 else image
        
        try:
            # æ£€æŸ¥ xphoto æ¨¡å—æ˜¯å¦å­˜åœ¨
            if hasattr(cv2, 'xphoto') and hasattr(cv2.xphoto, 'oilPainting'):
                oil_painting = cv2.xphoto.oilPainting(image, radius, intensity)
            else:
                raise AttributeError("xphoto module not available")
        except (AttributeError, Exception):
            # å¦‚æœ xphoto ä¸å¯ç”¨ï¼Œä½¿ç”¨æ›¿ä»£æ–¹æ³•
            # ä½¿ç”¨ stylization æ¨¡æ‹Ÿæ²¹ç”»æ•ˆæœ
            oil_painting = cv2.stylization(image, sigma_s=60, sigma_r=0.6)
            # æ·»åŠ ä¸€äº›çº¹ç†å¢å¼º
            kernel_size = radius * 2 + 1
            if kernel_size > 1:
                oil_painting = cv2.medianBlur(oil_painting, kernel_size)
        
        if enhance_color:
            # å¢å¼ºè‰²å½©é¥±å’Œåº¦
            hsv = cv2.cvtColor(oil_painting, cv2.COLOR_BGR2HSV)
            hsv = hsv.astype(np.float32)
            hsv[:, :, 1] = np.clip(hsv[:, :, 1] * 1.2, 0, 255)
            hsv = np.clip(hsv, 0, 255).astype(np.uint8)
            oil_painting = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        
        return oil_painting.astype(np.uint8)
    
    except Exception as e:
        # å¦‚æœå‘ç”Ÿä»»ä½•é”™è¯¯ï¼Œè¿”å›åŸå§‹å›¾åƒ
        print(f"Warning: apply_oil_painting_effect failed: {e}")
        return image.copy() if isinstance(image, np.ndarray) else image
def apply_starry_sky_style(image):
    """æ˜Ÿç©ºé£æ ¼ï¼ˆæ¢µé«˜ã€Šæ˜Ÿç©ºã€‹æ•ˆæœï¼‰- ä¼˜åŒ–"""
    # 1. å¢å¼ºè“è‰²è°ƒå’Œé»„è‰²è°ƒ
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    
    # å¢åŠ è“è‰²å’Œé»„è‰²
    b = cv2.add(b, 25).clip(0, 255)
    a = cv2.add(a, 10).clip(0, 255)
    
    lab = cv2.merge([l, a, b])
    color_tone = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    
    # 2. åº”ç”¨æ¢µé«˜é£æ ¼ï¼ˆä½¿ç”¨æ›´å°çš„æ—‹è½¬ï¼‰
    van_gogh_style = apply_van_gogh_style(color_tone, 0.0008)
    
    # 3. æ·»åŠ æ—‹æ¶¡æ•ˆæœ
    height, width = van_gogh_style.shape[:2]
    result = van_gogh_style.copy()
    
    # æ·»åŠ å¤šä¸ªæ—‹è½¬ä¸­å¿ƒ
    centers = [
        (width//4, height//4),
        (width*3//4, height//4),
        (width//4, height*3//4),
        (width*3//4, height*3//4)
    ]
    
    for center_x, center_y in centers:
        for y in range(max(0, center_y-50), min(height, center_y+50)):
            for x in range(max(0, center_x-50), min(width, center_x+50)):
                dx = x - center_x
                dy = y - center_y
                distance = np.sqrt(dx*dx + dy*dy)
                
                if distance < 50:
                    # è½»å¾®çš„æ—‹æ¶¡æ•ˆæœ
                    twist_angle = (50 - distance) * 0.01
                    src_x = int(center_x + distance * np.cos(np.arctan2(dy, dx) + twist_angle))
                    src_y = int(center_y + distance * np.sin(np.arctan2(dy, dx) + twist_angle))
                    
                    src_x = max(0, min(src_x, width-1))
                    src_y = max(0, min(src_y, height-1))
                    
                    result[y, x] = van_gogh_style[src_y, src_x]
    
    # 4. æ·»åŠ æ˜Ÿæ˜Ÿ
    for _ in range(150):
        x = random.randint(20, width-20)
        y = random.randint(20, height-20)
        
        # æ¢µé«˜é£æ ¼çš„æ˜Ÿæ˜Ÿï¼ˆæ›´è‡ªç„¶çš„æ˜ŸèŠ’æ•ˆæœï¼‰
        size = random.randint(1, 2)
        brightness = random.randint(220, 255)
        
        # ç»˜åˆ¶æ˜ŸèŠ’
        for angle in range(0, 360, 45):
            rad = np.deg2rad(angle)
            end_x = int(x + 6 * np.cos(rad))
            end_y = int(y + 6 * np.sin(rad))
            cv2.line(result, (x, y), (end_x, end_y), 
                    (brightness, brightness, brightness), 1)
        
        # ç»˜åˆ¶ä¸­å¿ƒå…‰ç‚¹
        cv2.circle(result, (x, y), size, 
                  (brightness, brightness, brightness), -1)
    
    return result

def apply_monet_style(image):
    """è«å¥ˆå°è±¡æ´¾é£æ ¼"""
    height, width = image.shape[:2]
    
    # 1. æŸ”å’Œçš„é¢œè‰²æ¨¡ç³Šï¼ˆå°è±¡æ´¾ç‰¹ç‚¹ï¼‰
    blurred = cv2.bilateralFilter(image, 15, 80, 80)
    
    # 2. æ·»åŠ ç¬”è§¦æ•ˆæœ
    brush_strokes = np.zeros_like(blurred, dtype=np.float32)
    
    # åˆ›å»ºéšæœºç¬”è§¦
    brush_size = 10
    for y in range(0, height, brush_size):
        for x in range(0, width, brush_size):
            # éšæœºé€‰æ‹©ç¬”è§¦æ–¹å‘
            angle = random.uniform(0, 2*np.pi)
            length = random.randint(brush_size, brush_size*2)
            
            end_x = int(x + length * np.cos(angle))
            end_y = int(y + length * np.sin(angle))
            
            end_x = max(0, min(end_x, width-1))
            end_y = max(0, min(end_y, height-1))
            
            # ä½¿ç”¨çº¿æ®µé¢œè‰²å¡«å……çŸ©å½¢åŒºåŸŸ
            color = blurred[y, x].astype(float)
            cv2.line(brush_strokes, (x, y), (end_x, end_y), color, brush_size)
    
    brush_strokes = brush_strokes.astype(np.uint8)
    
    # 3. å¢å¼ºé¢œè‰²ï¼ˆè«å¥ˆçš„é²œè‰³è‰²å½©ï¼‰
    hsv = cv2.cvtColor(brush_strokes, cv2.COLOR_BGR2HSV)
    
    # å¢åŠ é¥±å’Œåº¦
    hsv[:,:,1] = cv2.multiply(hsv[:,:,1], 1.3).clip(0, 255)
    
    # è°ƒæ•´è‰²è°ƒï¼ˆåå‘è“è‰²å’Œç´«è‰²ï¼‰
    hsv[:,:,0] = cv2.add(hsv[:,:,0], 10).clip(0, 255)
    
    # è½»å¾®æé«˜äº®åº¦
    hsv[:,:,2] = cv2.multiply(hsv[:,:,2], 1.1).clip(0, 255)
    
    result = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    
    # 4. æ·»åŠ å…‰æ™•æ•ˆæœ
    glow = cv2.GaussianBlur(result, (0, 0), 15)
    result = cv2.addWeighted(result, 0.7, glow, 0.3, 0)
    
    # 5. æ·»åŠ ç”»å¸ƒçº¹ç†
    texture = np.random.randn(height, width) * 10 + 128
    texture = np.clip(texture, 100, 150).astype(np.uint8)
    texture_bgr = cv2.cvtColor(texture, cv2.COLOR_GRAY2BGR)
    
    result = cv2.addWeighted(result, 0.95, texture_bgr, 0.05, 0)
    
    return result

def apply_picasso_cubist_style(image):
    """æ¯•åŠ ç´¢ç«‹ä½“ä¸»ä¹‰é£æ ¼"""
    height, width = image.shape[:2]
    
    # 1. åˆ†å‰²å›¾åƒä¸ºå¤šä¸ªå‡ ä½•åŒºåŸŸ
    result = np.zeros_like(image)
    
    # åˆ›å»ºç½‘æ ¼åˆ†å‰²
    grid_size = min(height, width) // 8
    
    for y in range(0, height, grid_size):
        for x in range(0, width, grid_size):
            # éšæœºå˜å½¢ç½‘æ ¼
            offset_x = random.randint(-grid_size//2, grid_size//2)
            offset_y = random.randint(-grid_size//2, grid_size//2)
            
            end_x = min(x + grid_size + offset_x, width)
            end_y = min(y + grid_size + offset_y, height)
            
            # è·å–åŒºåŸŸå¹³å‡é¢œè‰²
            region = image[max(0, y):end_y, max(0, x):end_x]
            if region.size > 0:
                avg_color = cv2.mean(region)[:3]
                
                # ç»˜åˆ¶å‡ ä½•å½¢çŠ¶
                shape_type = random.choice(['triangle', 'rectangle', 'polygon'])
                
                if shape_type == 'triangle':
                    # ç»˜åˆ¶ä¸‰è§’å½¢
                    pts = np.array([
                        [x, y],
                        [x + grid_size, y],
                        [x + grid_size//2, y + grid_size]
                    ], np.int32)
                    cv2.fillPoly(result, [pts], avg_color)
                    
                elif shape_type == 'rectangle':
                    # ç»˜åˆ¶çŸ©å½¢ï¼ˆå¯èƒ½æ—‹è½¬ï¼‰
                    angle = random.uniform(-30, 30)
                    center = (x + grid_size//2, y + grid_size//2)
                    rect = ((x + grid_size//2, y + grid_size//2), 
                           (grid_size, grid_size), angle)
                    
                    box = cv2.boxPoints(rect)
                    # ä¿®æ”¹è¿™é‡Œï¼šå°† np.int0 æ”¹ä¸º np.int32
                    box = np.int32(box)  # æˆ–è€… box.astype(np.int32)
                    cv2.fillPoly(result, [box], avg_color)
                    
                else:  # polygon
                    # ç»˜åˆ¶å¤šè¾¹å½¢
                    num_sides = random.randint(3, 6)
                    radius = grid_size // 2
                    center = (x + grid_size//2, y + grid_size//2)
                    
                    pts = []
                    for i in range(num_sides):
                        angle = 2 * np.pi * i / num_sides + random.uniform(-0.2, 0.2)
                        px = center[0] + radius * np.cos(angle)
                        py = center[1] + radius * np.sin(angle)
                        pts.append([px, py])
                    
                    pts = np.array(pts, np.int32)
                    cv2.fillPoly(result, [pts], avg_color)
    
    # 2. å¢å¼ºè¾¹ç¼˜ï¼ˆç«‹ä½“ä¸»ä¹‰çš„ç‰¹ç‚¹ï¼‰
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150)
    edges = cv2.dilate(edges, np.ones((3,3), np.uint8), iterations=1)
    
    # æ·»åŠ é»‘è‰²è½®å»“
    edges_bgr = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
    result = cv2.bitwise_and(result, cv2.bitwise_not(edges_bgr))
    
    # 3. é¢œè‰²ç®€åŒ–ï¼ˆç«‹ä½“ä¸»ä¹‰çš„æœ‰é™è‰²å½©ï¼‰
    pixels = result.reshape((-1, 3))
    pixels = np.float32(pixels)
    
    # ä½¿ç”¨K-meanså‡å°‘é¢œè‰²æ•°é‡
    k = 8
    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)
    _, labels, centers = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)
    
    centers = np.uint8(centers)
    simplified = centers[labels.flatten()]
    result = simplified.reshape(result.shape)
    
    # 4. å¢å¼ºå¯¹æ¯”åº¦
    lab = cv2.cvtColor(result, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    
    # å¢å¼ºäº®åº¦é€šé“çš„å¯¹æ¯”åº¦
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
    l = clahe.apply(l)
    
    lab = cv2.merge([l, a, b])
    result = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    
    return result

def apply_anime_style(image):
    """åŠ¨æ¼«é£æ ¼"""
    # 1. è¾¹ç¼˜æ£€æµ‹ï¼ˆç”¨äºæè¾¹ï¼‰
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # åŒè¾¹æ»¤æ³¢ä¿ç•™è¾¹ç¼˜
    filtered = cv2.bilateralFilter(image, 9, 75, 75)
    
    # ä½¿ç”¨DoGè¾¹ç¼˜æ£€æµ‹
    g1 = cv2.GaussianBlur(gray, (5, 5), 0.5)
    g2 = cv2.GaussianBlur(gray, (5, 5), 2.0)
    dog = g1 - g2
    
    # äºŒå€¼åŒ–è¾¹ç¼˜
    _, edges = cv2.threshold(dog, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    
    # ç»†åŒ–è¾¹ç¼˜
    edges = cv2.ximgproc.thinning(edges)
    
    # 2. é¢œè‰²å¹³å¦åŒ–ï¼ˆåŠ¨æ¼«çš„å¹³å¦ç€è‰²ï¼‰
    # ä½¿ç”¨å‡å€¼æ¼‚ç§»å‡å°‘é¢œè‰²å˜åŒ–
    filtered_ms = cv2.pyrMeanShiftFiltering(filtered, 20, 50)
    
    # 3. å¢å¼ºé¥±å’Œåº¦
    hsv = cv2.cvtColor(filtered_ms, cv2.COLOR_BGR2HSV)
    hsv[:,:,1] = cv2.multiply(hsv[:,:,1], 1.4).clip(0, 255)
    hsv[:,:,2] = cv2.multiply(hsv[:,:,2], 1.2).clip(0, 255)
    enhanced = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    
    # 4. æ·»åŠ é˜´å½±æ•ˆæœ
    height, width = enhanced.shape[:2]
    
    # åˆ›å»ºç®€å•å…‰æºæ•ˆæœ
    y_coords, x_coords = np.mgrid[0:height, 0:width]
    
    # ä»å·¦ä¸Šè§’çš„å…‰æº
    light_source = np.sqrt((x_coords/width)**2 + (y_coords/height)**2)
    light_source = 1 - light_source * 0.3
    
    # åº”ç”¨å…‰ç…§æ•ˆæœ
    result = enhanced.astype(np.float32) * light_source[:,:,np.newaxis]
    result = np.clip(result, 0, 255).astype(np.uint8)
    
    # 5. æ·»åŠ é»‘è‰²è½®å»“
    edges_bgr = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
    
    # è½®å»“é¢œè‰²å¯é€‰ï¼ˆé»‘è‰²æˆ–æ·±è‰²ï¼‰
    outline_color = (30, 30, 30)
    edges_colored = cv2.bitwise_and(edges_bgr, outline_color)
    
    # åº”ç”¨è½®å»“
    result = cv2.subtract(result, edges_colored)
    
    # 6. æ·»åŠ é«˜å…‰æ•ˆæœ
    # åœ¨è¾¹ç¼˜åŒºåŸŸæ·»åŠ é«˜å…‰
    highlight_mask = cv2.erode(edges, np.ones((2,2), np.uint8))
    
    # æ·»åŠ ç™½è‰²é«˜å…‰
    result = cv2.addWeighted(result, 1.0, 
                           cv2.cvtColor(highlight_mask, cv2.COLOR_GRAY2BGR), 
                           0.1, 0)
    
    return result

# 11. è€ç…§ç‰‡ä¸Šè‰²
def colorize_old_photo(image, color_intensity=1.0, ai_assist=True):
    """
    çœŸæ­£çš„é»‘ç™½ç…§ç‰‡ä¸Šè‰²å‡½æ•°
    å°†ç°åº¦å›¾åƒæ™ºèƒ½ä¸Šè‰²ä¸ºå½©è‰²
    
    å‚æ•°:
    - image: è¾“å…¥å›¾åƒï¼ˆBGRæ ¼å¼ï¼‰
    - color_intensity: è‰²å½©å¼ºåº¦ (0.5-1.5)
    - ai_assist: æ˜¯å¦ä½¿ç”¨AIè¾…åŠ©ï¼ˆç®€åŒ–ç‰ˆï¼‰
    
    è¿”å›:
    - colorized: ä¸Šè‰²åçš„å›¾åƒ
    """
    # ç¡®ä¿å›¾åƒæ˜¯BGRæ ¼å¼
    if len(image.shape) == 2:
        # å¦‚æœæ˜¯ç°åº¦å›¾ï¼Œè½¬æ¢ä¸º3é€šé“BGR
        gray = image.copy()
        image_bgr = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
    elif image.shape[2] == 4:
        # å¦‚æœæ˜¯RGBAï¼Œè½¬æ¢ä¸ºBGR
        image_bgr = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)
    else:
        image_bgr = image.copy()
    
    # ç¡®ä¿æ˜¯uint8ç±»å‹
    if image_bgr.dtype != np.uint8:
        image_bgr = image_bgr.astype(np.uint8)
    
    # 1. é¢„å¤„ç†ï¼šå¢å¼ºå¯¹æ¯”åº¦ï¼Œå»é™¤å™ªç‚¹
    # è½¬æ¢ä¸ºLABé¢œè‰²ç©ºé—´
    lab = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    
    # ä½¿ç”¨CLAHEå¢å¼ºäº®åº¦å¯¹æ¯”åº¦
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l_enhanced = clahe.apply(l)
    
    # 2. æ™ºèƒ½åŒºåŸŸæ£€æµ‹ï¼ˆç®€åŒ–ç‰ˆAIè¾…åŠ©ï¼‰
    gray_float = l_enhanced.astype(np.float32) / 255.0
    
    # æ ¹æ®äº®åº¦åˆ›å»ºåŒºåŸŸæ©ç 
    # å¤©ç©º/é«˜äº®åŒºåŸŸ
    sky_mask = (gray_float > 0.7).astype(np.uint8) * 255
    
    # åœ°é¢/ä¸­ç­‰äº®åº¦åŒºåŸŸ
    ground_mask = ((gray_float > 0.3) & (gray_float <= 0.7)).astype(np.uint8) * 255
    
    # æ¤è¢«åŒºåŸŸï¼ˆé€šè¿‡çº¹ç†æ£€æµ‹ï¼‰
    sobelx = cv2.Sobel(l_enhanced, cv2.CV_64F, 1, 0, ksize=3)
    sobely = cv2.Sobel(l_enhanced, cv2.CV_64F, 0, 1, ksize=3)
    gradient = np.sqrt(sobelx**2 + sobely**2)
    texture_mask = (gradient > np.percentile(gradient, 70)).astype(np.uint8) * 255
    
    # äººç‰©/å»ºç­‘åŒºåŸŸï¼ˆé€šè¿‡è¾¹ç¼˜æ£€æµ‹ï¼‰
    edges = cv2.Canny(l_enhanced, 50, 150)
    
    # 3. æ™ºèƒ½ä¸Šè‰²ï¼šä¸ºä¸åŒåŒºåŸŸåˆ†é…é¢œè‰²
    # åˆå§‹åŒ–å½©è‰²é€šé“ï¼ˆBGRé¡ºåºï¼‰
    colored_b = np.zeros_like(l_enhanced, dtype=np.float32)
    colored_g = np.zeros_like(l_enhanced, dtype=np.float32)
    colored_r = np.zeros_like(l_enhanced, dtype=np.float32)
    
    # åƒç´ çº§æ™ºèƒ½ä¸Šè‰²
    height, width = l_enhanced.shape
    
    for i in range(height):
        for j in range(width):
            brightness = l_enhanced[i, j] / 255.0
            
            # åŒºåŸŸåˆ¤æ–­
            is_sky = sky_mask[i, j] > 0
            is_ground = ground_mask[i, j] > 0
            is_textured = texture_mask[i, j] > 0
            has_edge = edges[i, j] > 0
            
            # æ™ºèƒ½ä¸Šè‰²è§„åˆ™
            if is_sky:
                # å¤©ç©ºï¼šè“è‰²è°ƒï¼Œäº®åº¦è¶Šé«˜è¶Šè“
                blue_intensity = 0.7 + brightness * 0.3
                green_intensity = 0.5 + brightness * 0.2
                red_intensity = 0.3 + brightness * 0.2
            elif is_textured and not has_edge:
                # æ¤è¢«ï¼šç»¿è‰²è°ƒ
                if brightness > 0.4:
                    green_intensity = 0.6 + brightness * 0.4
                    blue_intensity = 0.2 + brightness * 0.2
                    red_intensity = 0.1 + brightness * 0.2
                else:
                    # æ·±è‰²æ¤è¢«
                    green_intensity = 0.3 + brightness * 0.3
                    blue_intensity = 0.1 + brightness * 0.2
                    red_intensity = 0.05 + brightness * 0.1
            elif has_edge and brightness > 0.5:
                # å»ºç­‘/äººç‰©è¾¹ç¼˜ï¼šæš–è‰²è°ƒ
                red_intensity = 0.6 + brightness * 0.4
                green_intensity = 0.5 + brightness * 0.3
                blue_intensity = 0.3 + brightness * 0.2
            elif is_ground:
                # åœ°é¢ï¼šåœŸé»„è‰²è°ƒ
                red_intensity = 0.5 + brightness * 0.3
                green_intensity = 0.4 + brightness * 0.3
                blue_intensity = 0.2 + brightness * 0.2
            else:
                # é»˜è®¤ï¼šæ ¹æ®äº®åº¦è°ƒæ•´é¢œè‰²
                if brightness > 0.7:
                    # é«˜äº®åŒºåŸŸï¼šæµ…é»„è‰²
                    red_intensity = 0.8 + brightness * 0.2
                    green_intensity = 0.7 + brightness * 0.2
                    blue_intensity = 0.5 + brightness * 0.2
                elif brightness > 0.4:
                    # ä¸­ç­‰äº®åº¦ï¼šä¸­æ€§è‰²
                    red_intensity = 0.5 + brightness * 0.3
                    green_intensity = 0.5 + brightness * 0.3
                    blue_intensity = 0.5 + brightness * 0.3
                else:
                    # æš—éƒ¨ï¼šå†·è‰²è°ƒ
                    red_intensity = 0.2 + brightness * 0.2
                    green_intensity = 0.3 + brightness * 0.2
                    blue_intensity = 0.4 + brightness * 0.3
            
            # åº”ç”¨é¢œè‰²å¼ºåº¦
            colored_r[i, j] = red_intensity * brightness * 255 * color_intensity
            colored_g[i, j] = green_intensity * brightness * 255 * color_intensity
            colored_b[i, j] = blue_intensity * brightness * 255 * color_intensity
    
    # 4. åˆå¹¶å½©è‰²é€šé“
    colored_r = np.clip(colored_r, 0, 255).astype(np.uint8)
    colored_g = np.clip(colored_g, 0, 255).astype(np.uint8)
    colored_b = np.clip(colored_b, 0, 255).astype(np.uint8)
    
    colorized = cv2.merge([colored_b, colored_g, colored_r])
    
    # 5. åå¤„ç†ï¼šé¢œè‰²æ··åˆå’Œå¢å¼º
    # å°†åŸå§‹äº®åº¦ä¸é¢œè‰²æ··åˆ
    colored_lab = cv2.cvtColor(colorized, cv2.COLOR_BGR2LAB)
    cl, ca, cb = cv2.split(colored_lab)
    
    # ä¿æŒåŸå§‹äº®åº¦ï¼Œåªä½¿ç”¨ä¸Šè‰²çš„è‰²åº¦ä¿¡æ¯
    result_lab = cv2.merge([l_enhanced, ca, cb])
    result = cv2.cvtColor(result_lab, cv2.COLOR_LAB2BGR)
    
    # 6. æ·»åŠ å¤å¤æ•ˆæœ
    # è½»å¾®æš–è‰²è°ƒæ»¤é•œ
    warm_filter = np.array([
        [1.1, 0.0, 0.0],
        [0.0, 0.9, 0.0],
        [0.0, 0.0, 0.8]
    ], dtype=np.float32)
    
    warm_result = cv2.transform(result, warm_filter)
    warm_result = np.clip(warm_result, 0, 255).astype(np.uint8)
    
    # æ··åˆï¼š80%ä¸Šè‰² + 20%æ€€æ—§æš–è‰²
    final = cv2.addWeighted(result, 0.8, warm_result, 0.2, 0)
    
    # 7. é¢œè‰²è°ƒæ•´å’Œå¢å¼º
    hsv = cv2.cvtColor(final, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    
    # å¢åŠ é¥±å’Œåº¦
    s_enhanced = cv2.multiply(s, color_intensity).clip(0, 255)
    
    # ç¨å¾®è°ƒæ•´è‰²è°ƒï¼Œä½¿å…¶æ›´è‡ªç„¶
    h_enhanced = h.copy()
    h_shift = 5  # è½»å¾®è‰²è°ƒåç§»
    h_enhanced = (h_enhanced + h_shift) % 180
    
    # åˆå¹¶HSV
    hsv_enhanced = cv2.merge([h_enhanced, s_enhanced, v])
    final_enhanced = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)
    
    # 8. æ·»åŠ è½»å¾®èƒ¶ç‰‡é¢—ç²’æ•ˆæœï¼ˆå¯é€‰ï¼‰
    if ai_assist:
        # æ·»åŠ è½»å¾®çš„å™ªç‚¹æ¨¡æ‹Ÿèƒ¶ç‰‡é¢—ç²’
        noise = np.random.normal(0, 2, final_enhanced.shape).astype(np.int16)
        final_with_noise = cv2.add(final_enhanced.astype(np.int16), noise)
        final_enhanced = np.clip(final_with_noise, 0, 255).astype(np.uint8)
    
    # 9. æœ€åè½»å¾®æ¨¡ç³Šï¼Œä½¿é¢œè‰²è¿‡æ¸¡æ›´è‡ªç„¶
    final_enhanced = cv2.GaussianBlur(final_enhanced, (3, 3), 0.5)
    
    return final_enhanced

def apply_deep_learning_colorization(image):
    """
    æ·±åº¦å­¦ä¹ é£æ ¼çš„ä¸Šè‰²ï¼ˆç®€åŒ–ç‰ˆï¼‰
    ä½¿ç”¨é¢„è®­ç»ƒçš„è§„åˆ™æ¨¡æ‹Ÿæ·±åº¦å­¦ä¹ æ•ˆæœ
    """
    # å…ˆä½¿ç”¨åŸºç¡€çš„ä¸Šè‰²
    base_colorized = colorize_old_photo(image)
    
    # å¢åŠ é¢œè‰²ä¸°å¯Œåº¦
    hsv = cv2.cvtColor(base_colorized, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    
    # æ·±åº¦å­¦ä¹ é£æ ¼é€šå¸¸é¢œè‰²æ›´é²œè‰³
    s = cv2.multiply(s, 1.3).clip(0, 255)
    
    # ç¨å¾®é™ä½äº®åº¦ï¼Œå¢åŠ å¯¹æ¯”åº¦
    v = cv2.convertScaleAbs(v, alpha=1.1, beta=-20)
    
    # è‰²è°ƒå¾®è°ƒ
    h_shifted = (h + 10) % 180  # ç¨å¾®è°ƒæ•´è‰²è°ƒ
    
    hsv_enhanced = cv2.merge([h_shifted, s, v])
    result = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)
    
    return result

def apply_selective_colorization(image, focus_areas='auto'):
    """
    é€‰æ‹©æ€§ç„¦ç‚¹ä¸Šè‰²
    focus_areas: 'auto', 'center', 'faces', 'full'
    """
    base_colorized = colorize_old_photo(image)
    
    if focus_areas == 'full':
        return base_colorized
    
    # åˆ›å»ºç°åº¦ç‰ˆæœ¬
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    if len(gray.shape) == 2:
        gray_bgr = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
    else:
        gray_bgr = gray
    
    # åˆ›å»ºç„¦ç‚¹æ©ç 
    height, width = image.shape[:2]
    mask = np.zeros((height, width), dtype=np.uint8)
    
    if focus_areas == 'center':
        # ä¸­å¿ƒåŒºåŸŸä¸Šè‰²
        center_x, center_y = width // 2, height // 2
        radius = min(width, height) // 3
        cv2.circle(mask, (center_x, center_y), radius, 255, -1)
    elif focus_areas == 'auto':
        # è‡ªåŠ¨æ£€æµ‹é‡è¦åŒºåŸŸï¼ˆåŸºäºè¾¹ç¼˜å¯†åº¦ï¼‰
        edges = cv2.Canny(gray, 50, 150)
        
        # ä½¿ç”¨å½¢æ€å­¦æ“ä½œæ‰¾åˆ°è¾¹ç¼˜å¯†é›†åŒºåŸŸ
        kernel = np.ones((15, 15), np.uint8)
        edges_dilated = cv2.dilate(edges, kernel, iterations=1)
        
        # æ‰¾åˆ°è½®å»“
        contours, _ = cv2.findContours(edges_dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # ç»˜åˆ¶ä¸»è¦åŒºåŸŸ
        for contour in contours:
            area = cv2.contourArea(contour)
            if area > (width * height * 0.01):  # åªå¤„ç†è¶³å¤Ÿå¤§çš„åŒºåŸŸ
                cv2.drawContours(mask, [contour], -1, 255, -1)
    else:  # faces
        # äººè„¸æ£€æµ‹ï¼ˆéœ€è¦OpenCVçš„äººè„¸æ£€æµ‹å™¨ï¼‰
        try:
            # è½¬æ¢ä¸ºç°åº¦è¿›è¡Œäººè„¸æ£€æµ‹
            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            faces = face_cascade.detectMultiScale(gray, 1.1, 4)
            
            for (x, y, w, h) in faces:
                cv2.rectangle(mask, (x, y), (x+w, y+h), 255, -1)
        except:
            # å¦‚æœäººè„¸æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨ä¸­å¿ƒåŒºåŸŸ
            center_x, center_y = width // 2, height // 2
            radius = min(width, height) // 4
            cv2.circle(mask, (center_x, center_y), radius, 255, -1)
    
    # æ¨¡ç³Šæ©ç è¾¹ç¼˜ï¼Œä½¿è¿‡æ¸¡æ›´å¹³æ»‘
    mask = cv2.GaussianBlur(mask, (31, 31), 0)
    mask = mask.astype(np.float32) / 255.0
    mask = cv2.merge([mask, mask, mask])
    
    # æ··åˆå½©è‰²å’Œç°åº¦ç‰ˆæœ¬
    result = cv2.addWeighted(base_colorized.astype(np.float32), mask, 
                             gray_bgr.astype(np.float32), 1.0 - mask, 0)
    result = np.clip(result, 0, 255).astype(np.uint8)
    
    return result

def apply_erosion(image, kernel_size=3):
    """è…èš€æ“ä½œï¼ˆå¢å¼ºç‰ˆï¼‰"""
    # ä½¿ç”¨æ¤­åœ†æ ¸é€šå¸¸æ•ˆæœæ›´å¥½
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
    
    # å¯¹äºå°ç‰©ä½“å»é™¤ï¼Œå…ˆè¿›è¡Œè…èš€
    eroded = cv2.erode(image, kernel, iterations=1)
    
    # å¦‚æœå›¾åƒæ˜¯å½©è‰²çš„ï¼Œå¯¹æ¯ä¸ªé€šé“åˆ†åˆ«å¤„ç†ï¼ˆå¯é€‰ï¼‰
    if len(image.shape) == 3:
        # åˆ†ç¦»é€šé“å¤„ç†
        channels = cv2.split(eroded)
        processed_channels = []
        for channel in channels:
            # å¯¹æ¯ä¸ªé€šé“åº”ç”¨è½»åº¦è…èš€
            processed = cv2.erode(channel, kernel, iterations=1)
            processed_channels.append(processed)
        
        # åˆå¹¶é€šé“
        eroded = cv2.merge(processed_channels)
    
    return eroded

def apply_dilation(image, kernel_size=3):
    """è†¨èƒ€æ“ä½œï¼ˆå¢å¼ºç‰ˆï¼‰"""
    # ä½¿ç”¨æ¤­åœ†æ ¸æ•ˆæœæ›´è‡ªç„¶
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
    
    # å¯¹äºè¿æ¥æ–­è£‚ï¼Œå…ˆè¿›è¡Œè†¨èƒ€
    dilated = cv2.dilate(image, kernel, iterations=1)
    
    # å¦‚æœå›¾åƒæ˜¯å½©è‰²çš„ï¼Œå¯ä»¥å¢å¼ºè¾¹ç¼˜æ•ˆæœ
    if len(image.shape) == 3:
        # è½¬æ¢ä¸ºHSVï¼Œå¢å¼ºVé€šé“
        hsv = cv2.cvtColor(dilated, cv2.COLOR_BGR2HSV)
        h, s, v = cv2.split(hsv)
        
        # å¯¹äº®åº¦é€šé“è¿›è¡Œé¢å¤–è†¨èƒ€ï¼ˆå¢å¼ºæ•ˆæœï¼‰
        v = cv2.dilate(v, kernel, iterations=1)
        
        # åˆå¹¶å¹¶è½¬æ¢å›BGR
        hsv = cv2.merge([h, s, v])
        dilated = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    
    return dilated

def apply_opening(image, kernel_size=3):
    """å¼€è¿ç®—ï¼ˆå¢å¼ºç‰ˆï¼‰- å»é™¤å°ç‰©ä½“"""
    # ä½¿ç”¨æ¤­åœ†æ ¸ï¼Œæ•ˆæœæ¯”çŸ©å½¢æ ¸æ›´å¹³æ»‘
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
    
    # æ ‡å‡†å¼€è¿ç®—
    opened = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)
    
    # å¦‚æœå›¾åƒæ˜¯ç°åº¦å›¾ï¼Œå¯ä»¥æ·»åŠ å¯¹æ¯”åº¦å¢å¼º
    if len(image.shape) == 2:
        # å¯¹å¼€è¿ç®—åçš„å›¾åƒè¿›è¡Œç›´æ–¹å›¾å‡è¡¡åŒ–
        opened = cv2.equalizeHist(opened)
    elif len(image.shape) == 3:
        # å¯¹å½©è‰²å›¾åƒï¼Œå¢å¼ºè¾¹ç¼˜å¯¹æ¯”åº¦
        edges = cv2.Canny(opened, 50, 150)
        edges_colored = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
        
        # å°†è¾¹ç¼˜å åŠ åˆ°å¼€è¿ç®—ç»“æœä¸Š
        opened = cv2.addWeighted(opened, 0.8, edges_colored, 0.2, 0)
    
    return opened

def apply_closing(image, kernel_size=3):
    """é—­è¿ç®—ï¼ˆå¢å¼ºç‰ˆï¼‰- å¡«å……å°å­”æ´"""
    # ä½¿ç”¨æ¤­åœ†æ ¸
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
    
    # æ ‡å‡†é—­è¿ç®—
    closed = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)
    
    # å¢å¼ºæ•ˆæœï¼šå¦‚æœå›¾åƒæ˜¯äºŒå€¼å›¾ï¼Œå¯ä»¥ä¼˜åŒ–
    if len(image.shape) == 2:
        # é—­è¿ç®—åå¯èƒ½è¿˜æœ‰å°å­”æ´ï¼Œè¿›è¡Œå¡«å……
        contours, _ = cv2.findContours(closed, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
        for contour in contours:
            area = cv2.contourArea(contour)
            if area < 50:  # å¡«å……å°å­”æ´
                cv2.drawContours(closed, [contour], 0, 255, -1)
    
    return closed

def provide_download_button(image_rgb, filename, button_text, unique_key_suffix=""):
    """
    æä¾›ä¸‹è½½æŒ‰é’® - ä¸“é—¨ç”¨äºRGBå›¾åƒ
    
    Args:
        image_rgb: RGBæ ¼å¼çš„å›¾åƒæ•°ç»„
        filename: ä¸‹è½½æ–‡ä»¶å
        button_text: æŒ‰é’®æ–‡æœ¬
        unique_key_suffix: å”¯ä¸€keyåç¼€ï¼Œé˜²æ­¢é‡å¤ID
    """
    try:
        # ç¡®ä¿å›¾åƒæ˜¯RGBæ ¼å¼
        if len(image_rgb.shape) != 3 or image_rgb.shape[2] != 3:
            raise ValueError("å›¾åƒå¿…é¡»æ˜¯RGBæ ¼å¼ (H,W,3)")
        
        # è½¬æ¢ä¸ºPILå›¾åƒ
        image_pil = Image.fromarray(image_rgb)
        
        # ä¿å­˜åˆ°å­—èŠ‚æµ
        buffered = io.BytesIO()
        image_pil.save(buffered, format="JPEG", quality=95)
        
        # ç”Ÿæˆå”¯ä¸€key
        import time
        import hashlib
        timestamp = int(time.time() * 1000)
        
        # ä½¿ç”¨å›¾åƒå†…å®¹å“ˆå¸Œå’Œå½“å‰æ—¶é—´ç”Ÿæˆå”¯ä¸€key
        image_hash = hashlib.md5(image_rgb.tobytes()).hexdigest()[:8]
        unique_key = f"download_{filename}_{image_hash}_{timestamp}_{unique_key_suffix}"
        
        # ä¸‹è½½æŒ‰é’®
        st.download_button(
            label=button_text,
            data=buffered.getvalue(),
            file_name=filename,
            mime="image/jpeg",
            use_container_width=True,
            key=unique_key
        )
        
    except Exception as e:
        st.error(f"ä¸‹è½½åŠŸèƒ½å‡ºé”™: {str(e)}")

def create_color_histogram(image_rgb, title="é¢œè‰²ç›´æ–¹å›¾"):
    """
    åˆ›å»ºRGBé¢œè‰²ç›´æ–¹å›¾å¹¶è¿”å›Matplotlibå›¾å½¢
    
    Args:
        image_rgb: RGBæ ¼å¼çš„å›¾åƒæ•°ç»„ï¼ˆæˆ–ç°åº¦å›¾ï¼‰
        title: ç›´æ–¹å›¾æ ‡é¢˜
    
    Returns:
        fig: Matplotlibå›¾å½¢å¯¹è±¡
    """
    # æ£€æŸ¥å›¾åƒç»´åº¦
    if len(image_rgb.shape) == 2:
        # ç°åº¦å›¾åƒ
        gray_channel = image_rgb
        
        # åˆ›å»ºå›¾å½¢
        fig, ax = plt.subplots(figsize=(10, 4))
        
        # è®¡ç®—ç›´æ–¹å›¾
        hist_gray = cv2.calcHist([gray_channel], [0], None, [256], [0, 256])
        
        # å½’ä¸€åŒ–ä»¥ä¾¿æ¯”è¾ƒ
        hist_gray = cv2.normalize(hist_gray, hist_gray, 0, 1, cv2.NORM_MINMAX)
        
        # ç»˜åˆ¶ç›´æ–¹å›¾ï¼ˆç°è‰²ï¼‰
        ax.plot(hist_gray, color='gray', label='Gray', alpha=0.7, linewidth=2)
        
        # è®¾ç½®å›¾å½¢å±æ€§
        ax.set_title(title, fontsize=14, fontweight='bold', color='#333')
        ax.set_xlabel('åƒç´ å¼ºåº¦', fontsize=12)
        ax.set_ylabel('å½’ä¸€åŒ–é¢‘ç‡', fontsize=12)
        ax.grid(True, alpha=0.3)
        ax.legend()
        
    elif len(image_rgb.shape) == 3:
        # å½©è‰²å›¾åƒ
        # åˆ†ç¦»RGBé€šé“
        r_channel = image_rgb[:,:,0]
        g_channel = image_rgb[:,:,1]
        b_channel = image_rgb[:,:,2]
        
        # åˆ›å»ºå›¾å½¢
        fig, ax = plt.subplots(figsize=(10, 4))
        
        # è®¡ç®—ç›´æ–¹å›¾
        hist_r = cv2.calcHist([r_channel], [0], None, [256], [0, 256])
        hist_g = cv2.calcHist([g_channel], [0], None, [256], [0, 256])
        hist_b = cv2.calcHist([b_channel], [0], None, [256], [0, 256])
        
        # å½’ä¸€åŒ–ä»¥ä¾¿æ¯”è¾ƒ
        hist_r = cv2.normalize(hist_r, hist_r, 0, 1, cv2.NORM_MINMAX)
        hist_g = cv2.normalize(hist_g, hist_g, 0, 1, cv2.NORM_MINMAX)
        hist_b = cv2.normalize(hist_b, hist_b, 0, 1, cv2.NORM_MINMAX)
        
        # ç»˜åˆ¶ç›´æ–¹å›¾
        ax.plot(hist_r, color='red', label='Red', alpha=0.7, linewidth=2)
        ax.plot(hist_g, color='green', label='Green', alpha=0.7, linewidth=2)
        ax.plot(hist_b, color='blue', label='Blue', alpha=0.7, linewidth=2)
        
        # è®¾ç½®å›¾å½¢å±æ€§
        ax.set_title(title, fontsize=14, fontweight='bold', color='#333')
        ax.set_xlabel('åƒç´ å¼ºåº¦', fontsize=12)
        ax.set_ylabel('å½’ä¸€åŒ–é¢‘ç‡', fontsize=12)
        ax.grid(True, alpha=0.3)
        ax.legend()
    
    else:
        # æœªçŸ¥æ ¼å¼
        fig, ax = plt.subplots(figsize=(10, 4))
        ax.text(0.5, 0.5, 'æ— æ³•ç”Ÿæˆç›´æ–¹å›¾\nå›¾åƒæ ¼å¼ä¸æ”¯æŒ', 
                horizontalalignment='center', verticalalignment='center',
                transform=ax.transAxes, fontsize=12, color='red')
        ax.set_title(title, fontsize=14, fontweight='bold', color='#333')
    
    # è®¾ç½®èƒŒæ™¯è‰²
    fig.patch.set_facecolor('#f8f9fa')
    if 'ax' in locals():
        ax.set_facecolor('#ffffff')
    
    return fig

def display_comparison_with_histograms(original_rgb, processed_rgb, original_title="åŸå§‹å›¾åƒ", processed_title="å¤„ç†ç»“æœ"):
    """
    æ˜¾ç¤ºå›¾åƒå¯¹æ¯”å’Œç›´æ–¹å›¾å¯¹æ¯”
    
    Args:
        original_rgb: åŸå§‹RGBå›¾åƒï¼ˆæˆ–ç°åº¦å›¾ï¼‰
        processed_rgb: å¤„ç†åçš„RGBå›¾åƒï¼ˆæˆ–ç°åº¦å›¾ï¼‰
        original_title: åŸå§‹å›¾åƒæ ‡é¢˜
        processed_title: å¤„ç†åå›¾åƒæ ‡é¢˜
    """
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns(2)
    
    with col1:
        # åŸå§‹å›¾åƒ
        st.markdown(f'<h4 style="text-align: center;">{original_title}</h4>', unsafe_allow_html=True)
        
        # æ£€æŸ¥å›¾åƒç»´åº¦å¹¶æ­£ç¡®æ˜¾ç¤º
        if len(original_rgb.shape) == 2:
            # ç°åº¦å›¾åƒ
            st.image(original_rgb, use_container_width=True, clamp=True)
        else:
            # å½©è‰²å›¾åƒ
            st.image(original_rgb, use_container_width=True)
        
        # åŸå§‹å›¾åƒç›´æ–¹å›¾
        with st.expander("ğŸ“Š åŸå§‹å›¾åƒé¢œè‰²ç›´æ–¹å›¾", expanded=True):
            fig_orig = create_color_histogram(original_rgb, "åŸå§‹å›¾åƒé¢œè‰²åˆ†å¸ƒ")
            st.pyplot(fig_orig)
    
    with col2:
        # å¤„ç†åçš„å›¾åƒ
        st.markdown(f'<h4 style="text-align: center;">{processed_title}</h4>', unsafe_allow_html=True)
        
        # æ£€æŸ¥å›¾åƒç»´åº¦å¹¶æ­£ç¡®æ˜¾ç¤º
        if len(processed_rgb.shape) == 2:
            # ç°åº¦å›¾åƒ
            st.image(processed_rgb, use_container_width=True, clamp=True)
        else:
            # å½©è‰²å›¾åƒ
            st.image(processed_rgb, use_container_width=True)
        
        # å¤„ç†åå›¾åƒç›´æ–¹å›¾
        with st.expander("ğŸ“Š å¤„ç†åå›¾åƒé¢œè‰²ç›´æ–¹å›¾", expanded=True):
            fig_proc = create_color_histogram(processed_rgb, "å¤„ç†åå›¾åƒé¢œè‰²åˆ†å¸ƒ")
            st.pyplot(fig_proc)
    
    # åˆ†å‰²çº¿
    st.markdown("---")

def display_comparison_with_histograms(original_rgb, processed_rgb, original_title="åŸå§‹å›¾åƒ", processed_title="å¤„ç†ç»“æœ"):
    """
    æ˜¾ç¤ºå›¾åƒå¯¹æ¯”å’Œç›´æ–¹å›¾å¯¹æ¯”
    
    Args:
        original_rgb: åŸå§‹RGBå›¾åƒ
        processed_rgb: å¤„ç†åçš„RGBå›¾åƒ
        original_title: åŸå§‹å›¾åƒæ ‡é¢˜
        processed_title: å¤„ç†åå›¾åƒæ ‡é¢˜
    """
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns(2)
    
    with col1:
        # åŸå§‹å›¾åƒ
        st.markdown(f'<h4 style="text-align: center;">{original_title}</h4>', unsafe_allow_html=True)
        st.image(original_rgb, use_container_width=True)
        
        # åŸå§‹å›¾åƒç›´æ–¹å›¾
        with st.expander("ğŸ“Š åŸå§‹å›¾åƒé¢œè‰²ç›´æ–¹å›¾", expanded=True):
            fig_orig = create_color_histogram(original_rgb, "åŸå§‹å›¾åƒé¢œè‰²åˆ†å¸ƒ")
            st.pyplot(fig_orig)
    
    with col2:
        # å¤„ç†åçš„å›¾åƒ
        st.markdown(f'<h4 style="text-align: center;">{processed_title}</h4>', unsafe_allow_html=True)
        st.image(processed_rgb, use_container_width=True)
        
        # å¤„ç†åå›¾åƒç›´æ–¹å›¾
        with st.expander("ğŸ“Š å¤„ç†åå›¾åƒé¢œè‰²ç›´æ–¹å›¾", expanded=True):
            fig_proc = create_color_histogram(processed_rgb, "å¤„ç†åå›¾åƒé¢œè‰²åˆ†å¸ƒ")
            st.pyplot(fig_proc)
    
    # åˆ†å‰²çº¿
    st.markdown("---")

# ======================= ä¾§è¾¹æ æ¸²æŸ“ =======================
def render_sidebar():
    with st.sidebar:
        st.markdown("""
        <div style='background: linear-gradient(135deg, #dc2626, #b91c1c); color: white; 
                    padding: 25px; border-radius: 15px; text-align: center; margin-bottom: 25px;
                    box-shadow: 0 6px 12px rgba(220, 38, 38, 0.3); border: 2px solid #f59e0b;'>
            <h3 style='margin: 0;'>ğŸ”¬ å›¾åƒå¤„ç†å®éªŒå®¤</h3>
            <p style='margin: 10px 0 0 0;'>æŠ€æœ¯æŠ¥å›½ Â· åˆ›æ–°å‘å±• Â· æ€æ”¿å¼•é¢†</p>
        </div>
        """, unsafe_allow_html=True)
        
        # å¿«é€Ÿå¯¼èˆª
        st.markdown("### ğŸ§­ å¿«é€Ÿå¯¼èˆª")
        
        # ä¿®å¤å¯¼èˆªæŒ‰é’®
        if st.button("ğŸ  è¿”å›é¦–é¡µ", use_container_width=True):
            st.switch_page("main.py")
        if st.button("ğŸ”¬ å›¾åƒå¤„ç†å®éªŒå®¤", use_container_width=True):
            st.switch_page("pages/1_ğŸ”¬_å›¾åƒå¤„ç†å®éªŒå®¤.py")
        if st.button("ğŸ“ æ™ºèƒ½ä¸ä¼ ç»Ÿå›¾ç‰‡å¤„ç†", use_container_width=True):
            # ä½¿ç”¨JavaScriptåœ¨æ–°æ ‡ç­¾é¡µæ‰“å¼€é“¾æ¥
            st.switch_page("pages/æ™ºèƒ½ä¸ä¼ ç»Ÿå›¾ç‰‡å¤„ç†.py")
        if st.button("ğŸ“¤ å®éªŒä½œä¸šæäº¤", use_container_width=True):
            st.switch_page("pages/å®éªŒä½œä¸šæäº¤.py")
        if st.button("ğŸ“š å­¦ä¹ èµ„æºä¸­å¿ƒ", use_container_width=True):
            st.switch_page("pages/2_ğŸ“š_å­¦ä¹ èµ„æºä¸­å¿ƒ.py")
        if st.button("ğŸ“ æˆ‘çš„æ€æ”¿è¶³è¿¹", use_container_width=True):
            st.switch_page("pages/3_ğŸ“_æˆ‘çš„æ€æ”¿è¶³è¿¹.py")
        if st.button("ğŸ† æˆæœå±•ç¤º", use_container_width=True):
            st.switch_page("pages/4_ğŸ†_æˆæœå±•ç¤º.py")
        
        # æ€æ”¿å­¦ä¹ è¿›åº¦
        st.markdown("### ğŸ“š æ€æ”¿å­¦ä¹ è¿›åº¦")
        
        ideology_progress = [
            {"name": "å·¥åŒ ç²¾ç¥", "icon": "ğŸ”§", "progress": 85},
            {"name": "ç§‘å­¦æ€åº¦", "icon": "ğŸ”¬", "progress": 78},
            {"name": "åˆ›æ–°æ„è¯†", "icon": "ğŸ’¡", "progress": 82},
            {"name": "è´£ä»»æ‹…å½“", "icon": "âš–ï¸", "progress": 88}
        ]
        
        for item in ideology_progress:
            st.markdown(f"**{item['icon']} {item['name']}**")
            st.progress(item['progress'] / 100)
        
        st.markdown("---")
        
        # å®éªŒæŒ‡å—
        st.markdown("""
        <div class='info-card'>
            <h4>ğŸ“š å®éªŒæŒ‡å—</h4>
            <ol style='padding-left: 20px;'>
                <li>é€‰æ‹©å®éªŒæ¨¡å—</li>
                <li>ä¸Šä¼ å›¾åƒæ–‡ä»¶</li>
                <li>è°ƒæ•´å¤„ç†å‚æ•°</li>
                <li>æŸ¥çœ‹å®æ—¶æ•ˆæœ</li>
                <li>è®°å½•å­¦ä¹ æ„Ÿæ‚Ÿ</li>
            </ol>
            <p><strong>æ”¯æŒæ ¼å¼ï¼š</strong> JPG, PNG, JPEG, PDF, DOC, DOCX, ZIP</p>
        </div>
        """, unsafe_allow_html=True)
        # æ€æ”¿ç†è®ºå­¦ä¹ 
        st.markdown("### ğŸ¯ æ€æ”¿ç†è®ºå­¦ä¹ ")
        theory_topics = [
            "å›¾åƒå¤„ç†ä¸­çš„å·¥åŒ ç²¾ç¥",
            "ç§‘æŠ€åˆ›æ–°ä¸å›½å®¶å‘å±•",
            "æŠ€æœ¯ä¼¦ç†ä¸ç¤¾ä¼šè´£ä»»",
            "ç§‘å­¦å®¶ç²¾ç¥ä¼ æ‰¿"
        ]
        
        for topic in theory_topics:
            if st.button(f"ğŸ“– {topic}", key=f"theory_{topic}", use_container_width=True):
                st.info(f"å¼€å§‹å­¦ä¹ ï¼š{topic}")
        
        st.markdown("---")
        # æ€æ”¿æ•™è‚²æç¤º
        st.markdown("""
        <div class='ideology-card'>
            <h5>ğŸ’¡ æ€æ”¿æ•™è‚²æç¤º</h5>
            <p style='font-size: 0.9rem;'>åœ¨æŠ€æœ¯å­¦ä¹ ä¸­åŸ¹å…»ï¼š</p>
            <ul style='padding-left: 15px; font-size: 0.85rem;'>
                <li>ğŸ¯ ç²¾ç›Šæ±‚ç²¾çš„å·¥åŒ ç²¾ç¥</li>
                <li>ğŸ”¬ å®äº‹æ±‚æ˜¯çš„ç§‘å­¦æ€åº¦</li>
                <li>ğŸ’¡ åˆ›æ–°å‘å±•çš„æ—¶ä»£æ‹…å½“</li>
                <li>ğŸ‡¨ğŸ‡³ ç§‘æŠ€æŠ¥å›½çš„å®¶å›½æƒ…æ€€</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)      
        # ç³»ç»Ÿä¿¡æ¯
        st.markdown("---")
        st.markdown("**ğŸ“Š ç³»ç»Ÿä¿¡æ¯**")
        st.text(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        st.text("çŠ¶æ€: ğŸŸ¢ æ­£å¸¸è¿è¡Œ")
        st.text("ç‰ˆæœ¬: v3.0.0")
        st.text(f"æ¨¡å—æ•°: 13ä¸ª")

# ======================= ä¸»ç•Œé¢ =======================
# å®éªŒå®¤å¤´éƒ¨
st.markdown("""
<div class='lab-header'>
    <h1 class='lab-title'>ğŸ”¬ æ•°å­—å›¾åƒå¤„ç†å®éªŒå®¤</h1>
    <p style='font-size: 1.3rem; opacity: 0.95;'>èåˆç°ä»£åŒ–å›¾åƒå¤„ç†å®è·µå¹³å° Â· è·µè¡Œå·¥åŒ ç²¾ç¥ Â· åŸ¹å…»ç§‘å­¦ç´ å…»</p>
    <p style='font-size: 1.1rem; margin-top: 10px; opacity: 0.8;'>13å¤§å›¾åƒå¤„ç†æ¨¡å— Â· æ€æ”¿èåˆæ•™å­¦</p>
</div>
""", unsafe_allow_html=True)

# æ¸²æŸ“ä¾§è¾¹æ 
render_sidebar()

# åˆ›å»º13ä¸ªé€‰é¡¹å¡
tab_names = [
    "ğŸ”¬ å›¾åƒå¢å¼º", 
    "ğŸ“ è¾¹ç¼˜æ£€æµ‹", 
    "ğŸ”„ çº¿æ€§å˜æ¢", 
    "âœ¨ å›¾åƒé”åŒ–",
    "ğŸ“Š é‡‡æ ·ä¸é‡åŒ–",
    "ğŸ¨ å½©è‰²å›¾åƒåˆ†å‰²",
    "ğŸŒˆ é¢œè‰²é€šé“åˆ†æ",
    "ğŸ­ ç‰¹æ•ˆå¤„ç†",
    "ğŸ¨ å›¾åƒç»˜ç”»",
    "ğŸŒŸ é£æ ¼è¿ç§»",
    "ğŸ–¼ï¸ è€ç…§ç‰‡ä¸Šè‰²",
    "âš™ï¸ æ•°å­—å½¢æ€å­¦"
]

tabs = st.tabs(tab_names)

# å…¨å±€å›¾åƒä¸Šä¼ å™¨
uploaded_file = None
if 'current_image' not in st.session_state:
    st.session_state.current_image = None

def load_and_display_image(uploaded_file, tab_key):
    """é€šç”¨å‡½æ•°ï¼šåŠ è½½å¹¶æ˜¾ç¤ºå›¾åƒ"""
    if uploaded_file is not None:
        try:
            # è¯»å–å›¾åƒæ–‡ä»¶
            image_bytes = uploaded_file.read()
            nparr = np.frombuffer(image_bytes, np.uint8)
            
            # ä½¿ç”¨OpenCVè¯»å–å›¾åƒ
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if image is None:
                st.error("æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶ï¼Œè¯·ç¡®ä¿æ˜¯æœ‰æ•ˆçš„å›¾åƒæ ¼å¼")
                return None
            
            # ä¿å­˜åˆ°session state
            st.session_state[f'image_{tab_key}'] = image
            
            # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤ºï¼ˆStreamlitä½¿ç”¨RGBï¼‰
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            return image, image_rgb
            
        except Exception as e:
            st.error(f"åŠ è½½å›¾åƒæ—¶å‡ºé”™: {str(e)}")
            return None
    return None


# 1. å›¾åƒå¢å¼ºé€‰é¡¹å¡
with tabs[0]:
    st.markdown("### ğŸ”¬ å›¾åƒå¢å¼ºå¤„ç†")
    
    st.markdown("""
    <div class='ideology-card'>
        <h4>ğŸ¯ æ€æ”¿å…³è”ï¼šç²¾ç›Šæ±‚ç²¾çš„å·¥åŒ ç²¾ç¥</h4>
        <p>
        å›¾åƒå¢å¼ºæŠ€æœ¯ä½“ç°äº†<strong style='color: #dc2626;'>ç²¾ç›Šæ±‚ç²¾</strong>çš„å·¥åŒ ç²¾ç¥ï¼Œ
        é€šè¿‡ä¸æ–­ä¼˜åŒ–ç»†èŠ‚ï¼Œè¿½æ±‚æ›´é«˜è´¨é‡çš„å›¾åƒæ•ˆæœï¼Œè¿™æ­£ä½“ç°äº†ç¤¾ä¼šä¸»ä¹‰æ ¸å¿ƒä»·å€¼è§‚ä¸­çš„<strong style='color: #dc2626;'>æ•¬ä¸š</strong>ç²¾ç¥ã€‚
        åœ¨æŠ€æœ¯å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬è¦å‘æ‰¬è¿™ç§ä¸€ä¸ä¸è‹Ÿã€è¿½æ±‚å“è¶Šçš„ç²¾ç¥å“è´¨ã€‚
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # ===== åŒåˆ—å¸ƒå±€ï¼šå·¦ä¾§ä¸Šä¼ ï¼Œå³ä¾§ç´ æåº“ =====
    col_upload1, col_upload2 = st.columns(2)
    
    uploaded_file = None
    
    with col_upload1:
        uploaded_file = st.file_uploader(
            "ğŸ“¤ ä¸Šä¼ å›¾åƒæ–‡ä»¶", 
            type=["jpg", "jpeg", "png", "bmp", "webp"], 
            key="tab1_upload"
        )
    
    with col_upload2:
        # ç´ æåº“é€‰æ‹©
        example_files = get_example_images()
        
        if example_files:
            selected_example = st.selectbox(
                "ğŸ“š ä»ç´ æåº“é€‰æ‹©",
                ["-- è¯·é€‰æ‹©ç´ æ --"] + example_files,
                key="tab1_example"
            )
            
            if selected_example != "-- è¯·é€‰æ‹©ç´ æ --":
                uploaded_file = load_example_image(selected_example)
                st.success(f"âœ… å·²é€‰æ‹©ç´ æ: {selected_example}")
        else:
            st.info("ğŸ“ ç´ æåº“ä¸ºç©ºï¼Œè¯·æ·»åŠ å›¾ç‰‡åˆ°examplesæ–‡ä»¶å¤¹")
    
    if uploaded_file is not None:
        # è¯»å–å›¾åƒ
        pil_image = Image.open(uploaded_file)
        # ä¿å­˜RGBç‰ˆæœ¬ç”¨äºæ˜¾ç¤º
        image_rgb = np.array(pil_image)
        # è½¬æ¢ä¸ºBGRç”¨äºOpenCVå¤„ç†
        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
        
        # åˆå§‹åŒ–ç»“æœå˜é‡
        result_rgb = None
        
        col1, col2 = st.columns([2, 1])
        with col1:
            st.markdown('<div class="image-container">', unsafe_allow_html=True)
            # æ˜¾ç¤ºRGBç‰ˆæœ¬ï¼ˆæ­£ç¡®çš„é¢œè‰²ï¼‰
            st.image(image_rgb, caption="åŸå§‹å›¾åƒ", use_container_width=True)
            st.markdown('</div>', unsafe_allow_html=True)
        
        # å¢å¼ºæ–¹æ³•é€‰æ‹©
        enhancement_method = st.selectbox(
            "é€‰æ‹©å¢å¼ºæ–¹æ³•",
            ["ç›´æ–¹å›¾å‡è¡¡åŒ–", "å¯¹æ¯”åº¦è°ƒæ•´", "ä¼½é©¬æ ¡æ­£", "CLAHEå¢å¼º"]
        )
        
        col1, col2 = st.columns(2)
        with col1:
            if enhancement_method == "å¯¹æ¯”åº¦è°ƒæ•´":
                alpha = st.slider("å¯¹æ¯”åº¦ç³»æ•°", 0.5, 3.0, 1.2, 0.1)
                beta = st.slider("äº®åº¦è°ƒæ•´", -50, 50, 0)
                if st.button("åº”ç”¨å¯¹æ¯”åº¦è°ƒæ•´", use_container_width=True):
                    # ä½¿ç”¨BGRç‰ˆæœ¬è¿›è¡Œå¤„ç†
                    result_bgr = apply_contrast_adjustment(image_bgr, alpha, beta)
                    # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤º
                    result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
                    
            elif enhancement_method == "ä¼½é©¬æ ¡æ­£":
                gamma = st.slider("ä¼½é©¬å€¼", 0.1, 3.0, 1.0, 0.1)
                if st.button("åº”ç”¨ä¼½é©¬æ ¡æ­£", use_container_width=True):
                    # ä½¿ç”¨BGRç‰ˆæœ¬è¿›è¡Œå¤„ç†
                    result_bgr = apply_gamma_correction(image_bgr, gamma)
                    # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤º
                    result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
                    
            elif enhancement_method == "CLAHEå¢å¼º":
                clip_limit = st.slider("å¯¹æ¯”åº¦é™åˆ¶", 1.0, 4.0, 2.0, 0.1)
                tile_size = st.slider("ç½‘æ ¼å¤§å°", 4, 16, 8, 2)
                if st.button("åº”ç”¨CLAHEå¢å¼º", use_container_width=True):
                    # ä½¿ç”¨BGRç‰ˆæœ¬è¿›è¡Œå¤„ç†
                    result_bgr = apply_clahe(image_bgr, clip_limit, (tile_size, tile_size))
                    # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤º
                    result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
                    
            else:  # ç›´æ–¹å›¾å‡è¡¡åŒ–
                if st.button("åº”ç”¨ç›´æ–¹å›¾å‡è¡¡åŒ–", use_container_width=True):
                    # ä½¿ç”¨BGRç‰ˆæœ¬è¿›è¡Œå¤„ç†
                    result_bgr = apply_histogram_equalization(image_bgr)
                    # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤º
                    result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        with col2:
            if result_rgb is not None:
                st.markdown('<div class="image-container">', unsafe_allow_html=True)
                st.image(result_rgb, caption=f"{enhancement_method}ç»“æœ", use_container_width=True)
                st.markdown('</div>', unsafe_allow_html=True)
                
                # æ˜¾ç¤ºå¯¹æ¯”å’Œç›´æ–¹å›¾
                display_comparison_with_histograms(
                    image_rgb, 
                    result_rgb, 
                    original_title="åŸå§‹å›¾åƒ", 
                    processed_title=f"{enhancement_method}ç»“æœ"
                )
                
                # ä¸‹è½½æ—¶ä½¿ç”¨RGBç‰ˆæœ¬
                provide_download_button(
                    result_rgb, 
                    f"enhanced_{enhancement_method}.jpg", 
                    "ğŸ“¥ ä¸‹è½½å¢å¼ºç»“æœ",
                    unique_key_suffix="tab1_enhance"
                )
    else:
        st.info("ğŸ“¤ è¯·ä¸Šä¼ å›¾åƒæ–‡ä»¶æˆ–ä»ç´ æåº“é€‰æ‹©å›¾ç‰‡å¼€å§‹å¤„ç†")
# 2. è¾¹ç¼˜æ£€æµ‹é€‰é¡¹å¡
with tabs[1]:
    st.markdown("### ğŸ“ è¾¹ç¼˜æ£€æµ‹ç®—æ³•æ¯”è¾ƒ")
    
    st.markdown("""
    <div class='ideology-card'>
        <h4>ğŸ¯ æ€æ”¿å…³è”ï¼šä¸¥è°¨çš„ç§‘å­¦æ€åº¦</h4>
        <p>
        è¾¹ç¼˜æ£€æµ‹ç®—æ³•ä½“ç°äº†<strong style='color: #dc2626;'>ä¸¥è°¨æ±‚å®</strong>çš„ç§‘å­¦æ€åº¦ï¼Œ
        ä¸åŒç®—æ³•å„æœ‰ä¼˜åŠ£ï¼Œéœ€è¦æ ¹æ®å®é™…éœ€æ±‚é€‰æ‹©ï¼Œè¿™ä½“ç°äº†<strong style='color: #dc2626;'>å®äº‹æ±‚æ˜¯</strong>çš„ç§‘å­¦ç²¾ç¥ã€‚
        åœ¨æŠ€æœ¯ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬è¦ä¿æŒä¸¥è°¨çš„æ€åº¦ï¼Œè¿½æ±‚çœŸç†ã€‚
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # ===== åŒåˆ—å¸ƒå±€ï¼šå·¦ä¾§ä¸Šä¼ ï¼Œå³ä¾§ç´ æåº“ =====
    col_upload1, col_upload2 = st.columns(2)
    
    uploaded_file = None
    
    with col_upload1:
        uploaded_file = st.file_uploader(
            "ğŸ“¤ ä¸Šä¼ å›¾åƒæ–‡ä»¶", 
            type=["jpg", "jpeg", "png", "bmp", "webp"], 
            key="tab2_upload"
        )
    
    with col_upload2:
        # ç´ æåº“é€‰æ‹©
        example_files = get_example_images()
        
        if example_files:
            selected_example = st.selectbox(
                "ğŸ“š ä»ç´ æåº“é€‰æ‹©",
                ["-- è¯·é€‰æ‹©ç´ æ --"] + example_files,
                key="tab2_example"
            )
            
            if selected_example != "-- è¯·é€‰æ‹©ç´ æ --":
                uploaded_file = load_example_image(selected_example)
                st.success(f"âœ… å·²é€‰æ‹©ç´ æ: {selected_example}")
        else:
            st.info("ğŸ“ ç´ æåº“ä¸ºç©ºï¼Œè¯·æ·»åŠ å›¾ç‰‡åˆ°examplesæ–‡ä»¶å¤¹")
    
    if uploaded_file is not None:
        # è¯»å–å›¾åƒ
        pil_image = Image.open(uploaded_file)
        # ä¿å­˜RGBç‰ˆæœ¬ç”¨äºæ˜¾ç¤º
        image_rgb = np.array(pil_image)
        # è½¬æ¢ä¸ºBGRç”¨äºOpenCVå¤„ç†
        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
        
        # åˆå§‹åŒ–ç»“æœå˜é‡
        canny_result_rgb = None
        sobel_result_rgb = None
        laplacian_result_rgb = None
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("### Cannyè¾¹ç¼˜æ£€æµ‹")
            threshold1 = st.slider("ä½é˜ˆå€¼", 0, 100, 10, key="canny1")
            threshold2 = st.slider("é«˜é˜ˆå€¼", 100, 300, 100, key="canny2")
            
            if st.button("åº”ç”¨Canny", key="btn_canny", use_container_width=True):
                canny_result_bgr = apply_canny_edge(image_bgr, threshold1, threshold2)
                # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤ºå’Œä¸‹è½½
                canny_result_rgb = cv2.cvtColor(canny_result_bgr, cv2.COLOR_BGR2RGB)
            
            if canny_result_rgb is not None:
                st.image(canny_result_rgb, use_container_width=True)
                
                # æ˜¾ç¤ºå¯¹æ¯”å’Œç›´æ–¹å›¾
                st.markdown("### å¯¹æ¯”åˆ†æ")
                display_comparison_with_histograms(
                    image_rgb, 
                    canny_result_rgb, 
                    original_title="åŸå§‹å›¾åƒ", 
                    processed_title="Cannyè¾¹ç¼˜æ£€æµ‹ç»“æœ"
                )
                
                provide_download_button(
                    canny_result_rgb, 
                    "edges_canny.jpg", 
                    "ğŸ“¥ ä¸‹è½½Cannyç»“æœ",
                    unique_key_suffix="tab2_canny"
                )
        
        with col2:
            st.markdown("### Sobelè¾¹ç¼˜æ£€æµ‹")
            ksize = st.slider("æ ¸å¤§å°", 3, 17, 3, step=2, key="sobel")
            
            if st.button("åº”ç”¨Sobel", key="btn_sobel", use_container_width=True):
                sobel_result_bgr = apply_sobel_edge(image_bgr, ksize)
                # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤ºå’Œä¸‹è½½
                sobel_result_rgb = cv2.cvtColor(sobel_result_bgr, cv2.COLOR_BGR2RGB)
            
            if sobel_result_rgb is not None:
                st.image(sobel_result_rgb, use_container_width=True)
                
                # æ˜¾ç¤ºå¯¹æ¯”å’Œç›´æ–¹å›¾
                st.markdown("### å¯¹æ¯”åˆ†æ")
                display_comparison_with_histograms(
                    image_rgb, 
                    sobel_result_rgb, 
                    original_title="åŸå§‹å›¾åƒ", 
                    processed_title="Sobelè¾¹ç¼˜æ£€æµ‹ç»“æœ"
                )
                
                provide_download_button(
                    sobel_result_rgb, 
                    "edges_sobel.jpg", 
                    "ğŸ“¥ ä¸‹è½½Sobelç»“æœ",
                    unique_key_suffix="tab2_sobel"
                )
        
        with col3:
            st.markdown("### Laplacianè¾¹ç¼˜æ£€æµ‹")
            
            # æ·»åŠ Laplacianå‚æ•°æ§åˆ¶
            laplacian_ksize = st.slider("Laplacianæ ¸å¤§å°", 1, 7, 1, step=2, key="laplacian_ksize")
            laplacian_scale = st.slider("ç¼©æ”¾å› å­", 0.1, 5.0, 1.0, 0.1, key="laplacian_scale")
            laplacian_delta = st.slider("äº®åº¦è°ƒæ•´", 0, 100, 0, key="laplacian_delta")
            
            # åˆ›å»ºä¸€ä¸ªå¢å¼ºçš„Laplacianå‡½æ•°
            def apply_enhanced_laplacian(image, ksize=1, scale=1.0, delta=0):
                """å¢å¼ºçš„Laplacianè¾¹ç¼˜æ£€æµ‹"""
                if len(image.shape) == 3:
                    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                else:
                    gray = image.copy()
                
                # åº”ç”¨Laplacian
                laplacian = cv2.Laplacian(gray, cv2.CV_64F, ksize=ksize)
                
                # åº”ç”¨ç¼©æ”¾å’Œåç§»
                laplacian = cv2.convertScaleAbs(laplacian, alpha=scale, beta=delta)
                
                # è½¬æ¢ä¸ºå½©è‰²å›¾åƒç”¨äºæ˜¾ç¤º
                return cv2.cvtColor(laplacian, cv2.COLOR_GRAY2BGR)
            
            if st.button("åº”ç”¨Laplacian", key="btn_laplacian", use_container_width=True):
                laplacian_result_bgr = apply_enhanced_laplacian(
                    image_bgr, 
                    ksize=laplacian_ksize,
                    scale=laplacian_scale,
                    delta=laplacian_delta
                )
                # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤ºå’Œä¸‹è½½
                laplacian_result_rgb = cv2.cvtColor(laplacian_result_bgr, cv2.COLOR_BGR2RGB)
            
            if laplacian_result_rgb is not None:
                st.image(laplacian_result_rgb, caption=f"Laplacian ksize={laplacian_ksize}", use_container_width=True)
                
                # æ˜¾ç¤ºå¯¹æ¯”å’Œç›´æ–¹å›¾
                st.markdown("### å¯¹æ¯”åˆ†æ")
                display_comparison_with_histograms(
                    image_rgb, 
                    laplacian_result_rgb, 
                    original_title="åŸå§‹å›¾åƒ", 
                    processed_title="Laplacianè¾¹ç¼˜æ£€æµ‹ç»“æœ"
                )
                
                provide_download_button(
                    laplacian_result_rgb, 
                    "edges_laplacian.jpg", 
                    "ğŸ“¥ ä¸‹è½½Laplacianç»“æœ",
                    unique_key_suffix="tab2_laplacian"
                )
        
        # æ˜¾ç¤ºåŸå§‹å›¾åƒ
        st.markdown("### ğŸ“· åŸå§‹å›¾åƒå‚è€ƒ")
        st.image(image_rgb, caption="åŸå§‹å›¾åƒ", use_container_width=True)
    else:
        st.info("ğŸ“¤ è¯·ä¸Šä¼ å›¾åƒæ–‡ä»¶æˆ–ä»ç´ æåº“é€‰æ‹©å›¾ç‰‡å¼€å§‹å¤„ç†")

# 3. çº¿æ€§å˜æ¢é€‰é¡¹å¡
with tabs[2]:
    st.markdown("### ğŸ”„ çº¿æ€§å˜æ¢å¤„ç†")
    
    st.markdown("""
    <div class='ideology-card'>
        <h4>ğŸ¯ æ€æ”¿å…³è”ï¼šåˆ›æ–°å‘å±•çš„æ€ç»´</h4>
        <p>
        çº¿æ€§å˜æ¢æŠ€æœ¯ä½“ç°äº†<strong style='color: #dc2626;'>åˆ›æ–°æ±‚å˜</strong>çš„æ€ç»´æ¨¡å¼ï¼Œ
        é€šè¿‡æ•°å­¦å˜æ¢åˆ›é€ æ–°çš„è§†è§’ï¼Œè¿™ä½“ç°äº†<strong style='color: #dc2626;'>æ”¹é©åˆ›æ–°</strong>çš„æ—¶ä»£ç²¾ç¥ã€‚
        åœ¨æŠ€æœ¯å‘å±•ä¸­ï¼Œæˆ‘ä»¬è¦å‹‡äºåˆ›æ–°ï¼Œä¸æ–­æ¢ç´¢ã€‚
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # ===== åŒåˆ—å¸ƒå±€ï¼šå·¦ä¾§ä¸Šä¼ ï¼Œå³ä¾§ç´ æåº“ =====
    col_upload1, col_upload2 = st.columns(2)
    
    uploaded_file = None
    
    with col_upload1:
        uploaded_file = st.file_uploader(
            "ğŸ“¤ ä¸Šä¼ å›¾åƒæ–‡ä»¶", 
            type=["jpg", "jpeg", "png", "bmp", "webp"], 
            key="tab3_upload"
        )
    
    with col_upload2:
        # ç´ æåº“é€‰æ‹©
        example_files = get_example_images()
        
        if example_files:
            selected_example = st.selectbox(
                "ğŸ“š ä»ç´ æåº“é€‰æ‹©",
                ["-- è¯·é€‰æ‹©ç´ æ --"] + example_files,
                key="tab3_example"
            )
            
            if selected_example != "-- è¯·é€‰æ‹©ç´ æ --":
                uploaded_file = load_example_image(selected_example)
                st.success(f"âœ… å·²é€‰æ‹©ç´ æ: {selected_example}")
        else:
            st.info("ğŸ“ ç´ æåº“ä¸ºç©ºï¼Œè¯·æ·»åŠ å›¾ç‰‡åˆ°examplesæ–‡ä»¶å¤¹")
    
    if uploaded_file is not None:
        # è¯»å–å›¾åƒ
        pil_image = Image.open(uploaded_file)
        # ä¿å­˜RGBç‰ˆæœ¬ç”¨äºæ˜¾ç¤º
        image_rgb = np.array(pil_image)
        # è½¬æ¢ä¸ºBGRç”¨äºOpenCVå¤„ç†
        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
        
        # åˆå§‹åŒ–ç»“æœå˜é‡
        result_rgb = None
        
        transform_type = st.selectbox("é€‰æ‹©å˜æ¢ç±»å‹", ["ä»¿å°„å˜æ¢", "é€è§†å˜æ¢"])
        
        if transform_type == "ä»¿å°„å˜æ¢":
            col1, col2 = st.columns(2)
            with col1:
                angle = st.slider("æ—‹è½¬è§’åº¦", -180, 180, 0)
                scale = st.slider("ç¼©æ”¾æ¯”ä¾‹", 0.5, 2.0, 1.0, 0.1)
            with col2:
                tx = st.slider("æ°´å¹³å¹³ç§»", -100, 100, 0)
                ty = st.slider("å‚ç›´å¹³ç§»", -100, 100, 0)
            
            # æ·»åŠ é¢„è§ˆé€‰é¡¹
            show_preview = st.checkbox("æ˜¾ç¤ºå˜æ¢çŸ©é˜µé¢„è§ˆ", value=True)
            
            if show_preview:
                # è®¡ç®—å¹¶æ˜¾ç¤ºå˜æ¢çŸ©é˜µ
                height, width = image_bgr.shape[:2]
                center = (width // 2, height // 2)
                matrix = cv2.getRotationMatrix2D(center, angle, scale)
                matrix[0, 2] += tx
                matrix[1, 2] += ty
                
                st.markdown("**ä»¿å°„å˜æ¢çŸ©é˜µ:**")
                st.code(f"""
                [ cosÎ¸Â·s, -sinÎ¸Â·s, tx ]
                [ sinÎ¸Â·s,  cosÎ¸Â·s, ty ]
                = 
                [{matrix[0,0]:.3f}, {matrix[0,1]:.3f}, {matrix[0,2]:.1f}]
                [{matrix[1,0]:.3f}, {matrix[1,1]:.3f}, {matrix[1,2]:.1f}]
                """)
            
            if st.button("åº”ç”¨ä»¿å°„å˜æ¢", use_container_width=True):
                result_bgr = apply_affine_transform(image_bgr, angle, scale, tx, ty)
                # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤ºå’Œä¸‹è½½
                result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        else:  # é€è§†å˜æ¢
            st.markdown("### é€è§†å˜æ¢å‚æ•°")
            st.markdown("è°ƒæ•´å››ä¸ªè§’çš„åæ ‡æ¥æ”¹å˜é€è§†æ•ˆæœ:")
            
            height, width = image_bgr.shape[:2]
            
            # åˆ›å»º4ä¸ªæ§åˆ¶ç‚¹
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**å·¦ä¸Šè§’**")
                tl_x = st.slider("TL X", 0, width//2, 50, key="tl_x")
                tl_y = st.slider("TL Y", 0, height//2, 50, key="tl_y")
                
                st.markdown("**å³ä¸Šè§’**")
                tr_x = st.slider("TR X", width//2, width, width-50, key="tr_x")
                tr_y = st.slider("TR Y", 0, height//2, 0, key="tr_y")
            
            with col2:
                st.markdown("**å·¦ä¸‹è§’**")
                bl_x = st.slider("BL X", 0, width//2, 0, key="bl_x")
                bl_y = st.slider("BL Y", height//2, height, height-50, key="bl_y")
                
                st.markdown("**å³ä¸‹è§’**")
                br_x = st.slider("BR X", width//2, width, width, key="br_x")
                br_y = st.slider("BR Y", height//2, height, height, key="br_y")
            
            # æ›´æ–°é€è§†å˜æ¢å‡½æ•°
            def apply_custom_perspective_transform(image, src_points, dst_points):
                """è‡ªå®šä¹‰é€è§†å˜æ¢"""
                matrix = cv2.getPerspectiveTransform(src_points, dst_points)
                return cv2.warpPerspective(image, matrix, (width, height))
            
            # å®šä¹‰åŸå§‹ç‚¹ï¼ˆå›¾åƒçš„å››ä¸ªè§’ï¼‰
            src_points = np.float32([
                [0, 0],           # å·¦ä¸Šè§’
                [width, 0],       # å³ä¸Šè§’
                [0, height],      # å·¦ä¸‹è§’
                [width, height]   # å³ä¸‹è§’
            ])
            
            # å®šä¹‰ç›®æ ‡ç‚¹ï¼ˆæ ¹æ®æ»‘å—è°ƒæ•´ï¼‰
            dst_points = np.float32([
                [tl_x, tl_y],    # å·¦ä¸Šè§’
                [tr_x, tr_y],    # å³ä¸Šè§’
                [bl_x, bl_y],    # å·¦ä¸‹è§’
                [br_x, br_y]     # å³ä¸‹è§’
            ])
            
            # æ˜¾ç¤ºé€è§†å˜æ¢é¢„è§ˆ
            st.markdown("### å˜æ¢æ•ˆæœé¢„è§ˆ")
            
            # åˆ›å»ºå¸¦æœ‰æ§åˆ¶ç‚¹çš„é¢„è§ˆå›¾åƒ
            preview_image = image_rgb.copy()
            
            # ç»˜åˆ¶åŸå§‹ç‚¹å’Œç›®æ ‡ç‚¹
            points_colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0)]
            points_labels = ['TL', 'TR', 'BL', 'BR']
            
            # åœ¨é¢„è§ˆå›¾ä¸Šç»˜åˆ¶ç‚¹
            for i, (src_pt, dst_pt, color, label) in enumerate(zip(src_points, dst_points, points_colors, points_labels)):
                # ç»˜åˆ¶åŸå§‹ç‚¹ï¼ˆè“è‰²ï¼‰
                cv2.circle(preview_image, (int(src_pt[0]), int(src_pt[1])), 8, color, -1)
                cv2.putText(preview_image, f'{label}_src', 
                          (int(src_pt[0])+10, int(src_pt[1])+10),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
                
                # ç»˜åˆ¶ç›®æ ‡ç‚¹ï¼ˆçº¢è‰²ï¼‰
                cv2.circle(preview_image, (int(dst_pt[0]), int(dst_pt[1])), 8, color, 2)
                cv2.putText(preview_image, f'{label}_dst', 
                          (int(dst_pt[0])+10, int(dst_pt[1])+10),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
                
                # ç»˜åˆ¶è¿æ¥çº¿
                cv2.line(preview_image, 
                        (int(src_pt[0]), int(src_pt[1])),
                        (int(dst_pt[0]), int(dst_pt[1])),
                        (128, 128, 128), 1, cv2.LINE_AA)
            
            # æ˜¾ç¤ºé¢„è§ˆå›¾
            col1, col2 = st.columns(2)
            with col1:
                st.image(preview_image, caption="æ§åˆ¶ç‚¹é¢„è§ˆï¼ˆè“è‰²:åŸå§‹, çº¢è‰²:ç›®æ ‡ï¼‰", use_container_width=True)
            
            if st.button("åº”ç”¨é€è§†å˜æ¢", use_container_width=True):
                result_bgr = apply_custom_perspective_transform(image_bgr, src_points, dst_points)
                # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤ºå’Œä¸‹è½½
                result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        # æ˜¾ç¤ºç»“æœå’Œä¸‹è½½ï¼ˆé€‚ç”¨äºä¸¤ç§å˜æ¢ï¼‰
        if result_rgb is not None:
            with col2:
                caption = ""
                if transform_type == "ä»¿å°„å˜æ¢":
                    caption = f"ä»¿å°„å˜æ¢ç»“æœ\næ—‹è½¬:{angle}Â°, ç¼©æ”¾:{scale}x"
                    st.image(result_rgb, caption=caption, use_container_width=True)
                else:  # é€è§†å˜æ¢
                    caption = "é€è§†å˜æ¢ç»“æœ"
                    st.image(result_rgb, caption=caption, use_container_width=True)
                    
                    # æ˜¾ç¤ºå˜æ¢çŸ©é˜µ
                    matrix = cv2.getPerspectiveTransform(src_points, dst_points)
                    st.markdown("**é€è§†å˜æ¢çŸ©é˜µ:**")
                    st.code(f"""
                    [{matrix[0,0]:.6f}, {matrix[0,1]:.6f}, {matrix[0,2]:.6f}]
                    [{matrix[1,0]:.6f}, {matrix[1,1]:.6f}, {matrix[1,2]:.6f}]
                    [{matrix[2,0]:.6f}, {matrix[2,1]:.6f}, {matrix[2,2]:.6f}]
                    """)
            
            # æ˜¾ç¤ºå¯¹æ¯”å’Œç›´æ–¹å›¾
            st.markdown("### ğŸ–¼ï¸ å˜æ¢æ•ˆæœå¯¹æ¯”")
            display_comparison_with_histograms(
                image_rgb, 
                result_rgb, 
                original_title="åŸå§‹å›¾åƒ", 
                processed_title=f"{transform_type}ç»“æœ"
            )
            
            provide_download_button(
                result_rgb, 
                f"{transform_type}.jpg", 
                "ğŸ“¥ ä¸‹è½½å˜æ¢ç»“æœ",
                unique_key_suffix=f"tab3_{transform_type}"
            )
    else:
        st.info("ğŸ“¤ è¯·ä¸Šä¼ å›¾åƒæ–‡ä»¶æˆ–ä»ç´ æåº“é€‰æ‹©å›¾ç‰‡å¼€å§‹å¤„ç†")



# 4. å›¾åƒé”åŒ–é€‰é¡¹å¡
with tabs[3]:
    st.markdown("### âœ¨ å›¾åƒé”åŒ–å¤„ç†")
    
    st.markdown("""
    <div class='ideology-card'>
        <h4>ğŸ¯ æ€æ”¿å…³è”ï¼šç²¾ç›Šæ±‚ç²¾çš„æ€åº¦</h4>
        <p>
        å›¾åƒé”åŒ–æŠ€æœ¯ä½“ç°äº†<strong style='color: #dc2626;'>ç²¾ç›Šæ±‚ç²¾</strong>çš„å·¥ä½œæ€åº¦ï¼Œ
        é€šè¿‡å¢å¼ºç»†èŠ‚å±•ç°æ›´æ¸…æ™°çš„å›¾åƒï¼Œè¿™ä½“ç°äº†<strong style='color: #dc2626;'>è¿½æ±‚å“è¶Š</strong>çš„å·¥åŒ ç²¾ç¥ã€‚
        åœ¨æŠ€æœ¯å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è¦æ³¨é‡ç»†èŠ‚ï¼Œè¿½æ±‚å®Œç¾ã€‚
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # æ·»åŠ é”åŒ–åŸç†è¯´æ˜
    with st.expander("ğŸ“š é”åŒ–åŸç†è¯´æ˜", expanded=False):
        st.markdown("""
        ### å›¾åƒé”åŒ–æŠ€æœ¯åŸç†
        
        1. **é”åŒ–æ»¤æ³¢å™¨** - é€šè¿‡å·ç§¯æ ¸å¢å¼ºå›¾åƒè¾¹ç¼˜
        2. **éé”åŒ–æ©è”½** - å…ˆæ¨¡ç³Šå†ä¸åŸå›¾ç›¸å‡ï¼Œå¢å¼ºé«˜é¢‘ç»†èŠ‚
        3. **æ‹‰æ™®æ‹‰æ–¯é”åŒ–** - ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­æ£€æµ‹è¾¹ç¼˜
        4. **é«˜é¢‘æå‡æ»¤æ³¢** - å¢å¼ºå›¾åƒçš„é«˜é¢‘åˆ†é‡
        5. **è‡ªé€‚åº”é”åŒ–** - ä»…åœ¨è¾¹ç¼˜åŒºåŸŸåº”ç”¨é”åŒ–
        
        **ç°åº¦å›¾åƒé”åŒ–çš„ä¼˜åŠ¿**:
        - å‡å°‘è®¡ç®—å¤æ‚åº¦ï¼Œæé«˜å¤„ç†é€Ÿåº¦
        - é¿å…å½©è‰²é€šé“ä¹‹é—´çš„å¹²æ‰°
        - æ›´ä¸“æ³¨äºè¾¹ç¼˜å’Œç»†èŠ‚å¢å¼º
        - é€‚åˆæ–‡æœ¬ã€æ–‡æ¡£ã€åŒ»å­¦å½±åƒç­‰å¤„ç†
        
        **åº”ç”¨åœºæ™¯**:
        - æ¨¡ç³Šç…§ç‰‡çš„æ¸…æ™°åŒ–
        - æ–‡æ¡£æ‰«æä»¶çš„å¢å¼º
        - åŒ»å­¦å›¾åƒçš„ç»†èŠ‚æå–
        - ç›‘æ§è§†é¢‘çš„æ¸…æ™°åŒ–
        """)
    
    # ===== åŒåˆ—å¸ƒå±€ï¼šå·¦ä¾§ä¸Šä¼ ï¼Œå³ä¾§ç´ æåº“ =====
    col_upload1, col_upload2 = st.columns(2)
    
    uploaded_file = None
    
    with col_upload1:
        uploaded_file = st.file_uploader(
            "ğŸ“¤ ä¸Šä¼ å›¾åƒæ–‡ä»¶", 
            type=["jpg", "jpeg", "png", "bmp", "webp"], 
            key="tab4_upload"
        )
    
    with col_upload2:
        # ç´ æåº“é€‰æ‹©
        example_files = get_example_images()
        
        if example_files:
            selected_example = st.selectbox(
                "ğŸ“š ä»ç´ æåº“é€‰æ‹©",
                ["-- è¯·é€‰æ‹©ç´ æ --"] + example_files,
                key="tab4_example"
            )
            
            if selected_example != "-- è¯·é€‰æ‹©ç´ æ --":
                uploaded_file = load_example_image(selected_example)
                st.success(f"âœ… å·²é€‰æ‹©ç´ æ: {selected_example}")
        else:
            st.info("ğŸ“ ç´ æåº“ä¸ºç©ºï¼Œè¯·æ·»åŠ å›¾ç‰‡åˆ°examplesæ–‡ä»¶å¤¹")
    
    # æ·»åŠ å½©è‰²/ç°åº¦é€‰é¡¹
    processing_mode = st.radio(
        "é€‰æ‹©å¤„ç†æ¨¡å¼",
        ["ç°åº¦å›¾åƒé”åŒ–", "å½©è‰²å›¾åƒé”åŒ–"],
        horizontal=True,
        index=0,
        key="sharpen_mode"
    )
    
    if uploaded_file is not None:
        # è¯»å–å›¾åƒ
        pil_image = Image.open(uploaded_file)
        
        # æ ¹æ®å¤„ç†æ¨¡å¼è½¬æ¢å›¾åƒ
        if processing_mode == "ç°åº¦å›¾åƒé”åŒ–":
            # è½¬æ¢ä¸ºç°åº¦å›¾åƒ
            if pil_image.mode != 'L':
                pil_image = pil_image.convert('L')
            image_gray = np.array(pil_image)
            
            # ä¸ºå…¼å®¹OpenCVå¤„ç†ï¼Œå°†ç°åº¦å›¾è½¬ä¸º3é€šé“BGRæ ¼å¼
            image_bgr = cv2.cvtColor(image_gray, cv2.COLOR_GRAY2BGR)
            image_for_display = image_gray  # æ˜¾ç¤ºç”¨ç°åº¦å›¾
        else:
            # ä¿æŒå½©è‰²å›¾åƒ
            image_rgb = np.array(pil_image)
            image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
            image_for_display = image_rgb  # æ˜¾ç¤ºç”¨å½©è‰²å›¾
        
        # ç¡®ä¿å›¾åƒæ˜¯uint8ç±»å‹
        if image_bgr.dtype != np.uint8:
            image_bgr = image_bgr.astype(np.uint8)
        
        # æ˜¾ç¤ºåŸå§‹å›¾åƒä¿¡æ¯
        with st.expander("ğŸ“Š åŸå§‹å›¾åƒä¿¡æ¯", expanded=False):
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("å®½åº¦", f"{image_for_display.shape[1]}px")
            with col2:
                st.metric("é«˜åº¦", f"{image_for_display.shape[0]}px")
            with col3:
                st.metric("æ¨¡å¼", processing_mode)
                st.metric("æ ¼å¼", pil_image.format or "æœªçŸ¥")
        
        # æ˜¾ç¤ºåŸå§‹å›¾åƒ
        st.markdown("### ğŸ“· åŸå§‹å›¾åƒ")
        if processing_mode == "ç°åº¦å›¾åƒé”åŒ–":
            # æ·»åŠ  width å‚æ•°æ§åˆ¶æ˜¾ç¤ºå¤§å°
            st.image(image_for_display, use_container_width=False, width=400, 
                     caption=f"ç°åº¦å›¾åƒ {image_for_display.shape[1]} Ã— {image_for_display.shape[0]}",
                     clamp=True)
        else:
            st.image(image_for_display, use_container_width=False, width=400,
                     caption=f"å½©è‰²å›¾åƒ {image_for_display.shape[1]} Ã— {image_for_display.shape[0]}")
        
        # é€‰æ‹©é”åŒ–æ–¹æ³•
        sharpen_method = st.selectbox(
            "é€‰æ‹©é”åŒ–æ–¹æ³•", 
            ["é”åŒ–æ»¤æ³¢å™¨", "éé”åŒ–æ©è”½", "æ‹‰æ™®æ‹‰æ–¯é”åŒ–", "é«˜é¢‘æå‡æ»¤æ³¢", "è‡ªé€‚åº”é”åŒ–"],
            key="sharpen_method_select"
        )
        
        # ç»“æœå˜é‡
        result_image = None
        
        if sharpen_method == "é”åŒ–æ»¤æ³¢å™¨":
            st.markdown("#### ğŸ” é”åŒ–æ»¤æ³¢å™¨è®¾ç½®")
            
            col1, col2 = st.columns(2)
            with col1:
                kernel_size = st.slider("æ»¤æ³¢å™¨å¤§å°", 3, 15, 3, step=2, key="sharpen_kernel")
            with col2:
                sharpen_strength = st.slider("é”åŒ–å¼ºåº¦", 0.1, 3.0, 1.0, 0.1, key="sharpen_strength")
            
            if st.button("ğŸ” åº”ç”¨é”åŒ–æ»¤æ³¢å™¨", use_container_width=True, key="sharpen_filter_btn"):
                with st.spinner("æ­£åœ¨åº”ç”¨é”åŒ–æ»¤æ³¢å™¨..."):
                    # ä½¿ç”¨BGRå›¾åƒå¤„ç†
                    result_bgr = apply_sharpen_filter(image_bgr, kernel_size)
                    
                    # è°ƒæ•´é”åŒ–å¼ºåº¦
                    if sharpen_strength != 1.0:
                        detail = cv2.subtract(result_bgr, image_bgr)
                        result_bgr = cv2.addWeighted(image_bgr, 1.0, detail, sharpen_strength, 0)
                    
                    # æ ¹æ®å¤„ç†æ¨¡å¼è½¬æ¢ç»“æœ
                    if processing_mode == "ç°åº¦å›¾åƒé”åŒ–":
                        result_image = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2GRAY)
                    else:
                        result_image = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        elif sharpen_method == "éé”åŒ–æ©è”½":
            st.markdown("#### ğŸ¯ éé”åŒ–æ©è”½è®¾ç½®")
            
            col1, col2 = st.columns(2)
            with col1:
                sigma = st.slider("æ¨¡ç³Šç¨‹åº¦", 0.1, 5.0, 1.0, 0.1, key="unsharp_sigma")
            with col2:
                amount = st.slider("é”åŒ–å¼ºåº¦", 0.1, 3.0, 1.0, 0.1, key="unsharp_amount")
            
            if st.button("ğŸ¯ åº”ç”¨éé”åŒ–æ©è”½", use_container_width=True, key="unsharp_btn"):
                with st.spinner("æ­£åœ¨åº”ç”¨éé”åŒ–æ©è”½..."):
                    # ä½¿ç”¨BGRå›¾åƒå¤„ç†
                    result_bgr = apply_unsharp_masking(image_bgr, sigma, amount)
                    
                    # æ ¹æ®å¤„ç†æ¨¡å¼è½¬æ¢ç»“æœ
                    if processing_mode == "ç°åº¦å›¾åƒé”åŒ–":
                        result_image = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2GRAY)
                    else:
                        result_image = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        elif sharpen_method == "æ‹‰æ™®æ‹‰æ–¯é”åŒ–":
            st.markdown("#### âš¡ æ‹‰æ™®æ‹‰æ–¯é”åŒ–è®¾ç½®")
            
            col1, col2 = st.columns(2)
            with col1:
                edge_strength = st.slider("è¾¹ç¼˜å¢å¼º", 0.1, 2.0, 0.5, 0.1, key="laplace_strength")
            with col2:
                noise_reduction = st.checkbox("é™å™ªå¤„ç†", True, key="laplace_denoise")
            
            if st.button("âš¡ åº”ç”¨æ‹‰æ™®æ‹‰æ–¯é”åŒ–", use_container_width=True, key="laplace_btn"):
                with st.spinner("æ­£åœ¨åº”ç”¨æ‹‰æ™®æ‹‰æ–¯é”åŒ–..."):
                    # é¢„å¤„ç†ï¼šå¦‚æœéœ€è¦é™å™ª
                    if noise_reduction:
                        image_processed = cv2.bilateralFilter(image_bgr, 5, 50, 50)
                    else:
                        image_processed = image_bgr
                    
                    # åº”ç”¨æ‹‰æ™®æ‹‰æ–¯é”åŒ–
                    result_bgr = apply_laplacian_sharpening(image_processed)
                    
                    # è°ƒæ•´è¾¹ç¼˜å¼ºåº¦
                    if edge_strength != 1.0:
                        detail = cv2.subtract(result_bgr, image_bgr)
                        result_bgr = cv2.addWeighted(image_bgr, 1.0, detail, edge_strength, 0)
                    
                    # æ ¹æ®å¤„ç†æ¨¡å¼è½¬æ¢ç»“æœ
                    if processing_mode == "ç°åº¦å›¾åƒé”åŒ–":
                        result_image = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2GRAY)
                    else:
                        result_image = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        elif sharpen_method == "é«˜é¢‘æå‡æ»¤æ³¢":
            st.markdown("#### ğŸš€ é«˜é¢‘æå‡æ»¤æ³¢è®¾ç½®")
            
            col1, col2 = st.columns(2)
            with col1:
                boost_factor = st.slider("æå‡ç³»æ•°", 1.0, 3.0, 1.5, 0.1, key="boost_factor")
            with col2:
                blend_mode = st.selectbox("æ··åˆæ¨¡å¼", ["ç›´æ¥æ··åˆ", "è¾¹ç¼˜å¢å¼º"], key="boost_blend")
            
            if st.button("ğŸš€ åº”ç”¨é«˜é¢‘æå‡æ»¤æ³¢", use_container_width=True, key="boost_btn"):
                with st.spinner("æ­£åœ¨åº”ç”¨é«˜é¢‘æå‡æ»¤æ³¢..."):
                    # ä½¿ç”¨BGRå›¾åƒå¤„ç†
                    result_bgr = apply_high_boost_filter(image_bgr, boost_factor)
                    
                    # æ ¹æ®å¤„ç†æ¨¡å¼è½¬æ¢ç»“æœ
                    if processing_mode == "ç°åº¦å›¾åƒé”åŒ–":
                        result_image = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2GRAY)
                    else:
                        result_image = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        else:  # è‡ªé€‚åº”é”åŒ–
            st.markdown("#### ğŸ¨ è‡ªé€‚åº”é”åŒ–è®¾ç½®")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                strength = st.slider("é”åŒ–å¼ºåº¦", 0.1, 1.0, 0.5, 0.1, key="adaptive_strength")
            with col2:
                edge_threshold = st.slider("è¾¹ç¼˜é˜ˆå€¼", 30, 200, 100, key="adaptive_threshold")
            with col3:
                smooth_edges = st.checkbox("å¹³æ»‘è¾¹ç¼˜", True, key="adaptive_smooth")
            
            if st.button("ğŸ¨ åº”ç”¨è‡ªé€‚åº”é”åŒ–", use_container_width=True, key="adaptive_btn"):
                with st.spinner("æ­£åœ¨åº”ç”¨è‡ªé€‚åº”é”åŒ–..."):
                    # ä½¿ç”¨BGRå›¾åƒå¤„ç†
                    result_bgr = apply_adaptive_sharpen(image_bgr, strength)
                    
                    # æ ¹æ®å¤„ç†æ¨¡å¼è½¬æ¢ç»“æœ
                    if processing_mode == "ç°åº¦å›¾åƒé”åŒ–":
                        result_image = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2GRAY)
                    else:
                        result_image = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        # æ˜¾ç¤ºç»“æœå’Œä¸‹è½½
        if result_image is not None:
            # ç¡®ä¿ç»“æœæ˜¯uint8ç±»å‹
            if result_image.dtype != np.uint8:
                result_image = result_image.astype(np.uint8)
            
            # æ˜¾ç¤ºå¯¹æ¯”å’Œç›´æ–¹å›¾
            st.markdown(f"### ğŸ–¼ï¸ {sharpen_method}æ•ˆæœå¯¹æ¯”")
            
            if processing_mode == "ç°åº¦å›¾åƒé”åŒ–":
                # å¯¹äºç°åº¦å›¾åƒï¼Œéœ€è¦è½¬æ¢ä¸ºRGBç”¨äºç›´æ–¹å›¾æ˜¾ç¤º
                display_comparison_with_histograms(
                    cv2.cvtColor(image_for_display, cv2.COLOR_GRAY2RGB) if len(image_for_display.shape) == 2 else image_for_display,
                    cv2.cvtColor(result_image, cv2.COLOR_GRAY2RGB) if len(result_image.shape) == 2 else result_image,
                    original_title="åŸå§‹å›¾åƒ",
                    processed_title=f"{sharpen_method}ç»“æœ"
                )
            else:
                display_comparison_with_histograms(
                    image_for_display,
                    result_image,
                    original_title="åŸå§‹å›¾åƒ",
                    processed_title=f"{sharpen_method}ç»“æœ"
                )
            
            # ä¸‹è½½é€‰é¡¹
            st.markdown("### ğŸ“¥ ä¸‹è½½é”åŒ–ç»“æœ")
            
            # å°†ç»“æœè½¬æ¢ä¸ºPILå›¾åƒ
            if processing_mode == "ç°åº¦å›¾åƒé”åŒ–":
                result_pil = Image.fromarray(result_image, mode='L')
            else:
                result_pil = Image.fromarray(result_image)
            
            col_dl1, col_dl2, col_dl3 = st.columns(3)
            
            with col_dl1:
                # JPEGæ ¼å¼
                img_buffer = io.BytesIO()
                if processing_mode == "ç°åº¦å›¾åƒé”åŒ–":
                    # JPEGä¸æ”¯æŒçº¯ç°åº¦æ¨¡å¼ï¼Œè½¬æ¢ä¸ºRGB
                    result_pil.convert('RGB').save(img_buffer, format="JPEG", quality=95)
                else:
                    result_pil.save(img_buffer, format="JPEG", quality=95)
                img_buffer.seek(0)
                
                st.download_button(
                    label="ğŸ’¾ ä¸‹è½½JPEGæ ¼å¼",
                    data=img_buffer,
                    file_name=f"é”åŒ–_{processing_mode}_{sharpen_method}.jpg",
                    mime="image/jpeg",
                    use_container_width=True
                )
            
            with col_dl2:
                # PNGæ ¼å¼
                png_buffer = io.BytesIO()
                result_pil.save(png_buffer, format="PNG")
                png_buffer.seek(0)
                
                st.download_button(
                    label="ğŸ–¼ï¸ ä¸‹è½½PNGæ ¼å¼",
                    data=png_buffer,
                    file_name=f"é”åŒ–_{processing_mode}_{sharpen_method}.png",
                    mime="image/png",
                    use_container_width=True
                )
            
            with col_dl3:
                # é«˜è´¨é‡ç‰ˆæœ¬
                high_buffer = io.BytesIO()
                if processing_mode == "ç°åº¦å›¾åƒé”åŒ–":
                    result_pil.convert('RGB').save(high_buffer, format="JPEG", quality=100)
                else:
                    result_pil.save(high_buffer, format="JPEG", quality=100)
                high_buffer.seek(0)
                
                st.download_button(
                    label="ğŸŒŸ æœ€é«˜è´¨é‡",
                    data=high_buffer,
                    file_name=f"é”åŒ–_{processing_mode}_{sharpen_method}_é«˜è´¨é‡.jpg",
                    mime="image/jpeg",
                    use_container_width=True
                )
    
    else:
        # æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶æ—¶çš„ç•Œé¢
        st.info("ğŸ“¤ è¯·ä¸Šä¼ å›¾åƒæ–‡ä»¶æˆ–ä»ç´ æåº“é€‰æ‹©å›¾ç‰‡å¼€å§‹å¤„ç†")
        
        # æ·»åŠ ç¤ºä¾‹æ¼”ç¤º
        if st.checkbox("æ˜¾ç¤ºé”åŒ–ç¤ºä¾‹", key="sharpen_demo"):
            # åˆ›å»ºç¤ºä¾‹å›¾åƒ
            st.markdown("### ğŸ“ ç°åº¦å›¾åƒé”åŒ–ç¤ºä¾‹")
            
            # åˆ›å»ºç°åº¦ç¤ºä¾‹å›¾åƒ
            demo_image_gray = np.ones((300, 400), dtype=np.uint8) * 150
            cv2.putText(demo_image_gray, "Example Text", (80, 150), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1.5, 50, 3)
            
            # åº”ç”¨æ¨¡ç³Šæ¨¡æ‹Ÿéœ€è¦é”åŒ–çš„å›¾åƒ
            demo_blurred = cv2.GaussianBlur(demo_image_gray, (5, 5), 2)
            
            col1, col2 = st.columns(2)
            with col1:
                st.image(demo_blurred, caption="æ¨¡ç³Šçš„ç°åº¦å›¾åƒ", use_container_width=True, clamp=True)
            
            with col2:
                # å°†ç°åº¦å›¾è½¬ä¸º3é€šé“BGRç”¨äºå¤„ç†
                demo_blurred_bgr = cv2.cvtColor(demo_blurred, cv2.COLOR_GRAY2BGR)
                
                # åº”ç”¨é”åŒ–
                demo_sharp_bgr = apply_unsharp_masking(demo_blurred_bgr, 2.0, 1.5)
                demo_sharp_gray = cv2.cvtColor(demo_sharp_bgr, cv2.COLOR_BGR2GRAY)
                st.image(demo_sharp_gray, caption="é”åŒ–åçš„ç°åº¦å›¾åƒ", use_container_width=True, clamp=True)



# 5. é‡‡æ ·ä¸é‡åŒ–é€‰é¡¹å¡
with tabs[4]:
    st.markdown("### ğŸ“Š é‡‡æ ·ä¸é‡åŒ–åˆ†æ")
    
    st.markdown("""
    <div class='ideology-card'>
        <h4>ğŸ¯ æ€æ”¿å…³è”ï¼šå®äº‹æ±‚æ˜¯çš„ç§‘å­¦ç²¾ç¥</h4>
        <p>
        é‡‡æ ·ä¸é‡åŒ–æŠ€æœ¯ä½“ç°äº†<strong style='color: #dc2626;'>å®äº‹æ±‚æ˜¯</strong>çš„ç§‘å­¦ç²¾ç¥ï¼Œ
        é€šè¿‡åˆ†ææ•°æ®ç‰¹å¾ä¼˜åŒ–å­˜å‚¨å’Œä¼ è¾“ï¼Œè¿™ä½“ç°äº†<strong style='color: #dc2626;'>åŠ¡å®é«˜æ•ˆ</strong>çš„å·¥ä½œä½œé£ã€‚
        åœ¨æŠ€æœ¯åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬è¦æ³¨é‡å®é™…æ•ˆæœï¼Œè¿½æ±‚æ•ˆç‡ã€‚
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # ===== åŒåˆ—å¸ƒå±€ï¼šå·¦ä¾§ä¸Šä¼ ï¼Œå³ä¾§ç´ æåº“ =====
    col_upload1, col_upload2 = st.columns(2)
    
    uploaded_file = None
    
    with col_upload1:
        uploaded_file = st.file_uploader(
            "ğŸ“¤ ä¸Šä¼ å›¾åƒæ–‡ä»¶", 
            type=["jpg", "jpeg", "png", "bmp", "webp"], 
            key="tab5_upload"
        )
    
    with col_upload2:
        # ç´ æåº“é€‰æ‹©
        example_files = get_example_images()
        
        if example_files:
            selected_example = st.selectbox(
                "ğŸ“š ä»ç´ æåº“é€‰æ‹©",
                ["-- è¯·é€‰æ‹©ç´ æ --"] + example_files,
                key="tab5_example"
            )
            
            if selected_example != "-- è¯·é€‰æ‹©ç´ æ --":
                uploaded_file = load_example_image(selected_example)
                st.success(f"âœ… å·²é€‰æ‹©ç´ æ: {selected_example}")
        else:
            st.info("ğŸ“ ç´ æåº“ä¸ºç©ºï¼Œè¯·æ·»åŠ å›¾ç‰‡åˆ°examplesæ–‡ä»¶å¤¹")
    
    if uploaded_file is not None:
        # è¯»å–å›¾åƒ
        pil_image = Image.open(uploaded_file)
        # ä¿å­˜RGBç‰ˆæœ¬ç”¨äºæ˜¾ç¤º
        image_rgb = np.array(pil_image)
        # è½¬æ¢ä¸ºBGRç”¨äºOpenCVå¤„ç†
        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
        
        # åˆå§‹åŒ–ç»“æœå˜é‡
        sampled_rgb = None
        quantized_rgb = None
        
        # é‡‡æ ·æ§åˆ¶
        st.markdown("### ğŸ”½ å›¾åƒé‡‡æ ·")
        sample_ratio = st.slider("é‡‡æ ·æ¯”ä¾‹", 2, 8, 2)
        
        if st.button("åº”ç”¨é‡‡æ ·", key="sample_btn", use_container_width=True):
            # ä½¿ç”¨BGRå›¾åƒå¤„ç†
            sampled_bgr = apply_sampling(image_bgr, sample_ratio)
            # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤ºå’Œä¸‹è½½
            sampled_rgb = cv2.cvtColor(sampled_bgr, cv2.COLOR_BGR2RGB)
        
        # é‡åŒ–æ§åˆ¶
        st.markdown("### ğŸšï¸ å›¾åƒé‡åŒ–")
        quant_levels = st.slider("é‡åŒ–çº§åˆ«", 2, 256, 64)
        
        if st.button("åº”ç”¨é‡åŒ–", key="quant_btn", use_container_width=True):
            # ä½¿ç”¨BGRå›¾åƒå¤„ç†
            quantized_bgr = apply_quantization(image_bgr, quant_levels)
            # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤ºå’Œä¸‹è½½
            quantized_rgb = cv2.cvtColor(quantized_bgr, cv2.COLOR_BGR2RGB)
        
        # æ˜¾ç¤ºé‡‡æ ·ç»“æœ
        if sampled_rgb is not None:
            # æ˜¾ç¤ºå¯¹æ¯”å’Œç›´æ–¹å›¾
            st.markdown("### ğŸ”½ é‡‡æ ·æ•ˆæœå¯¹æ¯”")
            display_comparison_with_histograms(
                image_rgb, 
                sampled_rgb, 
                original_title=f"åŸå§‹å›¾åƒ {image_rgb.shape[1]}x{image_rgb.shape[0]}", 
                processed_title=f"é‡‡æ ·åå›¾åƒ {sampled_rgb.shape[1]}x{sampled_rgb.shape[0]}"
            )
            
            provide_download_button(
                sampled_rgb, 
                f"sampled_{sample_ratio}x.jpg", 
                "ğŸ“¥ ä¸‹è½½é‡‡æ ·ç»“æœ",
                unique_key_suffix="tab5_sampling"
            )
        
        # æ˜¾ç¤ºé‡åŒ–ç»“æœ
        if quantized_rgb is not None:
            # æ˜¾ç¤ºå¯¹æ¯”å’Œç›´æ–¹å›¾
            st.markdown("### ğŸšï¸ é‡åŒ–æ•ˆæœå¯¹æ¯”")
            display_comparison_with_histograms(
                image_rgb, 
                quantized_rgb, 
                original_title="åŸå§‹å›¾åƒ", 
                processed_title=f"{quant_levels}çº§é‡åŒ–"
            )
            
            provide_download_button(
                quantized_rgb, 
                f"quantized_{quant_levels}levels.jpg", 
                "ğŸ“¥ ä¸‹è½½é‡åŒ–ç»“æœ",
                unique_key_suffix="tab5_quantization"
            )
    else:
        st.info("ğŸ“¤ è¯·ä¸Šä¼ å›¾åƒæ–‡ä»¶æˆ–ä»ç´ æåº“é€‰æ‹©å›¾ç‰‡å¼€å§‹å¤„ç†")

# 6. å½©è‰²å›¾åƒåˆ†å‰²é€‰é¡¹å¡
with tabs[5]:
    st.markdown("### ğŸ¨ å½©è‰²å›¾åƒåˆ†å‰²")
    
    st.markdown("""
    <div class='ideology-card'>
        <h4>ğŸ¯ æ€æ”¿å…³è”ï¼šç²¾å‡†åˆ†æçš„èƒ½åŠ›</h4>
        <p>
        å½©è‰²å›¾åƒåˆ†å‰²æŠ€æœ¯ä½“ç°äº†<strong style='color: #dc2626;'>ç²¾å‡†åˆ†æ</strong>çš„èƒ½åŠ›ï¼Œ
        é€šè¿‡é¢œè‰²ç‰¹å¾è¯†åˆ«ä¸åŒåŒºåŸŸï¼Œè¿™ä½“ç°äº†<strong style='color: #dc2626;'>ç§‘å­¦åˆ†æ</strong>çš„å·¥ä½œæ–¹æ³•ã€‚
        åœ¨æŠ€æœ¯åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬è¦åŸ¹å…»ç²¾å‡†åˆ†æçš„èƒ½åŠ›ã€‚
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # ===== åŒåˆ—å¸ƒå±€ï¼šå·¦ä¾§ä¸Šä¼ ï¼Œå³ä¾§ç´ æåº“ =====
    col_upload1, col_upload2 = st.columns(2)
    
    uploaded_file = None
    
    with col_upload1:
        uploaded_file = st.file_uploader(
            "ğŸ“¤ ä¸Šä¼ å›¾åƒæ–‡ä»¶", 
            type=["jpg", "jpeg", "png", "bmp", "webp"], 
            key="tab6_upload"
        )
    
    with col_upload2:
        # ç´ æåº“é€‰æ‹©
        example_files = get_example_images()
        
        if example_files:
            selected_example = st.selectbox(
                "ğŸ“š ä»ç´ æåº“é€‰æ‹©",
                ["-- è¯·é€‰æ‹©ç´ æ --"] + example_files,
                key="tab6_example"
            )
            
            if selected_example != "-- è¯·é€‰æ‹©ç´ æ --":
                uploaded_file = load_example_image(selected_example)
                st.success(f"âœ… å·²é€‰æ‹©ç´ æ: {selected_example}")
        else:
            st.info("ğŸ“ ç´ æåº“ä¸ºç©ºï¼Œè¯·æ·»åŠ å›¾ç‰‡åˆ°examplesæ–‡ä»¶å¤¹")
    
    if uploaded_file is not None:
        # è¯»å–å›¾åƒ
        pil_image = Image.open(uploaded_file)
        # ä¿å­˜RGBç‰ˆæœ¬ç”¨äºæ˜¾ç¤º
        image_rgb = np.array(pil_image)
        # è½¬æ¢ä¸ºBGRç”¨äºOpenCVå¤„ç†
        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
        
        # åˆå§‹åŒ–ç»“æœå˜é‡
        result_rgb = None
        
        color_space = st.selectbox("é€‰æ‹©é¢œè‰²ç©ºé—´", ["RGBé¢œè‰²åˆ†å‰²", "HSVé¢œè‰²åˆ†å‰²"])
        
        if color_space == "RGBé¢œè‰²åˆ†å‰²":
            st.markdown("### RGBé¢œè‰²èŒƒå›´é€‰æ‹©")
            col1, col2 = st.columns(2)
            with col1:
                r_min = st.slider("Ræœ€å°å€¼", 0, 255, 0)
                g_min = st.slider("Gæœ€å°å€¼", 0, 255, 0)
                b_min = st.slider("Bæœ€å°å€¼", 0, 255, 0)
            with col2:
                r_max = st.slider("Ræœ€å¤§å€¼", 0, 255, 255)
                g_max = st.slider("Gæœ€å¤§å€¼", 0, 255, 255)
                b_max = st.slider("Bæœ€å¤§å€¼", 0, 255, 255)
            
            # OpenCVä½¿ç”¨BGRé¡ºåºï¼Œæ‰€ä»¥æ˜¯[B, G, R]
            lower_color = np.array([b_min, g_min, r_min])
            upper_color = np.array([b_max, g_max, r_max])
        else:
            st.markdown("### HSVé¢œè‰²èŒƒå›´é€‰æ‹©")
            col1, col2 = st.columns(2)
            with col1:
                h_min = st.slider("Hæœ€å°å€¼", 0, 179, 0)
                s_min = st.slider("Sæœ€å°å€¼", 0, 255, 0)
                v_min = st.slider("Væœ€å°å€¼", 0, 255, 0)
            with col2:
                h_max = st.slider("Hæœ€å¤§å€¼", 0, 179, 179)
                s_max = st.slider("Sæœ€å¤§å€¼", 0, 255, 255)
                v_max = st.slider("Væœ€å¤§å€¼", 0, 255, 255)
            
            lower_color = np.array([h_min, s_min, v_min])
            upper_color = np.array([h_max, s_max, v_max])
        
        if st.button("åº”ç”¨é¢œè‰²åˆ†å‰²", use_container_width=True):
            if color_space == "RGBé¢œè‰²åˆ†å‰²":
                # ä½¿ç”¨BGRå›¾åƒå¤„ç†
                result_bgr = apply_rgb_segmentation(image_bgr, lower_color, upper_color)
            else:
                # ä½¿ç”¨BGRå›¾åƒå¤„ç†
                result_bgr = apply_hsv_segmentation(image_bgr, lower_color, upper_color)
            
            # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤ºå’Œä¸‹è½½
            result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        # æ˜¾ç¤ºç»“æœå’Œä¸‹è½½
        if result_rgb is not None:
            # æ˜¾ç¤ºå¯¹æ¯”å’Œç›´æ–¹å›¾
            st.markdown(f"### ğŸ¨ {color_space}æ•ˆæœå¯¹æ¯”")
            display_comparison_with_histograms(
                image_rgb, 
                result_rgb, 
                original_title="åŸå§‹å›¾åƒ", 
                processed_title=f"{color_space}ç»“æœ"
            )
            
            provide_download_button(
                result_rgb, 
                f"color_segmentation.jpg", 
                "ğŸ“¥ ä¸‹è½½åˆ†å‰²ç»“æœ",
                unique_key_suffix="tab6_segmentation"
            )
    else:
        st.info("ğŸ“¤ è¯·ä¸Šä¼ å›¾åƒæ–‡ä»¶æˆ–ä»ç´ æåº“é€‰æ‹©å›¾ç‰‡å¼€å§‹å¤„ç†")
# 7. é¢œè‰²é€šé“åˆ†æé€‰é¡¹å¡
with tabs[6]:
    st.markdown("### ğŸŒˆ é¢œè‰²é€šé“åˆ†æ")
    
    st.markdown("""
    <div class='ideology-card'>
        <h4>ğŸ¯ æ€æ”¿å…³è”ï¼šç³»ç»Ÿåˆ†ææ€ç»´</h4>
        <p>
        é¢œè‰²é€šé“åˆ†æä½“ç°äº†<strong style='color: #dc2626;'>ç³»ç»Ÿåˆ†æ</strong>çš„æ€ç»´æ–¹å¼ï¼Œ
        é€šè¿‡åˆ†è§£å’Œé‡ç»„ç†è§£å›¾åƒç»“æ„ï¼Œè¿™ä½“ç°äº†<strong style='color: #dc2626;'>å…¨é¢åˆ†æ</strong>çš„ç§‘å­¦æ–¹æ³•ã€‚
        åœ¨æŠ€æœ¯å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬è¦åŸ¹å…»ç³»ç»Ÿæ€ç»´ã€‚
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # ===== åŒåˆ—å¸ƒå±€ï¼šå·¦ä¾§ä¸Šä¼ ï¼Œå³ä¾§ç´ æåº“ =====
    col_upload1, col_upload2 = st.columns(2)
    
    uploaded_file = None
    
    with col_upload1:
        uploaded_file = st.file_uploader(
            "ğŸ“¤ ä¸Šä¼ å›¾åƒæ–‡ä»¶", 
            type=["jpg", "jpeg", "png", "bmp", "webp"], 
            key="tab7_upload"
        )
    
    with col_upload2:
        # ç´ æåº“é€‰æ‹©
        example_files = get_example_images()
        
        if example_files:
            selected_example = st.selectbox(
                "ğŸ“š ä»ç´ æåº“é€‰æ‹©",
                ["-- è¯·é€‰æ‹©ç´ æ --"] + example_files,
                key="tab7_example"
            )
            
            if selected_example != "-- è¯·é€‰æ‹©ç´ æ --":
                uploaded_file = load_example_image(selected_example)
                st.success(f"âœ… å·²é€‰æ‹©ç´ æ: {selected_example}")
        else:
            st.info("ğŸ“ ç´ æåº“ä¸ºç©ºï¼Œè¯·æ·»åŠ å›¾ç‰‡åˆ°examplesæ–‡ä»¶å¤¹")
    
    if uploaded_file is not None:
        # è¯»å–å›¾åƒ
        pil_image = Image.open(uploaded_file)
        # ä¿å­˜RGBç‰ˆæœ¬ç”¨äºæ˜¾ç¤º
        image_rgb = np.array(pil_image)
        # è½¬æ¢ä¸ºBGRç”¨äºOpenCVå¤„ç†
        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
        
        # åˆå§‹åŒ–ç»“æœå˜é‡
        channels_rgb = None
        result_rgb = None
        
        st.markdown("### ğŸ“Š RGBé€šé“åˆ†ç¦»")
        if st.button("åˆ†ç¦»RGBé€šé“", use_container_width=True):
            # ä½¿ç”¨BGRå›¾åƒå¤„ç†
            channels_bgr = split_channels(image_bgr)
            
            # å°†æ¯ä¸ªé€šé“è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤º
            channels_rgb = []
            for channel_bgr in channels_bgr:
                channel_rgb = cv2.cvtColor(channel_bgr, cv2.COLOR_BGR2RGB)
                channels_rgb.append(channel_rgb)
        
        # æ˜¾ç¤ºé€šé“åˆ†ç¦»ç»“æœ
        if channels_rgb is not None:
            cols = st.columns(4)
            with cols[0]:
                # æ˜¾ç¤ºRGBåŸå§‹å›¾åƒ
                st.image(image_rgb, caption="åŸå§‹å›¾åƒ", use_container_width=True)
            with cols[1]:
                # æ˜¾ç¤ºçº¢è‰²é€šé“ï¼ˆBGRä¸­çš„ç¬¬2ä¸ªé€šé“ï¼‰
                st.image(channels_rgb[0], caption="çº¢è‰²é€šé“", use_container_width=True)
            with cols[2]:
                # æ˜¾ç¤ºç»¿è‰²é€šé“ï¼ˆBGRä¸­çš„ç¬¬1ä¸ªé€šé“ï¼‰
                st.image(channels_rgb[1], caption="ç»¿è‰²é€šé“", use_container_width=True)
            with cols[3]:
                # æ˜¾ç¤ºè“è‰²é€šé“ï¼ˆBGRä¸­çš„ç¬¬0ä¸ªé€šé“ï¼‰
                st.image(channels_rgb[2], caption="è“è‰²é€šé“", use_container_width=True)
            
            # æä¾›é€šé“åˆ†ç¦»ç»“æœä¸‹è½½
            st.markdown("### ğŸ“¥ é€šé“åˆ†ç¦»ä¸‹è½½")
            col1, col2, col3 = st.columns(3)
            with col1:
                provide_download_button(
                    channels_rgb[0], 
                    "red_channel.jpg", 
                    "ğŸ“¥ ä¸‹è½½çº¢è‰²é€šé“",
                    unique_key_suffix="tab7_red"
                )
            with col2:
                provide_download_button(
                    channels_rgb[1], 
                    "green_channel.jpg", 
                    "ğŸ“¥ ä¸‹è½½ç»¿è‰²é€šé“",
                    unique_key_suffix="tab7_green"
                )
            with col3:
                provide_download_button(
                    channels_rgb[2], 
                    "blue_channel.jpg", 
                    "ğŸ“¥ ä¸‹è½½è“è‰²é€šé“",
                    unique_key_suffix="tab7_blue"
                )
        
        st.markdown("### ğŸ›ï¸ é€šé“è°ƒæ•´")
        channel_to_adjust = st.selectbox("é€‰æ‹©è°ƒæ•´é€šé“", ["çº¢è‰²é€šé“", "ç»¿è‰²é€šé“", "è“è‰²é€šé“"])
        adjustment_value = st.slider("è°ƒæ•´å€¼", -100, 100, 0)
        
        if st.button("åº”ç”¨é€šé“è°ƒæ•´", use_container_width=True):
            # æ³¨æ„ï¼šBGRé¡ºåºï¼Œæ‰€ä»¥é€šé“æ˜ å°„ä¸åŒ
            # BGRé¡ºåºï¼š[è“è‰², ç»¿è‰², çº¢è‰²]
            channel_map = {
                "çº¢è‰²é€šé“": 2,  # BGRä¸­çš„ç¬¬2ä¸ªé€šé“æ˜¯çº¢è‰²
                "ç»¿è‰²é€šé“": 1,  # BGRä¸­çš„ç¬¬1ä¸ªé€šé“æ˜¯ç»¿è‰²
                "è“è‰²é€šé“": 0   # BGRä¸­çš„ç¬¬0ä¸ªé€šé“æ˜¯è“è‰²
            }
            
            # ä½¿ç”¨BGRå›¾åƒå¤„ç†
            result_bgr = adjust_channel(image_bgr, channel_map[channel_to_adjust], adjustment_value)
            # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤ºå’Œä¸‹è½½
            result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        # æ˜¾ç¤ºé€šé“è°ƒæ•´ç»“æœ
        if result_rgb is not None:
            # æ˜¾ç¤ºå¯¹æ¯”å’Œç›´æ–¹å›¾
            st.markdown(f"### ğŸ›ï¸ é€šé“è°ƒæ•´æ•ˆæœå¯¹æ¯”")
            display_comparison_with_histograms(
                image_rgb, 
                result_rgb, 
                original_title="åŸå§‹å›¾åƒ", 
                processed_title=f"è°ƒæ•´{channel_to_adjust}"
            )
            
            provide_download_button(
                result_rgb, 
                f"channel_adjusted.jpg", 
                "ğŸ“¥ ä¸‹è½½è°ƒæ•´ç»“æœ",
                unique_key_suffix="tab7_adjusted"
            )
    else:
        st.info("ğŸ“¤ è¯·ä¸Šä¼ å›¾åƒæ–‡ä»¶æˆ–ä»ç´ æåº“é€‰æ‹©å›¾ç‰‡å¼€å§‹å¤„ç†")

# 8. ç‰¹æ•ˆå¤„ç†é€‰é¡¹å¡
with tabs[7]:
    st.markdown("### ğŸ­ ç‰¹æ•ˆå¤„ç†")
    
    st.markdown("""
    <div class='ideology-card'>
        <h4>ğŸ¯ æ€æ”¿å…³è”ï¼šåˆ›æ–°å®è·µèƒ½åŠ›</h4>
        <p>
        ç‰¹æ•ˆå¤„ç†æŠ€æœ¯ä½“ç°äº†<strong style='color: #dc2626;'>åˆ›æ–°å®è·µ</strong>çš„èƒ½åŠ›ï¼Œ
        é€šè¿‡åˆ›é€ æ€§æ€ç»´å®ç°è§†è§‰æ•ˆæœï¼Œè¿™ä½“ç°äº†<strong style='color: #dc2626;'>å‹‡äºåˆ›æ–°</strong>çš„ç²¾ç¥ã€‚
        åœ¨æŠ€æœ¯åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬è¦æ•¢äºåˆ›æ–°ï¼Œå‹‡äºå®è·µã€‚
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # ===== åŒåˆ—å¸ƒå±€ï¼šå·¦ä¾§ä¸Šä¼ ï¼Œå³ä¾§ç´ æåº“ =====
    col_upload1, col_upload2 = st.columns(2)
    
    uploaded_file = None
    
    with col_upload1:
        uploaded_file = st.file_uploader(
            "ğŸ“¤ ä¸Šä¼ å›¾åƒæ–‡ä»¶", 
            type=["jpg", "jpeg", "png", "bmp", "webp"], 
            key="tab8_upload"
        )
    
    with col_upload2:
        # ç´ æåº“é€‰æ‹©
        example_files = get_example_images()
        
        if example_files:
            selected_example = st.selectbox(
                "ğŸ“š ä»ç´ æåº“é€‰æ‹©",
                ["-- è¯·é€‰æ‹©ç´ æ --"] + example_files,
                key="tab8_example"
            )
            
            if selected_example != "-- è¯·é€‰æ‹©ç´ æ --":
                uploaded_file = load_example_image(selected_example)
                st.success(f"âœ… å·²é€‰æ‹©ç´ æ: {selected_example}")
        else:
            st.info("ğŸ“ ç´ æåº“ä¸ºç©ºï¼Œè¯·æ·»åŠ å›¾ç‰‡åˆ°examplesæ–‡ä»¶å¤¹")
    
    if uploaded_file is not None:
        # è¯»å–å›¾åƒ
        pil_image = Image.open(uploaded_file)
        # ä¿å­˜RGBç‰ˆæœ¬ç”¨äºæ˜¾ç¤º
        image_rgb = np.array(pil_image)
        # è½¬æ¢ä¸ºBGRç”¨äºOpenCVå¤„ç†
        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
        
        effect_type = st.selectbox("é€‰æ‹©ç‰¹æ•ˆç±»å‹", 
                                  ["é›¨ç‚¹ç‰¹æ•ˆ", "é›ªèŠ±ç‰¹æ•ˆ", "æ¨±èŠ±ç‰¹æ•ˆ", "æ˜Ÿç©ºç‰¹æ•ˆ"])
        
        # åˆå§‹åŒ–ç»“æœå˜é‡
        result_rgb = None
        result_bgr = None
        
        if effect_type == "é›¨ç‚¹ç‰¹æ•ˆ":
            col1, col2 = st.columns(2)
            with col1:
                intensity = st.slider("é›¨ç‚¹å¯†åº¦", 50, 500, 150)
            with col2:
                opacity = st.slider("é€æ˜åº¦", 0.1, 1.0, 0.5, 0.1)
            
            if st.button("æ·»åŠ é›¨ç‚¹ç‰¹æ•ˆ", use_container_width=True):
                # ä½¿ç”¨BGRå›¾åƒå¤„ç†
                result_bgr = add_rain_effect(image_bgr, intensity, opacity)
                # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤º
                result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        elif effect_type == "é›ªèŠ±ç‰¹æ•ˆ":
            col1, col2 = st.columns(2)
            with col1:
                intensity = st.slider("é›ªèŠ±å¯†åº¦", 100, 1000, 300)
            with col2:
                opacity = st.slider("é€æ˜åº¦", 0.1, 1.0, 0.3, 0.1)
            
            if st.button("æ·»åŠ é›ªèŠ±ç‰¹æ•ˆ", use_container_width=True):
                # ä½¿ç”¨BGRå›¾åƒå¤„ç†
                result_bgr = add_snow_effect(image_bgr, intensity, opacity)
                # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤º
                result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        elif effect_type == "æ¨±èŠ±ç‰¹æ•ˆ":
            intensity = st.slider("æ¨±èŠ±æ•°é‡", 20, 200, 80)
            
            if st.button("æ·»åŠ æ¨±èŠ±ç‰¹æ•ˆ", use_container_width=True):
                # ä½¿ç”¨BGRå›¾åƒå¤„ç†
                sakura_intensity = intensity / 100.0  # è½¬æ¢ä¸º0.2-2.0çš„èŒƒå›´
                result_bgr = apply_sakura_effect(image_bgr, sakura_intensity)
                # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤º
                result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        else:  # æ˜Ÿç©ºç‰¹æ•ˆ
            stars = st.slider("æ˜Ÿæ˜Ÿæ•°é‡", 50, 500, 150)
            
            if st.button("æ·»åŠ æ˜Ÿç©ºç‰¹æ•ˆ", use_container_width=True):
                # ä½¿ç”¨BGRå›¾åƒå¤„ç†
                result_bgr = add_starry_night_effect(image_bgr, stars)
                # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤º
                result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        # æ˜¾ç¤ºç»“æœå’Œä¸‹è½½ - ä½¿ç”¨result_rgbæ£€æŸ¥
        if result_rgb is not None:
            # æ˜¾ç¤ºå¯¹æ¯”å’Œç›´æ–¹å›¾
            st.markdown(f"### ğŸ­ {effect_type}æ•ˆæœå¯¹æ¯”")
            display_comparison_with_histograms(
                image_rgb, 
                result_rgb, 
                original_title="åŸå§‹å›¾åƒ", 
                processed_title=f"{effect_type}ç»“æœ"
            )
            
            # ä¸‹è½½æ—¶ä¼ é€’RGBç‰ˆæœ¬
            provide_download_button(
                result_rgb, 
                f"ç‰¹æ•ˆ_{effect_type}.jpg", 
                "ğŸ“¥ ä¸‹è½½ç‰¹æ•ˆç»“æœ",
                unique_key_suffix="tab8_effect"  # æ·»åŠ å”¯ä¸€keyåç¼€é¿å…é‡å¤
            )
    else:
        st.info("ğŸ“¤ è¯·ä¸Šä¼ å›¾åƒæ–‡ä»¶æˆ–ä»ç´ æåº“é€‰æ‹©å›¾ç‰‡å¼€å§‹å¤„ç†")
                
                

# 9. å›¾åƒç»˜ç”»é€‰é¡¹å¡
with tabs[8]:
    st.markdown("### ğŸ¨ å›¾åƒç»˜ç”»é£æ ¼è½¬æ¢")
    
    st.markdown("""
    <div class='ideology-card'>
        <h4>ğŸ¯ æ€æ”¿å…³è”ï¼šè‰ºæœ¯ä¸ç§‘æŠ€èåˆ</h4>
        <p>
        å›¾åƒç»˜ç”»æŠ€æœ¯ä½“ç°äº†<strong style='color: #dc2626;'>è‰ºæœ¯ä¸ç§‘æŠ€</strong>çš„èåˆï¼Œ
        é€šè¿‡æŠ€æœ¯æ‰‹æ®µå®ç°è‰ºæœ¯æ•ˆæœï¼Œè¿™ä½“ç°äº†<strong style='color: #dc2626;'>åˆ›æ–°èåˆ</strong>çš„å‘å±•ç†å¿µã€‚
        åœ¨æŠ€æœ¯å‘å±•ä¸­ï¼Œæˆ‘ä»¬è¦æ³¨é‡å¤šå­¦ç§‘èåˆï¼Œæ¨åŠ¨<strong style='color: #dc2626;'>æ–‡åŒ–åˆ›æ–°</strong>å’Œ<strong style='color: #dc2626;'>ç§‘æŠ€è¿›æ­¥</strong>ã€‚
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # ===== åŒåˆ—å¸ƒå±€ï¼šå·¦ä¾§ä¸Šä¼ ï¼Œå³ä¾§ç´ æåº“ =====
    col_upload1, col_upload2 = st.columns(2)
    
    uploaded_file = None
    
    with col_upload1:
        uploaded_file = st.file_uploader(
            "ğŸ“¤ ä¸Šä¼ å›¾åƒæ–‡ä»¶", 
            type=["jpg", "jpeg", "png", "bmp", "webp"], 
            key="tab9_upload"
        )
    
    with col_upload2:
        # ç´ æåº“é€‰æ‹©
        example_files = get_example_images()
        
        if example_files:
            selected_example = st.selectbox(
                "ğŸ“š ä»ç´ æåº“é€‰æ‹©",
                ["-- è¯·é€‰æ‹©ç´ æ --"] + example_files,
                key="tab9_example"
            )
            
            if selected_example != "-- è¯·é€‰æ‹©ç´ æ --":
                uploaded_file = load_example_image(selected_example)
                st.success(f"âœ… å·²é€‰æ‹©ç´ æ: {selected_example}")
        else:
            st.info("ğŸ“ ç´ æåº“ä¸ºç©ºï¼Œè¯·æ·»åŠ å›¾ç‰‡åˆ°examplesæ–‡ä»¶å¤¹")
    
    if uploaded_file is not None:
        try:
            # è¯»å–å›¾åƒ
            pil_image = Image.open(uploaded_file)
            # ä¿å­˜RGBç‰ˆæœ¬ç”¨äºæ˜¾ç¤º
            image_rgb = np.array(pil_image)
            # è½¬æ¢ä¸ºBGRç”¨äºOpenCVå¤„ç†
            image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
            
            # ç¡®ä¿å›¾åƒæ˜¯uint8ç±»å‹
            if image_bgr.dtype != np.uint8:
                image_bgr = image_bgr.astype(np.uint8)
            
            # ç»˜ç”»é£æ ¼é€‰æ‹© - ç®€åŒ–ä¸ºåŸºæœ¬é£æ ¼
            painting_style = st.selectbox(
                "ğŸ¨ é€‰æ‹©ç»˜ç”»é£æ ¼", 
                [
                    "æ²¹ç”»æ•ˆæœ", 
                    "é“…ç¬”ç´ æ", 
                    "æ°´å¢¨ç”»æ•ˆæœ", 
                    "æ¼«ç”»é£æ ¼",
                    "æ°´å½©ç”»æ•ˆæœ",
                    "æ³¢æ™®è‰ºæœ¯æ•ˆæœ"
                ]
            )
            
            # åˆå§‹åŒ–ç»“æœå˜é‡
            result_rgb = None
            
            # æ ¹æ®é£æ ¼æ˜¾ç¤ºä¸åŒçš„æ§åˆ¶å‚æ•°
            if painting_style == "æ²¹ç”»æ•ˆæœ":
                col1, col2 = st.columns(2)
                with col1:
                    radius = st.slider("ç¬”è§¦åŠå¾„", 1, 10, 3, key="oil_radius")
                with col2:
                    intensity = st.slider("æ²¹ç”»å¼ºåº¦", 10, 50, 25, key="oil_intensity")
                
                if st.button("ğŸ¨ ç”Ÿæˆæ²¹ç”»æ•ˆæœ", use_container_width=True, key="oil_btn"):
                    with st.spinner("æ­£åœ¨ç»˜åˆ¶æ²¹ç”»..."):
                        result_bgr = apply_oil_painting_effect(
                            image_bgr, 
                            radius=radius, 
                            intensity=intensity
                        )
                        result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
            
            elif painting_style == "é“…ç¬”ç´ æ":
                col1, col2 = st.columns(2)
                with col1:
                    style_type = st.selectbox("ç´ æç±»å‹", ["ä¼˜é›…", "è‰ºæœ¯"], key="pencil_style")
                with col2:
                    intensity = st.slider("ç´ æå¼ºåº¦", 0.5, 2.0, 1.0, 0.1, key="pencil_intensity")
                
                if st.button("âœï¸ ç”Ÿæˆé“…ç¬”ç´ æ", use_container_width=True, key="pencil_btn"):
                    with st.spinner("æ­£åœ¨ç»˜åˆ¶ç´ æ..."):
                        if style_type == "ä¼˜é›…":
                            result_bgr = apply_pencil_sketch_effect(
                                image_bgr, 
                                style="elegant",
                                intensity=intensity
                            )
                        else:
                            result_bgr = apply_pencil_sketch_effect(
                                image_bgr,
                                style="artistic",
                                intensity=intensity
                            )
                        result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
            
            elif painting_style == "æ°´å¢¨ç”»æ•ˆæœ":
                ink_strength = st.slider("å¢¨è¿¹æµ“åº¦", 0.1, 0.8, 0.4, 0.1, key="ink_strength")
                
                if st.button("ğŸ–Œï¸ ç”Ÿæˆæ°´å¢¨ç”»", use_container_width=True, key="ink_btn"):
                    with st.spinner("æ­£åœ¨æ¸²æŸ“æ°´å¢¨æ•ˆæœ..."):
                        result_bgr = apply_ink_wash_painting_effect(
                            image_bgr, 
                            ink_strength=ink_strength
                        )
                        result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
            
            elif painting_style == "æ¼«ç”»é£æ ¼":
                col1, col2 = st.columns(2)
                with col1:
                    edge_threshold = st.slider("è½®å»“ç²—ç»†", 30, 150, 50, key="comic_edge")
                with col2:
                    color_style = st.selectbox("é¢œè‰²é£æ ¼", ["é²œè‰³", "æŸ”å’Œ"], key="comic_style")
                
                if st.button("ğŸ–¼ï¸ ç”Ÿæˆæ¼«ç”»æ•ˆæœ", use_container_width=True, key="comic_btn"):
                    with st.spinner("æ­£åœ¨è½¬æ¢ä¸ºæ¼«ç”»é£æ ¼..."):
                        result_bgr = apply_comic_effect(
                            image_bgr,
                            edge_threshold=edge_threshold,
                            color_style="vibrant" if color_style == "é²œè‰³" else "soft"
                        )
                        result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
            
            elif painting_style == "æ°´å½©ç”»æ•ˆæœ":
                col1, col2 = st.columns(2)
                with col1:
                    texture_strength = st.slider("çº¹ç†å¼ºåº¦", 0.0, 0.5, 0.3, 0.05, key="watercolor_texture")
                with col2:
                    style_type = st.selectbox("é£æ ¼ç±»å‹", ["ç»å…¸", "ç°ä»£"], key="watercolor_style")
                
                if st.button("ğŸ¨ ç”Ÿæˆæ°´å½©ç”»", use_container_width=True, key="watercolor_btn"):
                    with st.spinner("æ­£åœ¨æ¸²æŸ“æ°´å½©æ•ˆæœ..."):
                        result_bgr = apply_watercolor_effect(
                            image_bgr,
                            style="classic" if style_type == "ç»å…¸" else "modern",
                            texture_strength=texture_strength
                        )
                        result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
            
            elif painting_style == "æ³¢æ™®è‰ºæœ¯æ•ˆæœ":
                num_colors = st.slider("é¢œè‰²æ•°é‡", 3, 12, 6, key="popart_colors")
                
                if st.button("âœ¨ ç”Ÿæˆæ³¢æ™®è‰ºæœ¯", use_container_width=True, key="popart_btn"):
                    with st.spinner("æ­£åœ¨åˆ›å»ºæ³¢æ™®è‰ºæœ¯..."):
                        result_bgr = apply_pop_art_effect(
                            image_bgr,
                            num_colors=num_colors
                        )
                        result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
            
            # æ˜¾ç¤ºç»“æœå’Œä¸‹è½½
            if result_rgb is not None:
                # ç¡®ä¿ç»“æœæ˜¯uint8ç±»å‹
                if result_rgb.dtype != np.uint8:
                    result_rgb = result_rgb.astype(np.uint8)
                
                # æ˜¾ç¤ºå¯¹æ¯”å’Œç›´æ–¹å›¾
                st.markdown(f"### ğŸ–¼ï¸ {painting_style}æ•ˆæœå¯¹æ¯”")
                display_comparison_with_histograms(
                    image_rgb, 
                    result_rgb, 
                    original_title="åŸå§‹å›¾åƒ", 
                    processed_title=f"{painting_style}"
                )
                
                # ä¸‹è½½é€‰é¡¹
                st.markdown("### ğŸ“¥ ä¸‹è½½è‰ºæœ¯ä½œå“")
                
                # å°†ç»“æœè½¬æ¢ä¸ºPILå›¾åƒ
                result_pil = Image.fromarray(result_rgb)
                
                col_dl1, col_dl2, col_dl3 = st.columns(3)
                
                with col_dl1:
                    # JPEGæ ¼å¼
                    img_buffer = io.BytesIO()
                    result_pil.save(img_buffer, format="JPEG", quality=90)
                    img_buffer.seek(0)
                    
                    st.download_button(
                        label="ğŸ’¾ ä¸‹è½½JPEGæ ¼å¼",
                        data=img_buffer,
                        file_name=f"ç»˜ç”»_{painting_style}.jpg",
                        mime="image/jpeg",
                        use_container_width=True
                    )
                
                with col_dl2:
                    # PNGæ ¼å¼
                    png_buffer = io.BytesIO()
                    result_pil.save(png_buffer, format="PNG")
                    png_buffer.seek(0)
                    
                    st.download_button(
                        label="ğŸ–¼ï¸ ä¸‹è½½PNGæ ¼å¼",
                        data=png_buffer,
                        file_name=f"ç»˜ç”»_{painting_style}.png",
                        mime="image/png",
                        use_container_width=True
                    )
                
                with col_dl3:
                    # é«˜è´¨é‡ç‰ˆæœ¬
                    high_buffer = io.BytesIO()
                    result_pil.save(high_buffer, format="JPEG", quality=100)
                    high_buffer.seek(0)
                    
                    st.download_button(
                        label="ğŸŒŸ æœ€é«˜è´¨é‡",
                        data=high_buffer,
                        file_name=f"ç»˜ç”»_{painting_style}_é«˜è´¨é‡.jpg",
                        mime="image/jpeg",
                        use_container_width=True
                    )
        
        except Exception as e:
            st.error(f"å¤„ç†å›¾åƒæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            st.info("è¯·å°è¯•ä¸Šä¼ å…¶ä»–å›¾åƒæˆ–é€‰æ‹©ä¸åŒçš„å¤„ç†é€‰é¡¹ã€‚")
    
    else:
        # æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶æ—¶çš„ç•Œé¢
        st.info("ğŸ“¤ è¯·ä¸Šä¼ å›¾åƒæ–‡ä»¶æˆ–ä»ç´ æåº“é€‰æ‹©å›¾ç‰‡å¼€å§‹å¤„ç†")



# åº•éƒ¨æ€æ”¿æ€»ç»“
st.markdown("---")# 10. é£æ ¼è¿ç§»é€‰é¡¹å¡
with tabs[9]:
    st.markdown("### ğŸŒŸ é£æ ¼è¿ç§»ä¸è‰ºæœ¯åŒ–")
    
    st.markdown("""
    <div class='ideology-card'>
        <h4>ğŸ¯ æ€æ”¿å…³è”ï¼šæ–‡åŒ–ä¼ æ‰¿ä¸åˆ›æ–°</h4>
        <p>
        é£æ ¼è¿ç§»æŠ€æœ¯ä½“ç°äº†<strong style='color: #dc2626;'>æ–‡åŒ–ä¼ æ‰¿ä¸åˆ›æ–°</strong>ï¼Œ
        é€šè¿‡ç°ä»£æŠ€æœ¯é‡ç°ç»å…¸è‰ºæœ¯é£æ ¼ï¼Œè¿™ä½“ç°äº†<strong style='color: #dc2626;'>æ–‡åŒ–è‡ªä¿¡</strong>ã€‚
        åœ¨æŠ€æœ¯åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬è¦æ³¨é‡æ–‡åŒ–ä¼ æ‰¿ã€‚
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # åŒåˆ—å¸ƒå±€ï¼šå·¦ä¾§ä¸Šä¼ ï¼Œå³ä¾§ç´ æåº“
    col_upload1, col_upload2 = st.columns(2)
    
    uploaded_file = None
    
    with col_upload1:
        uploaded_file = st.file_uploader(
            "ğŸ“¤ ä¸Šä¼ å›¾åƒæ–‡ä»¶", 
            type=["jpg", "jpeg", "png"], 
            key="tab10_upload"
        )
    
    with col_upload2:
        # ç´ æåº“é€‰æ‹©
        example_files = get_example_images()
        
        if example_files:
            selected_example = st.selectbox(
                "ğŸ“š ä»ç´ æåº“é€‰æ‹©",
                ["-- è¯·é€‰æ‹©ç´ æ --"] + example_files,
                key="tab10_example"
            )
            
            if selected_example != "-- è¯·é€‰æ‹©ç´ æ --":
                uploaded_file = load_example_image(selected_example)
                st.success(f"âœ… å·²é€‰æ‹©ç´ æ: {selected_example}")
        else:
            st.info("ğŸ“ ç´ æåº“ä¸ºç©ºï¼Œè¯·æ·»åŠ å›¾ç‰‡åˆ°examplesæ–‡ä»¶å¤¹")
    
    if uploaded_file is not None:
        # è¯»å–å›¾åƒ
        pil_image = Image.open(uploaded_file)
        # ä¿å­˜RGBç‰ˆæœ¬ç”¨äºæ˜¾ç¤º
        image_rgb = np.array(pil_image)
        # è½¬æ¢ä¸ºBGRç”¨äºOpenCVå¤„ç†
        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
        
        # åˆå§‹åŒ–ç»“æœå˜é‡
        result_rgb = None
        
        style_type = st.selectbox("é€‰æ‹©è‰ºæœ¯é£æ ¼", 
                                  ["æ¢µé«˜é£æ ¼", "æ˜Ÿç©ºé£æ ¼", "è«å¥ˆå°è±¡æ´¾", 
                                   "æ¯•åŠ ç´¢ç«‹ä½“ä¸»ä¹‰", "åŠ¨æ¼«é£æ ¼"])
        
        if style_type == "æ¢µé«˜é£æ ¼":
            col1, col2 = st.columns(2)
            with col1:
                twist_strength = st.slider("æ‰­æ›²å¼ºåº¦", 0.0001,0.005,0.001,0.0001, 
                                          key="vangogh_twist")
            with col2:
                color_intensity = st.slider("è‰²å½©å¼ºåº¦", 0.5, 2.0, 1.5, 0.1, 
                                           key="vangogh_color")
            
            if st.button("ğŸ¨ åº”ç”¨æ¢µé«˜é£æ ¼", use_container_width=True, key="vangogh_btn"):
                with st.spinner("æ­£åœ¨åˆ›ä½œæ¢µé«˜é£æ ¼..."):
                    # ä¸´æ—¶è°ƒæ•´é¢œè‰²å¼ºåº¦
                    if color_intensity != 1.0:
                        hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)
                        hsv[:,:,1] = cv2.multiply(hsv[:,:,1], color_intensity).clip(0, 255)
                        temp_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
                        result_bgr = apply_van_gogh_style(temp_image, twist_strength)
                    else:
                        result_bgr = apply_van_gogh_style(image_bgr, twist_strength)
                    
                    result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        elif style_type == "æ˜Ÿç©ºé£æ ¼":
            col1, col2 = st.columns(2)
            with col1:
                star_density = st.slider("æ˜Ÿæ˜Ÿå¯†åº¦", 50, 300, 150, key="starry_stars")
            with col2:
                blue_intensity = st.slider("è“è‰²å¼ºåº¦", 0.5, 2.0, 1.2, 0.1, key="starry_blue")
            
            if st.button("ğŸŒŒ åº”ç”¨æ˜Ÿç©ºé£æ ¼", use_container_width=True, key="starry_btn"):
                with st.spinner("æ­£åœ¨ç»˜åˆ¶æ˜Ÿç©º..."):
                    # è°ƒæ•´è“è‰²å¼ºåº¦
                    if blue_intensity != 1.0:
                        lab = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2LAB)
                        l, a, b = cv2.split(lab)
                        b = cv2.multiply(b, blue_intensity).clip(0, 255)
                        lab = cv2.merge([l, a, b])
                        temp_image = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
                        result_bgr = apply_starry_sky_style(temp_image)
                    else:
                        result_bgr = apply_starry_sky_style(image_bgr)
                    
                    result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        elif style_type == "è«å¥ˆå°è±¡æ´¾":
            col1, col2 = st.columns(2)
            with col1:
                brush_size = st.slider("ç¬”è§¦å¤§å°", 5, 20, 10, key="monet_brush")
            with col2:
                color_vivid = st.slider("è‰²å½©é²œè‰³åº¦", 0.5, 2.0, 1.3, 0.1, key="monet_color")
            
            if st.button("ğŸŒ¸ åº”ç”¨è«å¥ˆé£æ ¼", use_container_width=True, key="monet_btn"):
                with st.spinner("æ­£åœ¨åˆ›ä½œå°è±¡æ´¾..."):
                    result_bgr = apply_monet_style(image_bgr)
                    
                    # è°ƒæ•´ç¬”è§¦å’Œè‰²å½©
                    if brush_size != 10 or color_vivid != 1.3:
                        # é‡æ–°è°ƒæ•´é¢œè‰²
                        hsv = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2HSV)
                        hsv[:,:,1] = cv2.multiply(hsv[:,:,1], color_vivid).clip(0, 255)
                        result_bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
                    
                    result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        elif style_type == "æ¯•åŠ ç´¢ç«‹ä½“ä¸»ä¹‰":
            col1, col2 = st.columns(2)
            with col1:
                grid_size = st.slider("å‡ ä½•å—å¤§å°", 10, 50, 30, key="picasso_grid")
            with col2:
                color_simplify = st.slider("é¢œè‰²ç®€åŒ–åº¦", 4, 16, 8, key="picasso_colors")
            
            if st.button("ğŸ”· åº”ç”¨ç«‹ä½“ä¸»ä¹‰é£æ ¼", use_container_width=True, key="picasso_btn"):
                with st.spinner("æ­£åœ¨åˆ›ä½œç«‹ä½“ä¸»ä¹‰ä½œå“..."):
                    result_bgr = apply_picasso_cubist_style(image_bgr)
                    
                    # è°ƒæ•´é¢œè‰²ç®€åŒ–åº¦
                    if color_simplify != 8:
                        pixels = result_bgr.reshape((-1, 3))
                        pixels = np.float32(pixels)
                        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)
                        _, labels, centers = cv2.kmeans(pixels, color_simplify, None, 
                                                        criteria, 10, cv2.KMEANS_RANDOM_CENTERS)
                        centers = np.uint8(centers)
                        simplified = centers[labels.flatten()]
                        result_bgr = simplified.reshape(result_bgr.shape)
                    
                    result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        else:  # åŠ¨æ¼«é£æ ¼
            col1, col2 = st.columns(2)
            with col1:
                edge_thickness = st.slider("è½®å»“ç²—ç»†", 1, 5, 2, key="anime_edge")
            with col2:
                flatness = st.slider("è‰²å½©å¹³å¦åº¦", 0.5, 2.0, 1.4, 0.1, key="anime_flat")
            
            if st.button("ğŸ­ åº”ç”¨åŠ¨æ¼«é£æ ¼", use_container_width=True, key="anime_btn"):
                with st.spinner("æ­£åœ¨è½¬æ¢ä¸ºåŠ¨æ¼«é£æ ¼..."):
                    result_bgr = apply_anime_style(image_bgr)
                    
                    # è°ƒæ•´è½®å»“ç²—ç»†
                    if edge_thickness != 2:
                        gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
                        g1 = cv2.GaussianBlur(gray, (5, 5), 0.5)
                        g2 = cv2.GaussianBlur(gray, (5, 5), 2.0)
                        dog = g1 - g2
                        _, edges = cv2.threshold(dog, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
                        edges = cv2.ximgproc.thinning(edges)
                        
                        # æ ¹æ®åšåº¦è°ƒæ•´è½®å»“
                        kernel_size = edge_thickness * 2 + 1
                        kernel = np.ones((kernel_size, kernel_size), np.uint8)
                        edges_thick = cv2.dilate(edges, kernel)
                        
                        # åº”ç”¨æ–°çš„è½®å»“
                        edges_bgr = cv2.cvtColor(edges_thick, cv2.COLOR_GRAY2BGR)
                        outline_color = (30, 30, 30)
                        edges_colored = cv2.bitwise_and(edges_bgr, outline_color)
                        result_bgr = cv2.subtract(result_bgr, edges_colored)
                    
                    result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        # æ˜¾ç¤ºç»“æœå’Œä¸‹è½½
        if result_rgb is not None:
            # æ˜¾ç¤ºå¯¹æ¯”å’Œç›´æ–¹å›¾
            st.markdown(f"### ğŸ¨ {style_type}æ•ˆæœå¯¹æ¯”")
            display_comparison_with_histograms(
                image_rgb, 
                result_rgb, 
                original_title="åŸå§‹å›¾åƒ", 
                processed_title=f"{style_type}"
            )
            
            # ä¸‹è½½é€‰é¡¹
            st.markdown("### ğŸ“¥ è‰ºæœ¯åˆ›ä½œä¸‹è½½")
            
            download_cols = st.columns(3)
            with download_cols[0]:
                provide_download_button(
                    result_rgb, 
                    f"è‰ºæœ¯_{style_type}.jpg", 
                    "ğŸ¨ ä¸‹è½½è‰ºæœ¯ä½œå“",
                    unique_key_suffix="art_main"
                )
            
            with download_cols[1]:
                # ç¼©ç•¥å›¾ç‰ˆæœ¬
                thumbnail = cv2.resize(result_rgb, (400, 400))
                provide_download_button(
                    thumbnail, 
                    f"è‰ºæœ¯_{style_type}_ç¼©ç•¥å›¾.jpg", 
                    "ğŸ–¼ï¸ ä¸‹è½½ç¼©ç•¥å›¾",
                    unique_key_suffix="art_thumb"
                )
            
            with download_cols[2]:
                # é«˜è´¨é‡ç‰ˆæœ¬
                high_buffer = io.BytesIO()
                result_pil = Image.fromarray(result_rgb)
                result_pil.save(high_buffer, format="JPEG", quality=100)
                high_buffer.seek(0)
                
                st.download_button(
                    label="ğŸŒŸ æœ€é«˜è´¨é‡",
                    data=high_buffer,
                    file_name=f"è‰ºæœ¯_{style_type}_é«˜è´¨é‡.jpg",
                    mime="image/jpeg",
                    use_container_width=True
                )
    else:
        st.info("ğŸ“¤ è¯·ä¸Šä¼ å›¾åƒæ–‡ä»¶æˆ–ä»ç´ æåº“é€‰æ‹©å¼€å§‹è‰ºæœ¯åˆ›ä½œ")
        
# 11. è€ç…§ç‰‡ä¸Šè‰²é€‰é¡¹å¡
with tabs[10]:
    st.markdown("### ğŸ–¼ï¸ è€ç…§ç‰‡ä¸Šè‰²ä¸ä¿®å¤")
    
    st.markdown("""
    <div class='ideology-card'>
        <h4>ğŸ¯ æ€æ”¿å…³è”ï¼šå†å²ä¼ æ‰¿ä¸è®°å¿†</h4>
        <p>
        è€ç…§ç‰‡ä¸Šè‰²æŠ€æœ¯ä½“ç°äº†<strong style='color: #dc2626;'>å†å²ä¼ æ‰¿</strong>çš„æ„ä¹‰ï¼Œ
        é€šè¿‡æŠ€æœ¯æ‰‹æ®µé‡ç°å†å²è‰²å½©ï¼Œè¿™ä½“ç°äº†<strong style='color: #dc2626;'>è®°å¿†ä¼ æ‰¿</strong>çš„ä»·å€¼ã€‚
        åœ¨æŠ€æœ¯åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬è¦å°Šé‡å†å²ï¼Œä¼ æ‰¿æ–‡åŒ–ã€‚
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # åŒåˆ—å¸ƒå±€ï¼šå·¦ä¾§ä¸Šä¼ ï¼Œå³ä¾§ç´ æåº“
    col_upload1, col_upload2 = st.columns(2)
    
    uploaded_file = None
    
    with col_upload1:
        uploaded_file = st.file_uploader(
            "ğŸ“¤ ä¸Šä¼ é»‘ç™½æˆ–è€æ—§ç…§ç‰‡", 
            type=["jpg", "jpeg", "png"], 
            key="tab11_upload"
        )
    
    with col_upload2:
        # ç´ æåº“é€‰æ‹©
        example_files = get_example_images()
        
        if example_files:
            selected_example = st.selectbox(
                "ğŸ“š ä»ç´ æåº“é€‰æ‹©",
                ["-- è¯·é€‰æ‹©ç´ æ --"] + example_files,
                key="tab11_example"
            )
            
            if selected_example != "-- è¯·é€‰æ‹©ç´ æ --":
                uploaded_file = load_example_image(selected_example)
                st.success(f"âœ… å·²é€‰æ‹©ç´ æ: {selected_example}")
        else:
            st.info("ğŸ“ ç´ æåº“ä¸ºç©ºï¼Œè¯·æ·»åŠ å›¾ç‰‡åˆ°examplesæ–‡ä»¶å¤¹")
    
    if uploaded_file is not None:
        # è¯»å–å›¾åƒ
        pil_image = Image.open(uploaded_file)
        # ä¿å­˜RGBç‰ˆæœ¬ç”¨äºæ˜¾ç¤º
        image_rgb = np.array(pil_image)
        # è½¬æ¢ä¸ºBGRç”¨äºOpenCVå¤„ç†
        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
        
        # æ˜¾ç¤ºåŸå§‹å›¾åƒ
        col1, col2 = st.columns(2)
        with col1:
            st.image(image_rgb, caption="åŸå§‹ç…§ç‰‡", use_container_width=True)
        
        # æ£€æŸ¥å›¾åƒæ˜¯å¦æ˜¯é»‘ç™½çš„
        is_colorful = True
        if len(image_rgb.shape) == 3:
            # è®¡ç®—é¢œè‰²å·®å¼‚
            r_channel = image_rgb[:,:,0]
            g_channel = image_rgb[:,:,1]
            b_channel = image_rgb[:,:,2]
            
            # å¦‚æœä¸‰ä¸ªé€šé“éå¸¸ç›¸ä¼¼ï¼Œå¯èƒ½æ˜¯é»‘ç™½å›¾åƒ
            diff_rg = np.abs(r_channel.astype(float) - g_channel.astype(float)).mean()
            diff_rb = np.abs(r_channel.astype(float) - b_channel.astype(float)).mean()
            diff_gb = np.abs(g_channel.astype(float) - b_channel.astype(float)).mean()
            
            # å¦‚æœå¹³å‡å·®å¼‚å¾ˆå°ï¼Œå¯èƒ½æ˜¯é»‘ç™½å›¾åƒ
            avg_diff = (diff_rg + diff_rb + diff_gb) / 3
            is_colorful = avg_diff > 15  # ç¨å¾®æé«˜é˜ˆå€¼
            
            with col2:
                st.markdown("### ğŸ” å›¾åƒåˆ†æ")
                st.info(f"é¢œè‰²å·®å¼‚åº¦: {avg_diff:.2f}")
                
                if avg_diff < 10:
                    st.success("âœ… æ£€æµ‹åˆ°é»‘ç™½/ç°åº¦å›¾åƒ")
                elif avg_diff < 15:
                    st.warning("âš ï¸ æ£€æµ‹åˆ°è¿‘ç°åº¦å›¾åƒï¼Œä¸Šè‰²æ•ˆæœè¾ƒå¥½")
                else:
                    st.warning("âš ï¸ æ£€æµ‹åˆ°å½©è‰²å›¾åƒï¼Œä¸Šè‰²æ•ˆæœå¯èƒ½ä¸æ˜æ˜¾")
        
        # æ·»åŠ é¢œè‰²è°ƒæ•´å‚æ•°
        st.markdown("### ğŸ¨ ä¸Šè‰²å‚æ•°è®¾ç½®")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # é€‰æ‹©ä¸Šè‰²æ¨¡å¼
            colorize_mode = st.selectbox(
                "ä¸Šè‰²æ¨¡å¼",
                ["æ™ºèƒ½ä¸Šè‰²", "å¤å¤è‰²è°ƒ", "é²œè‰³è‰²è°ƒ", "è‡ªç„¶è‰²è°ƒ", "AIå¢å¼ºä¸Šè‰²"],
                help="é€‰æ‹©ä¸åŒçš„ä¸Šè‰²é£æ ¼"
            )
            
            # æ˜¯å¦å¼ºåˆ¶å»è‰²
            force_grayscale = st.checkbox(
                "å¼ºåˆ¶è½¬æ¢ä¸ºé»‘ç™½å›¾åƒ", 
                value=not is_colorful,
                help="å¦‚æœåŸå§‹å›¾åƒå·²ç»æ˜¯å½©è‰²ï¼Œå¯ä»¥å¼ºåˆ¶è½¬æ¢ä¸ºé»‘ç™½å†ä¸Šè‰²"
            )
            
        with col2:
            # é¢œè‰²å¢å¼ºå‚æ•°
            saturation = st.slider("é¥±å’Œåº¦", 0.5, 3.0, 1.2, 0.1,
                                  help="è°ƒæ•´é¢œè‰²çš„é²œè‰³ç¨‹åº¦")
            
            brightness = st.slider("äº®åº¦", -30, 30, 0,
                                  help="è°ƒæ•´å›¾åƒçš„æ•´ä½“äº®åº¦")
            
            color_intensity = st.slider("è‰²å½©å¼ºåº¦", 0.5, 1.5, 1.0, 0.1,
                                       help="æ§åˆ¶ä¸Šè‰²çš„å¼ºåº¦")
            
        with col3:
            # å¯¹æ¯”åº¦å‚æ•°
            contrast = st.slider("å¯¹æ¯”åº¦", 0.5, 2.0, 1.0, 0.1,
                                help="è°ƒæ•´å›¾åƒçš„å¯¹æ¯”åº¦")
            
            # é™å™ªå¼ºåº¦
            denoise_strength = st.slider("é™å™ªå¼ºåº¦", 0, 10, 3,
                                        help="å»é™¤å›¾åƒå™ªç‚¹")
            
            # AIè¾…åŠ©
            ai_assist = st.checkbox("å¯ç”¨AIæ™ºèƒ½è¯†åˆ«", True,
                                   help="ä½¿ç”¨æ™ºèƒ½ç®—æ³•è¯†åˆ«å›¾åƒå†…å®¹")
        
        # è¾…åŠ©å‡½æ•°
        def smart_colorize_photo(image, color_intensity=1.0):
            """ä¼˜åŒ–çš„æ™ºèƒ½ä¸Šè‰²å‡½æ•°"""
            # å¦‚æœæ˜¯å½©è‰²å›¾åƒä¸”éœ€è¦ä¸Šè‰²ï¼Œå…ˆè½¬æ¢ä¸ºç°åº¦å†å¤„ç†
            if len(image.shape) == 3:
                # æ£€æŸ¥æ˜¯å¦æ˜¯çœŸæ­£çš„å½©è‰²å›¾
                b, g, r = cv2.split(image)
                diff = np.abs(b.astype(float) - g.astype(float)).mean() + \
                      np.abs(b.astype(float) - r.astype(float)).mean() + \
                      np.abs(g.astype(float) - r.astype(float)).mean()
                
                if diff > 15:  # å½©è‰²å›¾åƒ
                    # è½¬æ¢ä¸ºç°åº¦å†ä¸Šè‰²
                    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                    image = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
            
            # åŸºç¡€çš„ä¸Šè‰²å¤„ç†
            lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            
            # å¢å¼ºäº®åº¦å¯¹æ¯”åº¦
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            l_enhanced = clahe.apply(l)
            
            # æ™ºèƒ½æ·»åŠ é¢œè‰²
            height, width = l_enhanced.shape
            
            # æ ¹æ®äº®åº¦åŒºåŸŸæ™ºèƒ½ä¸Šè‰²
            for i in range(height):
                for j in range(width):
                    brightness = l_enhanced[i, j] / 255.0
                    
                    # æ™ºèƒ½ä¸Šè‰²è§„åˆ™
                    if brightness > 0.8:  # é«˜äº®åŒºåŸŸï¼ˆå¤©ç©º/äº‘ï¼‰
                        a[i, j] = 128 + int(64 * brightness)  # åé’è‰²
                        b[i, j] = 128 + int(96 * brightness)  # åè“è‰²
                    elif brightness > 0.6:  # ä¸­ç­‰åäº®ï¼ˆçš®è‚¤/å¢™å£ï¼‰
                        a[i, j] = 140 + int(40 * brightness)  # åæš–è‰²
                        b[i, j] = 100 + int(30 * brightness)  # åé»„è‰²
                    elif brightness > 0.4:  # ä¸­ç­‰äº®åº¦ï¼ˆæ¤è¢«ï¼‰
                        a[i, j] = 90 + int(70 * brightness)   # åç»¿è‰²
                        b[i, j] = 120 + int(40 * brightness)  # åé»„è‰²
                    elif brightness > 0.2:  # æš—éƒ¨ï¼ˆåœŸåœ°/é˜´å½±ï¼‰
                        a[i, j] = 110 + int(30 * brightness)  # åæ£•è‰²
                        b[i, j] = 80 + int(20 * brightness)   # åè“è‰²
                    else:  # å¾ˆæš—çš„åŒºåŸŸ
                        a[i, j] = 128
                        b[i, j] = 128
            
            # åº”ç”¨é¢œè‰²å¼ºåº¦
            a_center = 128
            b_center = 128
            a = ((a - a_center) * color_intensity + a_center).clip(0, 255).astype(np.uint8)
            b = ((b - b_center) * color_intensity + b_center).clip(0, 255).astype(np.uint8)
            
            lab_colored = cv2.merge([l_enhanced, a, b])
            result = cv2.cvtColor(lab_colored, cv2.COLOR_LAB2BGR)
            
            return result
        
        def apply_vintage_filter(image):
            """åº”ç”¨å¤å¤æ»¤é•œ"""
            # æ·»åŠ æ£•è¤è‰²è°ƒ
            sepia_filter = np.array([
                [0.393, 0.769, 0.189],
                [0.349, 0.686, 0.168],
                [0.272, 0.534, 0.131]
            ], dtype=np.float32)
            
            vintage = cv2.transform(image, sepia_filter)
            vintage = np.clip(vintage, 0, 255).astype(np.uint8)
            
            # æ·»åŠ è½»å¾®å™ªç‚¹
            noise = np.random.normal(0, 3, vintage.shape).astype(np.int16)
            vintage = cv2.add(vintage.astype(np.int16), noise)
            vintage = np.clip(vintage, 0, 255).astype(np.uint8)
            
            return vintage
        
        def enhance_color_vibrance(image, saturation_factor=1.5):
            """å¢å¼ºé¢œè‰²é²œè‰³åº¦"""
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            hsv[:,:,1] = cv2.multiply(hsv[:,:,1], saturation_factor).clip(0, 255)
            return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        
        def apply_natural_tones(image):
            """åº”ç”¨è‡ªç„¶è‰²è°ƒ"""
            # è½»å¾®é™ä½é¥±å’Œåº¦ï¼Œä½¿é¢œè‰²æ›´è‡ªç„¶
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            hsv[:,:,1] = cv2.multiply(hsv[:,:,1], 0.8).clip(0, 255)
            
            # å¢åŠ ä¸€ç‚¹æš–è‰²è°ƒ
            hsv[:,:,0] = (hsv[:,:,0] + 5) % 180
            
            return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        
        # æ·»åŠ é¢„è§ˆæŒ‰é’®
        st.markdown("---")
        
        col_btn1, col_btn2 = st.columns(2)
        with col_btn1:
            if st.button("ğŸ¨ åº”ç”¨ä¸Šè‰²æ•ˆæœ", use_container_width=True):
                with st.spinner("æ­£åœ¨æ™ºèƒ½ä¸Šè‰²ä¸­..."):
                    # ä½¿ç”¨BGRå›¾åƒå¤„ç†
                    process_image = image_bgr.copy()
                    if force_grayscale and is_colorful:
                        # è½¬æ¢ä¸ºç°åº¦å›¾
                        gray = cv2.cvtColor(process_image, cv2.COLOR_BGR2GRAY)
                        # å°†ç°åº¦å›¾è½¬æ¢ä¸ºä¸‰é€šé“BGR
                        process_image = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
                    
                    # æ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„ä¸Šè‰²æ–¹æ³•
                    if colorize_mode == "AIå¢å¼ºä¸Šè‰²":
                        result_bgr = colorize_old_photo(process_image, color_intensity, ai_assist)
                    elif colorize_mode == "æ™ºèƒ½ä¸Šè‰²":
                        result_bgr = smart_colorize_photo(process_image, color_intensity)
                    elif colorize_mode == "å¤å¤è‰²è°ƒ":
                        base_colored = smart_colorize_photo(process_image, color_intensity)
                        result_bgr = apply_vintage_filter(base_colored)
                    elif colorize_mode == "é²œè‰³è‰²è°ƒ":
                        base_colored = smart_colorize_photo(process_image, color_intensity)
                        result_bgr = enhance_color_vibrance(base_colored, saturation * 1.5)
                    else:  # è‡ªç„¶è‰²è°ƒ
                        base_colored = smart_colorize_photo(process_image, color_intensity * 0.8)
                        result_bgr = apply_natural_tones(base_colored)
                    
                    # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤º
                    result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
                    
                    # å­˜å‚¨ç»“æœ
                    st.session_state.colorize_result_rgb = result_rgb
                    st.session_state.colorize_result_bgr = result_bgr
                    
                    st.success("âœ… ä¸Šè‰²å®Œæˆï¼")
        
        with col_btn2:
            if st.button("ğŸ”„ é‡ç½®å‚æ•°", use_container_width=True):
                # é‡ç½®æ‰€æœ‰å‚æ•°åˆ°é»˜è®¤å€¼
                st.rerun()
        
        # æ˜¾ç¤ºç»“æœ
        if 'colorize_result_rgb' in st.session_state:
            result_rgb = st.session_state.colorize_result_rgb
            
            # æ˜¾ç¤ºå¯¹æ¯”å’Œç›´æ–¹å›¾
            st.markdown(f"### ğŸ¨ {colorize_mode}ä¸Šè‰²æ•ˆæœå¯¹æ¯”")
            display_comparison_with_histograms(
                image_rgb, 
                result_rgb, 
                original_title="åŸå§‹ç…§ç‰‡", 
                processed_title=f"ä¸Šè‰²ç»“æœ ({colorize_mode})"
            )
            
            # ä¸‹è½½é€‰é¡¹
            st.markdown("### ğŸ“¥ ä¸‹è½½ä¸Šè‰²ç»“æœ")
            
            col_dl1, col_dl2, col_dl3 = st.columns(3)
            
            with col_dl1:
                provide_download_button(
                    result_rgb, 
                    f"colorized_{colorize_mode}.jpg", 
                    "ğŸ’¾ ä¸‹è½½JPEGæ ¼å¼",
                    unique_key_suffix="colorize_jpg"
                )
            
            with col_dl2:
                # PNGæ ¼å¼
                png_buffer = io.BytesIO()
                result_pil = Image.fromarray(result_rgb)
                result_pil.save(png_buffer, format="PNG")
                png_buffer.seek(0)
                
                st.download_button(
                    label="ğŸ–¼ï¸ ä¸‹è½½PNGæ ¼å¼",
                    data=png_buffer,
                    file_name=f"colorized_{colorize_mode}.png",
                    mime="image/png",
                    use_container_width=True
                )
            
            with col_dl3:
                # é«˜è´¨é‡ç‰ˆæœ¬
                high_buffer = io.BytesIO()
                result_pil.save(high_buffer, format="JPEG", quality=100)
                high_buffer.seek(0)
                
                st.download_button(
                    label="ğŸŒŸ æœ€é«˜è´¨é‡",
                    data=high_buffer,
                    file_name=f"colorized_{colorize_mode}_é«˜è´¨é‡.jpg",
                    mime="image/jpeg",
                    use_container_width=True
                )
    else:
        # æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶æ—¶çš„ç•Œé¢
        st.info("ğŸ“¤ è¯·ä¸Šä¼ é»‘ç™½æˆ–è€æ—§ç…§ç‰‡æˆ–ä»ç´ æåº“é€‰æ‹©å¼€å§‹ä¸Šè‰²")

# 12. æ•°å­—å½¢æ€å­¦é€‰é¡¹å¡
with tabs[11]:
    st.markdown("### âš™ï¸ æ•°å­—å½¢æ€å­¦è½¬æ¢")
    
    st.markdown("""
    <div class='ideology-card'>
        <h4>ğŸ¯ æ€æ”¿å…³è”ï¼šç»“æ„åŒ–æ€ç»´</h4>
        <p>
        æ•°å­—å½¢æ€å­¦æŠ€æœ¯ä½“ç°äº†<strong style='color: #dc2626;'>ç»“æ„åŒ–</strong>æ€ç»´ï¼Œ
        é€šè¿‡æ•°å­¦å½¢æ€å¤„ç†å›¾åƒç»“æ„ï¼Œè¿™ä½“ç°äº†<strong style='color: #dc2626;'>ç³»ç»ŸåŒ–</strong>çš„å·¥ä½œæ–¹æ³•ã€‚
        åœ¨æŠ€æœ¯å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬è¦åŸ¹å…»ç»“æ„åŒ–æ€ç»´ã€‚
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # åŒåˆ—å¸ƒå±€ï¼šå·¦ä¾§ä¸Šä¼ ï¼Œå³ä¾§ç´ æåº“
    col_upload1, col_upload2 = st.columns(2)
    
    uploaded_file = None
    
    with col_upload1:
        uploaded_file = st.file_uploader(
            "ğŸ“¤ ä¸Šä¼ å›¾åƒæ–‡ä»¶ï¼ˆæ¨èäºŒå€¼å›¾åƒï¼‰", 
            type=["jpg", "jpeg", "png"], 
            key="tab12_upload"
        )
    
    with col_upload2:
        # ç´ æåº“é€‰æ‹©
        example_files = get_example_images()
        
        if example_files:
            selected_example = st.selectbox(
                "ğŸ“š ä»ç´ æåº“é€‰æ‹©",
                ["-- è¯·é€‰æ‹©ç´ æ --"] + example_files,
                key="tab12_example"
            )
            
            if selected_example != "-- è¯·é€‰æ‹©ç´ æ --":
                uploaded_file = load_example_image(selected_example)
                st.success(f"âœ… å·²é€‰æ‹©ç´ æ: {selected_example}")
        else:
            st.info("ğŸ“ ç´ æåº“ä¸ºç©ºï¼Œè¯·æ·»åŠ å›¾ç‰‡åˆ°examplesæ–‡ä»¶å¤¹")
    
    if uploaded_file is not None:
        # è¯»å–å›¾åƒ
        pil_image = Image.open(uploaded_file)
        # ä¿å­˜RGBç‰ˆæœ¬ç”¨äºæ˜¾ç¤º
        image_rgb = np.array(pil_image)
        
        # è½¬æ¢ä¸ºBGRç”¨äºOpenCVå¤„ç†
        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
        
        # å¦‚æœå›¾åƒä¸æ˜¯äºŒå€¼å›¾ï¼Œå…ˆè½¬æ¢ä¸ºç°åº¦å†äºŒå€¼åŒ–
        if len(image_bgr.shape) == 3:
            gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
            _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)
            # å°†äºŒå€¼å›¾åƒè½¬æ¢ä¸ºBGRä¸‰é€šé“
            image_bgr = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)
            # åŒæ—¶æ›´æ–°ç”¨äºæ˜¾ç¤ºçš„RGBç‰ˆæœ¬
            image_rgb = cv2.cvtColor(binary, cv2.COLOR_GRAY2RGB)
        
        operation = st.selectbox("é€‰æ‹©å½¢æ€å­¦æ“ä½œ", 
                                ["è…èš€", "è†¨èƒ€", "å¼€è¿ç®—", "é—­è¿ç®—"])
        
        kernel_size = st.slider("æ ¸å¤§å°", 3, 15, 5, step=2)
        
        if operation == "è…èš€":
            result_bgr = apply_erosion(image_bgr, kernel_size)
        elif operation == "è†¨èƒ€":
            result_bgr = apply_dilation(image_bgr, kernel_size)
        elif operation == "å¼€è¿ç®—":
            result_bgr = apply_opening(image_bgr, kernel_size)
        else:  # é—­è¿ç®—
            result_bgr = apply_closing(image_bgr, kernel_size)
        
        # è½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤ºå’Œä¸‹è½½
        result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
        
        # æ˜¾ç¤ºå¯¹æ¯”å’Œç›´æ–¹å›¾
        st.markdown(f"### âš™ï¸ {operation}æ•ˆæœå¯¹æ¯”")
        display_comparison_with_histograms(
            image_rgb, 
            result_rgb, 
            original_title="åŸå§‹å›¾åƒï¼ˆå·²äºŒå€¼åŒ–ï¼‰", 
            processed_title=f"{operation}ç»“æœ"
        )
        
        # ä¸‹è½½æ—¶ä¼ é€’RGBç‰ˆæœ¬
        provide_download_button(result_rgb, f"morphology_{operation}.jpg", "ğŸ“¥ ä¸‹è½½ç»“æœ")
    else:
        st.info("è¯·ä¸Šä¼ å›¾åƒæ–‡ä»¶æˆ–ä»ç´ æåº“é€‰æ‹©å¼€å§‹å¤„ç†")
st.markdown("""
<div class='ideology-card'>
    <h3>ğŸŒŸ æ€æ”¿å­¦ä¹ æ€»ç»“</h3>
    <p style='text-align: center; font-size: 1.1rem;'>
    é€šè¿‡13ä¸ªå›¾åƒå¤„ç†æ¨¡å—çš„å­¦ä¹ ä¸å®è·µï¼Œæˆ‘ä»¬ä¸ä»…æŒæ¡äº†å…ˆè¿›æŠ€æœ¯ï¼Œæ›´é‡è¦çš„æ˜¯åŸ¹å…»äº†
    <strong style='color: #dc2626;'>å·¥åŒ ç²¾ç¥ã€ç§‘å­¦æ€åº¦ã€åˆ›æ–°æ„è¯†ã€è´£ä»»æ‹…å½“ã€ç³»ç»Ÿæ€ç»´ã€æ–‡åŒ–ä¼ æ‰¿</strong>
    ç­‰ç»¼åˆç´ è´¨ã€‚å°†ä¸ªäººæˆé•¿ä¸å›½å®¶å‘å±•ç´§å¯†ç»“åˆï¼Œä¸ºå®ç°ç§‘æŠ€å¼ºå›½ç›®æ ‡è´¡çŒ®åŠ›é‡ã€‚
    </p>
</div>
""", unsafe_allow_html=True)

# åº•éƒ¨ä¿¡æ¯
st.markdown("""
<div style='text-align: center; margin-top: 40px; color: #666; font-size: 0.9rem;'>
    <p>ğŸ”¬ æ•°å­—å›¾åƒå¤„ç†å®éªŒå®¤ v3.0 | èåˆæ€æ”¿æ•™è‚² | åŸ¹å…»åˆ›æ–°äººæ‰</p>
    <p>Â© 2025 å›¾åƒå¤„ç†èæ€æ”¿å¹³å° | æŠ€æœ¯æ”¯æŒï¼šOpenCV, Streamlit, NumPy</p>
</div>
""", unsafe_allow_html=True)